{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48e17b6",
   "metadata": {},
   "source": [
    "Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup & Configuration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    # File paths\n",
    "    RAW_DATA_PATH = \"data/raw_conversation.xlsx\"\n",
    "    PROCESSED_DATA_PATH = \"data/processed/conversations.pkl\"\n",
    "    MODEL_SAVE_PATH = \"models/\"\n",
    "    \n",
    "    # ML Configuration\n",
    "    TEST_SIZE = 0.2\n",
    "    RANDOM_STATE = 42\n",
    "    \n",
    "    # Time thresholds (dalam menit)\n",
    "    NORMAL_THRESHOLD = 5\n",
    "    SERIOUS_FIRST_REPLY_THRESHOLD = 5\n",
    "    SERIOUS_FINAL_REPLY_THRESHOLD = 480  # 8 jam\n",
    "    COMPLAINT_FINAL_REPLY_THRESHOLD = 7200  # 5 hari\n",
    "    \n",
    "    # Abandoned detection\n",
    "    ABANDONED_TIMEOUT_MINUTES = 60  # 1 jam tanpa response\n",
    "    NO_CONVERSATION_TIMEOUT_MINUTES = 30  # 30 menit tanpa meaningful interaction\n",
    "    \n",
    "config = Config()\n",
    "\n",
    "# Create directories\n",
    "Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "Path(\"output\").mkdir(exist_ok=True)\n",
    "Path(\"output/reports\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"output/visualizations\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Setup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666cf9a8",
   "metadata": {},
   "source": [
    "Data Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f079890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessor\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.role_mapping = {\n",
    "            'bot': 'Bot',\n",
    "            'customer': 'Customer', \n",
    "            'operator': 'Operator',\n",
    "            'ticket automation': 'Ticket Automation'\n",
    "        }\n",
    "    \n",
    "    def load_raw_data(self, file_path):\n",
    "        \"\"\"Load data dari Excel dengan format yang ditentukan\"\"\"\n",
    "        print(f\"üìñ Loading data from {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_excel(file_path)\n",
    "            print(f\"‚úÖ Loaded {len(df)} rows\")\n",
    "            \n",
    "            # Validasi columns\n",
    "            required_columns = ['No', 'Ticket Number', 'Role', 'Sender', 'Message Date', 'Message']\n",
    "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "            \n",
    "            if missing_columns:\n",
    "                print(f\"‚ö†Ô∏è Missing columns: {missing_columns}\")\n",
    "                return None\n",
    "            \n",
    "            # Clean data\n",
    "            df = self.clean_data(df)\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def clean_data(self, df):\n",
    "        \"\"\"Clean dan preprocess data\"\"\"\n",
    "        # Copy dataframe\n",
    "        df_clean = df.copy()\n",
    "        \n",
    "        # Handle missing values\n",
    "        df_clean = df_clean.dropna(subset=['Message', 'Ticket Number'])\n",
    "        \n",
    "        # Clean text\n",
    "        df_clean['Message'] = df_clean['Message'].astype(str).str.strip()\n",
    "        \n",
    "        # Parse timestamp\n",
    "        df_clean['parsed_timestamp'] = pd.to_datetime(\n",
    "            df_clean['Message Date'], errors='coerce'\n",
    "        )\n",
    "        \n",
    "        # Remove invalid timestamps\n",
    "        initial_count = len(df_clean)\n",
    "        df_clean = df_clean[df_clean['parsed_timestamp'].notna()]\n",
    "        final_count = len(df_clean)\n",
    "        print(f\"üìÖ Valid timestamps: {final_count}/{initial_count}\")\n",
    "        \n",
    "        # Standardize roles\n",
    "        df_clean['Role'] = df_clean['Role'].str.lower().map(\n",
    "            lambda x: self.role_mapping.get(x, x.title())\n",
    "        )\n",
    "        \n",
    "        # Filter meaningful messages\n",
    "        df_clean = df_clean[df_clean['Message'].str.len() > 1]\n",
    "        \n",
    "        print(f\"üßπ Cleaned data: {len(df_clean)} rows\")\n",
    "        return df_clean\n",
    "    \n",
    "    def detect_conversation_start(self, ticket_df):\n",
    "        \"\"\"Deteksi kapan conversation benar-benar dimulai dengan operator\"\"\"\n",
    "        operator_greeting_patterns = [\n",
    "            r\"halo bapak/ibu.*selamat datang di livechat.*saya.*akan membantu\",\n",
    "            r\"Selamat datang di livechat\",\n",
    "            r\"Selamat.*, .* Selamat datang di layanan Live Chat Toyota Astra Motor. Dengan .*, apakah ada yang bisa dibantu?\",\n",
    "            r\"hai.*selamat datang\",\n",
    "            r\"halo.*selamat datang\"\n",
    "        ]\n",
    "        \n",
    "        for idx, row in ticket_df.iterrows():\n",
    "            message = str(row['Message']).lower()\n",
    "            role = str(row['Role']).lower()\n",
    "            \n",
    "            # Cari pattern greeting operator\n",
    "            if 'operator' in role:\n",
    "                for pattern in operator_greeting_patterns:\n",
    "                    if re.search(pattern, message):\n",
    "                        return row['parsed_timestamp']\n",
    "        \n",
    "        return None\n",
    "\n",
    "# Test preprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "raw_df = preprocessor.load_raw_data(config.RAW_DATA_PATH)\n",
    "\n",
    "if raw_df is not None:\n",
    "    print(f\"üìä Data preview:\")\n",
    "    print(f\"   Columns: {list(raw_df.columns)}\")\n",
    "    print(f\"   Shape: {raw_df.shape}\")\n",
    "    print(f\"   Ticket count: {raw_df['Ticket Number'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bdb52b",
   "metadata": {},
   "source": [
    "Conversation Parser & Q-A Pair Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c156f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONVERSATION PARSER - FIXED VERSION =====\n",
    "class ConversationParser:\n",
    "    def __init__(self):\n",
    "        self.question_indicators = [\n",
    "            '?', 'apa', 'bagaimana', 'berapa', 'kapan', 'dimana', 'kenapa',\n",
    "            'bisa', 'boleh', 'minta', 'tolong', 'tanya', 'info', 'caranya',\n",
    "            'mau tanya', 'boleh tanya', 'minta info', 'berapa harga',\n",
    "            'bagaimana cara', 'bisa tolong', 'mohon bantuan', 'gimana',\n",
    "            'promo', 'error', 'rusak', 'masalah', 'mogok', 'gagal', 'tidak bisa',\n",
    "            'harga', 'biaya', 'tarif', 'fungsi', 'cara', 'solusi', 'bantuan'\n",
    "        ]\n",
    "        \n",
    "        self.operator_greeting_patterns = [\n",
    "            r\"selamat\\s+(pagi|siang|sore|malam)\",\n",
    "            r\"selamat\\s+\\w+\\s+selamat\\s+datang\",\n",
    "            r\"selamat\\s+datang\",\n",
    "            r\"dengan\\s+\\w+\\s+apakah\\s+ada\",\n",
    "            r\"ada\\s+yang\\s+bisa\\s+dibantu\",\n",
    "            r\"boleh\\s+dibantu\",\n",
    "            r\"bisa\\s+dibantu\", \n",
    "            r\"halo.*selamat\",\n",
    "            r\"hai.*selamat\",\n",
    "            r\"perkenalkan.*saya\",\n",
    "            r\"layanan\\s+live\\s+chat\",\n",
    "            r\"live\\s+chat\\s+toyota\",\n",
    "            r\"toyota\\s+astra\\s+motor\"\n",
    "        ]\n",
    "        \n",
    "        self.bot_patterns = [\n",
    "            'klik.*setuju', 'data privasi', 'virtual assistant', 'silakan memilih',\n",
    "            'pilih menu', 'silahkan ketik nama', 'halo kak', 'bucket', 'media-images',\n",
    "            'pusat bantuan', 'main menu', 'feedback'\n",
    "        ]\n",
    "        \n",
    "        self.generic_reply_patterns = [\n",
    "            'terima kasih telah menghubungi',\n",
    "            'silakan pilih menu',\n",
    "            'virtual assistant',\n",
    "            'akan segera menghubungi',\n",
    "            'dalam antrian',\n",
    "            'tunggu sebentar',\n",
    "            'terima kasih, saat ini anda masuk',\n",
    "            'customer service akan',\n",
    "            'menghubungi anda'\n",
    "        ]\n",
    "    \n",
    "    def detect_conversation_start(self, ticket_df):\n",
    "        \"\"\"Deteksi kapan conversation benar-benar dimulai dengan operator\"\"\"\n",
    "        ticket_df = ticket_df.sort_values('parsed_timestamp').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"   üîç Analyzing {len(ticket_df)} messages for conversation start...\")\n",
    "        \n",
    "        # METHOD 1: Cari operator greeting message\n",
    "        for idx, row in ticket_df.iterrows():\n",
    "            message = str(row['Message']).lower()\n",
    "            role = str(row['Role']).lower()\n",
    "            \n",
    "            if self._is_bot_message(message, role):\n",
    "                continue\n",
    "                \n",
    "            if any(keyword in role for keyword in ['operator', 'agent', 'admin', 'cs']):\n",
    "                for pattern in self.operator_greeting_patterns:\n",
    "                    if re.search(pattern, message, re.IGNORECASE):\n",
    "                        print(f\"   ‚úÖ Conversation start: operator greeting at position {idx}\")\n",
    "                        return row['parsed_timestamp']\n",
    "        \n",
    "        # METHOD 2: Cari first operator response to meaningful customer question\n",
    "        meaningful_questions = []\n",
    "        for idx, row in ticket_df.iterrows():\n",
    "            role = str(row['Role']).lower()\n",
    "            message = str(row['Message']).lower()\n",
    "            \n",
    "            if self._is_bot_message(message, role):\n",
    "                continue\n",
    "                \n",
    "            if any(keyword in role for keyword in ['customer', 'user', 'pelanggan']):\n",
    "                if self._is_meaningful_message(message):\n",
    "                    meaningful_questions.append({\n",
    "                        'index': idx, 'time': row['parsed_timestamp'], 'message': message\n",
    "                    })\n",
    "            \n",
    "            elif meaningful_questions and any(keyword in role for keyword in ['operator', 'agent']):\n",
    "                last_question = meaningful_questions[-1]\n",
    "                time_gap = (row['parsed_timestamp'] - last_question['time']).total_seconds()\n",
    "                \n",
    "                if time_gap < 1800:  # 30 menit\n",
    "                    print(f\"   ‚úÖ Conversation start: first operator response at position {idx}\")\n",
    "                    return last_question['time']\n",
    "        \n",
    "        # Fallback methods\n",
    "        if meaningful_questions:\n",
    "            print(f\"   ‚ö†Ô∏è  Conversation start: first meaningful question\")\n",
    "            return meaningful_questions[0]['time']\n",
    "            \n",
    "        for idx, row in ticket_df.iterrows():\n",
    "            message = str(row['Message']).lower()\n",
    "            role = str(row['Role']).lower()\n",
    "            \n",
    "            if not self._is_bot_message(message, role):\n",
    "                print(f\"   ‚ö†Ô∏è  Conversation start: first non-bot message\")\n",
    "                return row['parsed_timestamp']\n",
    "        \n",
    "        if len(ticket_df) > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  Conversation start: first message\")\n",
    "            return ticket_df.iloc[0]['parsed_timestamp']\n",
    "        \n",
    "        print(\"   ‚ùå No conversation start detected\")\n",
    "        return None\n",
    "    \n",
    "    def parse_conversation(self, ticket_df):\n",
    "        \"\"\"Parse conversation menjadi Q-A pairs - FIXED SORTING VERSION\"\"\"\n",
    "        conversation_start = self.detect_conversation_start(ticket_df)\n",
    "        \n",
    "        if not conversation_start:\n",
    "            print(\"   ‚ö†Ô∏è  Using all non-bot messages\")\n",
    "            conv_df = self._filter_bot_messages(ticket_df)\n",
    "        else:\n",
    "            conv_df = self._filter_bot_messages(ticket_df)\n",
    "            conv_df = conv_df[conv_df['parsed_timestamp'] >= conversation_start]\n",
    "        \n",
    "        print(f\"   üìù Analyzing {len(conv_df)} meaningful messages\")\n",
    "        \n",
    "        if len(conv_df) == 0:\n",
    "            print(\"   ‚ùå No meaningful messages after filtering\")\n",
    "            return []\n",
    "        \n",
    "        # üî• FIX: URUTKAN DATA BERDASARKAN TIMESTAMP DULU!\n",
    "        conv_df = conv_df.sort_values('parsed_timestamp').reset_index(drop=True)\n",
    "        print(f\"   üîÑ Sorted messages by timestamp\")\n",
    "        \n",
    "        qa_pairs = []\n",
    "        current_question = None\n",
    "        question_time = None\n",
    "        question_context = []\n",
    "        last_customer_time = None\n",
    "        \n",
    "        # Track position untuk debugging\n",
    "        message_positions = []\n",
    "        \n",
    "        for idx, row in conv_df.iterrows():\n",
    "            role = str(row['Role']).lower()\n",
    "            message = str(row['Message'])\n",
    "            timestamp = row['parsed_timestamp']\n",
    "            \n",
    "            message_positions.append({\n",
    "                'position': idx,\n",
    "                'time': timestamp,\n",
    "                'role': role,\n",
    "                'message': message[:50] + '...' if len(message) > 50 else message\n",
    "            })\n",
    "            \n",
    "            # CUSTOMER MESSAGE\n",
    "            if any(keyword in role for keyword in ['customer', 'user', 'pelanggan']):\n",
    "                last_customer_time = timestamp\n",
    "                \n",
    "                if self._is_meaningful_message(message):\n",
    "                    # Jika ada previous question yang belum dijawab, simpan dulu\n",
    "                    if current_question and question_context:\n",
    "                        self._save_qa_pair(qa_pairs, question_context, question_time, None, None, position=idx)\n",
    "                    \n",
    "                    # Start new question\n",
    "                    current_question = message\n",
    "                    question_time = timestamp\n",
    "                    question_context = [message]\n",
    "                \n",
    "                elif current_question and question_context:\n",
    "                    # Check jika ini bagian dari bubble chat yang sama\n",
    "                    time_gap = (timestamp - question_time).total_seconds()\n",
    "                    if time_gap < 300:  # 5 menit\n",
    "                        question_context.append(message)\n",
    "                        question_time = timestamp  # Update ke timestamp terakhir\n",
    "                    else:\n",
    "                        # Bubble chat baru\n",
    "                        self._save_qa_pair(qa_pairs, question_context, question_time, None, None, position=idx)\n",
    "                        current_question = message\n",
    "                        question_time = timestamp\n",
    "                        question_context = [message]\n",
    "            \n",
    "            # OPERATOR MESSAGE - potential answer\n",
    "            elif current_question and question_context and any(keyword in role for keyword in ['operator', 'agent', 'admin', 'cs']):\n",
    "                # Skip jika ini generic reply\n",
    "                if self._is_generic_reply(message):\n",
    "                    continue\n",
    "                \n",
    "                # Pastikan ini benar-benar jawaban (bukan greeting awal)\n",
    "                time_gap = (timestamp - question_time).total_seconds()\n",
    "                \n",
    "                # üî• FIX: JANGAN PAKAI MINIMAL 1 MENIT, PAKAI LOGIKA LEBIH BAIK\n",
    "                # Cek jika ini operator message pertama setelah customer question\n",
    "                if time_gap >= 0:  # Boleh 0 atau positif (setelah question)\n",
    "                    lead_time = time_gap\n",
    "                    self._save_qa_pair(qa_pairs, question_context, question_time, message, timestamp, role, lead_time, position=idx)\n",
    "                    \n",
    "                    # Reset untuk next question\n",
    "                    current_question = None\n",
    "                    question_time = None\n",
    "                    question_context = []\n",
    "        \n",
    "        # Handle last question jika ada\n",
    "        if current_question and question_context:\n",
    "            self._save_qa_pair(qa_pairs, question_context, question_time, None, None, position=len(conv_df))\n",
    "        \n",
    "        # POST-PROCESSING: Cari jawaban untuk unanswered questions\n",
    "        qa_pairs = self._find_missing_answers(conv_df, qa_pairs)\n",
    "        \n",
    "        # üî• FIX: URUTKAN Q-A PAIRS BERDASARKAN QUESTION TIME!\n",
    "        qa_pairs = sorted(qa_pairs, key=lambda x: x['question_time'] if x['question_time'] else pd.Timestamp.min)\n",
    "        \n",
    "        # üî• FIX: TAMBAHKAN POSITION INDEX YANG BENAR BERDASARKAN URUTAN WAKTU\n",
    "        for i, pair in enumerate(qa_pairs):\n",
    "            pair['position'] = i  # Position berdasarkan urutan waktu\n",
    "        \n",
    "        print(f\"   ‚úÖ Found {len(qa_pairs)} Q-A pairs ({sum(1 for p in qa_pairs if p['is_answered'])} answered)\")\n",
    "        \n",
    "        # Debug: Print message sequence\n",
    "        print(f\"   üîç Message sequence (first 5):\")\n",
    "        for msg in message_positions[:5]:\n",
    "            print(f\"      {msg['position']}: {msg['time']} | {msg['role']:15} | {msg['message']}\")\n",
    "        \n",
    "        return qa_pairs\n",
    "    \n",
    "    def _save_qa_pair(self, qa_pairs, question_context, question_time, answer, answer_time, answer_role=None, lead_time=None, position=None):\n",
    "        \"\"\"Save Q-A pair ke list - FIXED dengan position\"\"\"\n",
    "        full_question = \" | \".join(question_context)\n",
    "        \n",
    "        pair_data = {\n",
    "            'question': full_question,\n",
    "            'question_time': question_time,\n",
    "            'bubble_count': len(question_context),\n",
    "            'is_answered': answer is not None,\n",
    "            'position': position if position is not None else len(qa_pairs)  # Default position\n",
    "        }\n",
    "        \n",
    "        if answer:\n",
    "            pair_data.update({\n",
    "                'answer': answer,\n",
    "                'answer_time': answer_time,\n",
    "                'answer_role': answer_role,\n",
    "                'lead_time_seconds': lead_time,\n",
    "                'lead_time_minutes': round(lead_time / 60, 2) if lead_time else None,\n",
    "                'lead_time_hhmmss': self._seconds_to_hhmmss(lead_time) if lead_time else None\n",
    "            })\n",
    "        else:\n",
    "            pair_data.update({\n",
    "                'answer': 'NO_ANSWER',\n",
    "                'answer_time': None,\n",
    "                'answer_role': None,\n",
    "                'lead_time_seconds': None,\n",
    "                'lead_time_minutes': None,\n",
    "                'lead_time_hhmmss': None\n",
    "            })\n",
    "        \n",
    "        qa_pairs.append(pair_data)\n",
    "    \n",
    "    def _find_missing_answers(self, conv_df, qa_pairs):\n",
    "        \"\"\"Cari jawaban untuk questions yang belum terjawab - FIXED SORTING\"\"\"\n",
    "        answered_pairs = [p for p in qa_pairs if p['is_answered']]\n",
    "        unanswered_pairs = [p for p in qa_pairs if not p['is_answered']]\n",
    "        \n",
    "        if not unanswered_pairs:\n",
    "            return qa_pairs\n",
    "        \n",
    "        # Untuk setiap unanswered question, cari operator message setelahnya\n",
    "        for i, pair in enumerate(unanswered_pairs):\n",
    "            question_time = pair['question_time']\n",
    "            \n",
    "            # Cari operator messages setelah question time\n",
    "            subsequent_messages = conv_df[\n",
    "                (conv_df['parsed_timestamp'] > question_time) &\n",
    "                (conv_df['Role'].str.lower().str.contains('operator|agent|admin|cs', na=False))\n",
    "            ].sort_values('parsed_timestamp')  # üî• FIX: URUTKAN\n",
    "            \n",
    "            if not subsequent_messages.empty:\n",
    "                # Ambil operator message pertama setelah question\n",
    "                first_operator_msg = subsequent_messages.iloc[0]\n",
    "                \n",
    "                # Skip jika generic reply\n",
    "                if not self._is_generic_reply(first_operator_msg['Message']):\n",
    "                    lead_time = (first_operator_msg['parsed_timestamp'] - question_time).total_seconds()\n",
    "                    \n",
    "                    # Update pair dengan answer yang ditemukan\n",
    "                    pair.update({\n",
    "                        'answer': first_operator_msg['Message'],\n",
    "                        'answer_time': first_operator_msg['parsed_timestamp'],\n",
    "                        'answer_role': first_operator_msg['Role'],\n",
    "                        'lead_time_seconds': lead_time,\n",
    "                        'lead_time_minutes': round(lead_time / 60, 2),\n",
    "                        'lead_time_hhmmss': self._seconds_to_hhmmss(lead_time),\n",
    "                        'is_answered': True\n",
    "                    })\n",
    "                    print(f\"   üîç Found missing answer for question {i+1}\")\n",
    "        \n",
    "        return answered_pairs + unanswered_pairs\n",
    "    \n",
    "    def _filter_bot_messages(self, df):\n",
    "        \"\"\"Filter out bot messages dari dataframe\"\"\"\n",
    "        return df[~df.apply(\n",
    "            lambda row: self._is_bot_message(str(row['Message']).lower(), str(row['Role']).lower()), \n",
    "            axis=1\n",
    "        )].copy()\n",
    "    \n",
    "    def _is_bot_message(self, message, role):\n",
    "        \"\"\"Check jika message dari bot\"\"\"\n",
    "        if any(keyword in role for keyword in ['bot', 'system', 'virtual', 'automation']):\n",
    "            return True\n",
    "        return any(pattern in message for pattern in self.bot_patterns)\n",
    "    \n",
    "    def _is_meaningful_message(self, message):\n",
    "        \"\"\"Check jika message meaningful untuk analysis\"\"\"\n",
    "        if not message or len(message.strip()) < 3:\n",
    "            return False\n",
    "            \n",
    "        message_lower = message.lower().strip()\n",
    "        \n",
    "        # Skip very short messages yang cuma greetings/consent\n",
    "        greetings = ['halo', 'hai', 'hi', 'selamat', 'pagi', 'siang', 'sore', 'malam']\n",
    "        consent_words = ['setuju', 'consent', 'agree', 'ok', 'oke', 'iya', 'yes']\n",
    "        menu_words = ['menu', 'pusatbantuan', 'mainmenu', 'kembali', 'others']\n",
    "        \n",
    "        words = message_lower.split()\n",
    "        if len(words) <= 2:\n",
    "            if any(word in words for word in greetings + consent_words + menu_words):\n",
    "                return False\n",
    "        \n",
    "        # Skip pure consent messages\n",
    "        if any(word in message_lower for word in consent_words) and len(message_lower) < 10:\n",
    "            return False\n",
    "            \n",
    "        # Skip menu navigation\n",
    "        if any(word in message_lower for word in menu_words) and len(message_lower) < 15:\n",
    "            return False\n",
    "        \n",
    "        # Question indicators\n",
    "        has_question_indicator = any(indicator in message_lower for indicator in self.question_indicators)\n",
    "        has_question_mark = '?' in message_lower\n",
    "        \n",
    "        # Meaningful content check\n",
    "        meaningful_words = [w for w in words if len(w) > 2 and w not in greetings + consent_words + menu_words]\n",
    "        has_meaningful_content = len(meaningful_words) >= 2\n",
    "        \n",
    "        return (has_question_indicator and has_meaningful_content) or has_question_mark or len(meaningful_words) >= 3\n",
    "    \n",
    "    def _is_generic_reply(self, message):\n",
    "        \"\"\"Skip generic/bot replies\"\"\"\n",
    "        message_lower = str(message).lower()\n",
    "        return any(pattern in message_lower for pattern in self.generic_reply_patterns)\n",
    "    \n",
    "    def _seconds_to_hhmmss(self, seconds):\n",
    "        \"\"\"Convert seconds to HH:MM:SS format\"\"\"\n",
    "        try:\n",
    "            hours = int(seconds // 3600)\n",
    "            minutes = int((seconds % 3600) // 60)\n",
    "            seconds = int(seconds % 60)\n",
    "            return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "        except:\n",
    "            return \"00:00:00\"\n",
    "\n",
    "    def _calculate_real_lead_time(self, ticket_data, customer_messages, agent_messages):\n",
    "        \"\"\"Calculate REAL lead time dari timestamps - FIXED VERSION\"\"\"\n",
    "        try:\n",
    "            if 'Message Date' not in ticket_data.columns:\n",
    "                # Estimate based on message count jika tidak ada timestamp\n",
    "                if customer_messages and agent_messages:\n",
    "                    return len(agent_messages) * 5.0  # Estimate 5 minutes per reply\n",
    "                return 10.0  # Default\n",
    "            \n",
    "            # Convert to datetime dengan error handling\n",
    "            ticket_data = ticket_data.copy()\n",
    "            \n",
    "            # Debug: Check original Message Date values\n",
    "            print(f\"DEBUG: Original Message Date sample: {ticket_data['Message Date'].head(3).tolist()}\")\n",
    "            \n",
    "            # Try different date parsing strategies\n",
    "            ticket_data['parsed_timestamp'] = pd.to_datetime(\n",
    "                ticket_data['Message Date'], \n",
    "                errors='coerce',\n",
    "                format='mixed'  # Try multiple formats\n",
    "            )\n",
    "            \n",
    "            # Check for parsing failures\n",
    "            failed_parses = ticket_data['parsed_timestamp'].isna().sum()\n",
    "            if failed_parses > 0:\n",
    "                print(f\"‚ö†Ô∏è Failed to parse {failed_parses} timestamps\")\n",
    "                \n",
    "                # Try alternative parsing\n",
    "                ticket_data['parsed_timestamp'] = pd.to_datetime(\n",
    "                    ticket_data['Message Date'], \n",
    "                    errors='coerce',\n",
    "                    dayfirst=True  # Try day-first format\n",
    "                )\n",
    "            \n",
    "            # Drop rows with invalid dates\n",
    "            valid_data = ticket_data.dropna(subset=['parsed_timestamp'])\n",
    "            \n",
    "            if len(valid_data) < 2:\n",
    "                print(\"‚ö†Ô∏è Not enough valid timestamps, using fallback\")\n",
    "                return 10.0  # Default jika tidak cukup data\n",
    "            \n",
    "            # üî• FIX: URUTKAN DATA BERDASARKAN TIMESTAMP!\n",
    "            valid_data = valid_data.sort_values('parsed_timestamp')\n",
    "            \n",
    "            print(f\"DEBUG: First message: {valid_data.iloc[0]['parsed_timestamp']}\")\n",
    "            print(f\"DEBUG: Last message: {valid_data.iloc[-1]['parsed_timestamp']}\")\n",
    "            \n",
    "            # Find first customer message time\n",
    "            customer_messages_times = []\n",
    "            agent_messages_times = []\n",
    "            \n",
    "            for idx, row in valid_data.iterrows():\n",
    "                role_str = str(row['Role']).lower()\n",
    "                message_time = row['parsed_timestamp']\n",
    "                \n",
    "                if any(keyword in role_str for keyword in ['customer', 'user', 'pelanggan']):\n",
    "                    customer_messages_times.append(message_time)\n",
    "                elif any(keyword in role_str for keyword in ['operator', 'agent', 'admin', 'cs']):\n",
    "                    agent_messages_times.append(message_time)\n",
    "            \n",
    "            if not customer_messages_times:\n",
    "                print(\"‚ö†Ô∏è No customer messages found\")\n",
    "                return 15.0\n",
    "            \n",
    "            if not agent_messages_times:\n",
    "                print(\"‚ö†Ô∏è No agent messages found\")\n",
    "                return 15.0\n",
    "            \n",
    "            # Ambil timestamp pertama customer dan agent\n",
    "            first_customer_time = min(customer_messages_times)\n",
    "            first_agent_time = min(agent_messages_times)\n",
    "            \n",
    "            print(f\"DEBUG: First customer time: {first_customer_time}\")\n",
    "            print(f\"DEBUG: First agent time: {first_agent_time}\")\n",
    "            \n",
    "            # Validasi: pastikan agent reply setelah customer question\n",
    "            if first_agent_time > first_customer_time:\n",
    "                lead_time_minutes = (first_agent_time - first_customer_time).total_seconds() / 60\n",
    "                print(f\"DEBUG: Calculated lead time: {lead_time_minutes} minutes\")\n",
    "                \n",
    "                # Minimum 1 minute, maksimum reasonable\n",
    "                lead_time_minutes = max(lead_time_minutes, 1.0)\n",
    "                lead_time_minutes = min(lead_time_minutes, 1440.0)  # Max 24 jam\n",
    "                \n",
    "                return lead_time_minutes\n",
    "            else:\n",
    "                # Jika agent reply sebelum customer, ini masalah timestamp\n",
    "                print(f\"‚ö†Ô∏è Timestamp issue: Agent replied before customer question\")\n",
    "                print(f\"   Customer: {first_customer_time}, Agent: {first_agent_time}\")\n",
    "                \n",
    "                # Fallback: cari agent reply pertama SETELAH customer question\n",
    "                subsequent_agents = [t for t in agent_messages_times if t > first_customer_time]\n",
    "                if subsequent_agents:\n",
    "                    first_valid_agent_time = min(subsequent_agents)\n",
    "                    lead_time_minutes = (first_valid_agent_time - first_customer_time).total_seconds() / 60\n",
    "                    lead_time_minutes = max(lead_time_minutes, 1.0)\n",
    "                    print(f\"‚úÖ Using subsequent agent reply: {lead_time_minutes} minutes\")\n",
    "                    return lead_time_minutes\n",
    "                else:\n",
    "                    # Fallback: estimate based on message order\n",
    "                    print(\"‚ö†Ô∏è Using message count fallback\")\n",
    "                    if customer_messages and agent_messages:\n",
    "                        return len(agent_messages) * 3.0\n",
    "                    \n",
    "                return 15.0  # Default fallback\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Lead time calculation error: {e}\")\n",
    "            import traceback\n",
    "            print(f\"Detailed error: {traceback.format_exc()}\")\n",
    "            return 10.0  # Fallback\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921fe3d",
   "metadata": {},
   "source": [
    "Debugging Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc100117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis untuk problematic tickets\n",
    "def debug_problematic_tickets():\n",
    "    \"\"\"Debug khusus untuk ticket yang bermasalah\"\"\"\n",
    "    if raw_df is None:\n",
    "        return\n",
    "    \n",
    "    problematic_tickets = ['18ea89910d0d8eac44aecca81d779e3a', '9842cd7eee5451283f8430fb83469940']\n",
    "    \n",
    "    print(\"üêõ DETAILED DEBUG FOR PROBLEMATIC TICKETS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    parser = ConversationParser()\n",
    "    for ticket_id in problematic_tickets:\n",
    "        print(f\"\\nüîç DEBUG TICKET: {ticket_id}\")\n",
    "        ticket_df = raw_df[raw_df['Ticket Number'] == ticket_id].sort_values('parsed_timestamp')\n",
    "        \n",
    "        # Show ALL messages setelah conversation start\n",
    "        conversation_start = parser.detect_conversation_start(ticket_df)\n",
    "        \n",
    "        if conversation_start:\n",
    "            filtered_df = parser._filter_bot_messages(ticket_df)\n",
    "            filtered_df = filtered_df[filtered_df['parsed_timestamp'] >= conversation_start]\n",
    "            \n",
    "            print(f\"üìã ALL MESSAGES AFTER CONVERSATION START ({len(filtered_df)} messages):\")\n",
    "            for idx, row in filtered_df.iterrows():\n",
    "                role = row['Role']\n",
    "                message = str(row['Message'])[:80]\n",
    "                timestamp = row['parsed_timestamp']\n",
    "                is_meaningful = parser._is_meaningful_message(message)\n",
    "                meaningful_flag = \"‚úÖ\" if is_meaningful else \"‚ùå\"\n",
    "                \n",
    "                print(f\"   {meaningful_flag} {timestamp} | {role:15} | {message}...\")\n",
    "            \n",
    "            # Analyze why no Q-A pairs\n",
    "            print(f\"\\nüîé ANALYSIS:\")\n",
    "            customer_msgs = filtered_df[filtered_df['Role'].str.lower().str.contains('customer', na=False)]\n",
    "            operator_msgs = filtered_df[filtered_df['Role'].str.lower().str.contains('operator|agent', na=False)]\n",
    "            \n",
    "            print(f\"   ‚Ä¢ Customer messages: {len(customer_msgs)}\")\n",
    "            print(f\"   ‚Ä¢ Operator messages: {len(operator_msgs)}\")\n",
    "            \n",
    "            meaningful_customer = [msg for msg in customer_msgs['Message'] if parser._is_meaningful_message(str(msg))]\n",
    "            print(f\"   ‚Ä¢ Meaningful customer messages: {len(meaningful_customer)}\")\n",
    "            \n",
    "            if len(meaningful_customer) == 0:\n",
    "                print(\"   ‚ùå REASON: No meaningful customer questions after operator greeting\")\n",
    "            elif len(operator_msgs) == 0:\n",
    "                print(\"   ‚ùå REASON: No operator responses after customer questions\")\n",
    "            else:\n",
    "                print(\"   ‚ùå REASON: Timing/sequence issues in Q-A matching\")\n",
    "\n",
    "# Run debug\n",
    "debug_problematic_tickets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3f5d3",
   "metadata": {},
   "source": [
    "Main Issue Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Issue Detector dengan Enhanced Question Detection\n",
    "class MainIssueDetector:\n",
    "    def __init__(self):\n",
    "        self.issue_keywords = {\n",
    "            'serious': [\n",
    "                'error', 'rusak', 'masalah', 'gagal', 'mogok', 'mati', 'tidak bisa', \n",
    "                'help', 'urgent', 'kendala', 'trouble', 'macet', 'hang', 'blank',\n",
    "                'not responding', 'bermasalah', 'gangguan', 'mogok', 'starter',\n",
    "                'rem blong', 'overheating', 'transmisi', 'kelistrikan', 'aki soak'\n",
    "            ],\n",
    "            'complaint': [\n",
    "                'komplain', 'kecewa', 'marah', 'protes', 'pengaduan', 'keluhan', \n",
    "                'sakit hati', 'tidak puas', 'keberatan', 'sangat kecewa', 'refund',\n",
    "                'garansi ditolak', 'pelayanan buruk', 'tidak profesional'\n",
    "            ],\n",
    "            'normal': [\n",
    "                'tanya', 'info', 'harga', 'berapa', 'cara', 'bagaimana', 'fungsi', \n",
    "                'promo', 'spesifikasi', 'fitur', 'mau tanya', 'boleh tanya', \n",
    "                'minta info', 'informasi', 'tanyakan', 'booking', 'test drive',\n",
    "                'alamat', 'lokasi', 'jam operasional', 'servis', 'sparepart'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # initial question indicators\n",
    "        self.initial_question_indicators = [\n",
    "            'mau tanya', 'boleh tanya', 'minta info', 'tanya dong', 'berapa harga',\n",
    "            'bagaimana cara', 'info', 'promo', 'spesifikasi', 'fungsi',\n",
    "            'apa', 'bagaimana', 'berapa', 'kapan', 'dimana', 'kenapa',  \n",
    "            'bisa', 'boleh', 'minta', 'tolong', 'caranya', 'gimana'    \n",
    "        ]\n",
    "        \n",
    "        # follow-up indicators \n",
    "        self.follow_up_indicators = [\n",
    "            'ok', 'oke', 'baik', 'sip', 'terima kasih', 'tks', 'thanks', 'makasih',\n",
    "            'kalau', 'jadi', 'berarti', 'apakah', 'apakah benar', 'bukan', 'oh',\n",
    "            'clarification', 'follow up', 'lanjutan' \n",
    "        ]\n",
    "    \n",
    "    def _is_initial_question(self, question):\n",
    "        \"\"\"Improved initial question detection\"\"\"\n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        # 1. Check explicit initial question patterns\n",
    "        if any(indicator in question_lower for indicator in self.initial_question_indicators):\n",
    "            return True\n",
    "        \n",
    "        # 2. Check jika question diawali dengan question word \n",
    "        question_words = ['apa', 'bagaimana', 'berapa', 'kapan', 'dimana', 'kenapa', 'bisa', 'boleh']\n",
    "        first_word = question_lower.split()[0] if question_lower.split() else \"\"\n",
    "        if first_word in question_words:\n",
    "            return True\n",
    "        \n",
    "        # 3. Check question mark dan meaningful content \n",
    "        has_question_mark = '?' in question_lower\n",
    "        word_count = len(question_lower.split())\n",
    "        \n",
    "        if has_question_mark and word_count >= 4 and not self._is_follow_up(question):\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def _is_follow_up(self, question):\n",
    "        \"\"\"Follow-up detection\"\"\"\n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        # 1. Check explicit follow-up patterns\n",
    "        if any(indicator in question_lower for indicator in self.follow_up_indicators):\n",
    "            return True\n",
    "        \n",
    "        # 2. Check jika question pendek dan mengandung acknowledgment\n",
    "        words = question_lower.split()\n",
    "        acknowledgment_words = ['ok', 'oke', 'baik', 'sip', 'tks', 'thanks']\n",
    "        \n",
    "        if len(words) <= 3 and any(word in acknowledgment_words for word in words):\n",
    "            return True\n",
    "        \n",
    "        # 3. Check clarification patterns\n",
    "        clarification_indicators = ['berarti', 'jadi', 'bukan', 'oh', 'apakah benar']\n",
    "        if any(indicator in question_lower for indicator in clarification_indicators):\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def detect_main_issue(self, qa_pairs):\n",
    "        \"\"\"Deteksi main issue dari Q-A pairs - IMPROVED\"\"\"\n",
    "        if not qa_pairs:\n",
    "            return None\n",
    "        \n",
    "        scored_issues = []\n",
    "        \n",
    "        for i, pair in enumerate(qa_pairs):\n",
    "            if not pair['is_answered']:\n",
    "                continue\n",
    "                \n",
    "            question = pair['question'].lower()\n",
    "            score = 0\n",
    "            \n",
    "            # 1. Keyword-based scoring \n",
    "            complaint_matches = sum(1 for kw in self.issue_keywords['complaint'] if kw in question)\n",
    "            serious_matches = sum(1 for kw in self.issue_keywords['serious'] if kw in question) \n",
    "            normal_matches = sum(1 for kw in self.issue_keywords['normal'] if kw in question)\n",
    "            \n",
    "            # Weighted scoring - complaint > serious > normal\n",
    "            score += (complaint_matches * 3) + (serious_matches * 2) + (normal_matches * 1)\n",
    "            \n",
    "            # 2. Question type analysis \n",
    "            is_initial_question = self._is_initial_question(pair['question'])  \n",
    "            is_follow_up = self._is_follow_up(pair['question'])  \n",
    "            \n",
    "            if is_initial_question and not is_follow_up:\n",
    "                score += 3  # Strong bonus untuk initial question\n",
    "            elif is_follow_up and not is_initial_question:\n",
    "                score -= 2  # Penalty untuk follow-up/clarification questions\n",
    "            \n",
    "            # 3. Position scoring \n",
    "            if i == 0:  # First question\n",
    "                score += 2\n",
    "            elif i == 1:  # Second question  \n",
    "                score += 1\n",
    "            \n",
    "            # 4. Content quality scoring \n",
    "            # Question yang lebih panjang dan detailed biasanya lebih important\n",
    "            word_count = len(question.split())\n",
    "            if word_count > 8:\n",
    "                score += 1\n",
    "            elif word_count < 4:\n",
    "                score -= 1\n",
    "            \n",
    "            # 5. Lead time consideration \n",
    "            # Questions dengan lead time sangat panjang mungkin important\n",
    "            lead_time = pair.get('lead_time_minutes', 0)\n",
    "            if lead_time > 15:  # Lebih dari 15 menit\n",
    "                score += 1\n",
    "            \n",
    "            scored_issues.append({\n",
    "                'question': pair['question'],\n",
    "                'question_time': pair['question_time'],\n",
    "                'score': max(score, 0),  \n",
    "                'position': i,\n",
    "                'lead_time': lead_time,\n",
    "                'bubble_count': pair.get('bubble_count', 1),\n",
    "                'word_count': word_count,\n",
    "                'is_initial_question': is_initial_question,\n",
    "                'is_follow_up': is_follow_up,\n",
    "                'complaint_matches': complaint_matches,\n",
    "                'serious_matches': serious_matches, \n",
    "                'normal_matches': normal_matches,\n",
    "                'pair_data': pair\n",
    "            })\n",
    "        \n",
    "        if not scored_issues:\n",
    "            return None\n",
    "        \n",
    "        # Pilih question dengan score tertinggi\n",
    "        main_issue = max(scored_issues, key=lambda x: x['score'])\n",
    "        \n",
    "        # IMPROVED issue type determination\n",
    "        if main_issue['complaint_matches'] > 0:\n",
    "            issue_type = 'complaint'\n",
    "        elif main_issue['serious_matches'] > 0:\n",
    "            issue_type = 'serious'\n",
    "        elif main_issue['normal_matches'] > 0:\n",
    "            issue_type = 'normal'\n",
    "        else:\n",
    "            # Fallback based on score\n",
    "            if main_issue['score'] >= 5:\n",
    "                issue_type = 'complaint'\n",
    "            elif main_issue['score'] >= 3:\n",
    "                issue_type = 'serious'\n",
    "            else:\n",
    "                issue_type = 'normal'\n",
    "        \n",
    "        # Build detailed reason\n",
    "        reason_parts = []\n",
    "        if main_issue['is_initial_question']:\n",
    "            reason_parts.append(\"initial question\")\n",
    "        if main_issue['complaint_matches'] > 0:\n",
    "            reason_parts.append(f\"{main_issue['complaint_matches']} complaint keywords\")\n",
    "        if main_issue['serious_matches'] > 0:\n",
    "            reason_parts.append(f\"{main_issue['serious_matches']} serious keywords\") \n",
    "        if main_issue['normal_matches'] > 0:\n",
    "            reason_parts.append(f\"{main_issue['normal_matches']} normal keywords\")\n",
    "        if main_issue['position'] == 0:\n",
    "            reason_parts.append(\"first question\")\n",
    "        \n",
    "        reason = f\"Score: {main_issue['score']} ({', '.join(reason_parts)})\"\n",
    "        \n",
    "        return {\n",
    "            'question': main_issue['question'],\n",
    "            'question_time': main_issue['question_time'],\n",
    "            'issue_type': issue_type,\n",
    "            'confidence_score': min(main_issue['score'] / 10.0, 1.0),\n",
    "            'all_candidates': scored_issues,\n",
    "            'selected_reason': reason,\n",
    "            'scoring_details': {\n",
    "                'complaint_matches': main_issue['complaint_matches'],\n",
    "                'serious_matches': main_issue['serious_matches'],\n",
    "                'normal_matches': main_issue['normal_matches'],\n",
    "                'is_initial_question': main_issue['is_initial_question'],\n",
    "                'is_follow_up': main_issue['is_follow_up']\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def debug_scoring(self, qa_pairs):\n",
    "        \"\"\"Debug function untuk melihat detailed scoring\"\"\"\n",
    "        if not qa_pairs:\n",
    "            return\n",
    "        \n",
    "        main_issue = self.detect_main_issue(qa_pairs)\n",
    "        \n",
    "        print(\"üîç DETAILED SCORING ANALYSIS:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for i, candidate in enumerate(main_issue['all_candidates']):\n",
    "            print(f\"\\n{i+1}. '{candidate['question'][:60]}...'\")\n",
    "            print(f\"   Score: {candidate['score']}\")\n",
    "            print(f\"   Position: {candidate['position'] + 1}\")\n",
    "            print(f\"   Word Count: {candidate['word_count']}\")\n",
    "            print(f\"   Initial Question: {candidate['is_initial_question']}\")\n",
    "            print(f\"   Follow-up: {candidate['is_follow_up']}\")\n",
    "            print(f\"   Keywords: C:{candidate['complaint_matches']} S:{candidate['serious_matches']} N:{candidate['normal_matches']}\")\n",
    "            print(f\"   Lead Time: {candidate['lead_time']} min\")\n",
    "\n",
    "# Test dengan improved detector\n",
    "detector = MainIssueDetector()\n",
    "\n",
    "parser = ConversationParser()\n",
    "if 'parser' in locals() and raw_df is not None:\n",
    "    sample_ticket_id = 'ead8d44e4914399b76af974a5169856e'\n",
    "    ticket_df = raw_df[raw_df['Ticket Number'] == sample_ticket_id]\n",
    "    qa_pairs = parser.parse_conversation(ticket_df)\n",
    "    \n",
    "    if qa_pairs:\n",
    "        print(\"üéØ ENHANCED MAIN ISSUE DETECTION:\")\n",
    "        main_issue = detector.detect_main_issue(qa_pairs)\n",
    "        print(f\"   Selected: '{main_issue['question'][:80]}...'\")\n",
    "        print(f\"   Type: {main_issue['issue_type']}\")\n",
    "        print(f\"   Confidence: {main_issue['confidence_score']:.2f}\")\n",
    "        print(f\"   Reason: {main_issue['selected_reason']}\")\n",
    "        \n",
    "        # Show scoring details\n",
    "        print(f\"\\nüìä Scoring Details:\")\n",
    "        details = main_issue['scoring_details']\n",
    "        print(f\"   Complaint Keywords: {details['complaint_matches']}\")\n",
    "        print(f\"   Serious Keywords: {details['serious_matches']}\")\n",
    "        print(f\"   Normal Keywords: {details['normal_matches']}\")\n",
    "        print(f\"   Initial Question: {details['is_initial_question']}\")\n",
    "        print(f\"   Follow-up: {details['is_follow_up']}\")\n",
    "        \n",
    "        # Debug scoring\n",
    "        detector.debug_scoring(qa_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e0a13",
   "metadata": {},
   "source": [
    "Hybrid ML Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1107cd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Hybrid Classifier initialized\n",
      "üß™ TESTING ENHANCED CLASSIFIER\n",
      "\n",
      "üîç Enhanced Prediction Results:\n",
      "   'mobil saya error tidak bisa starter, mog...' ‚Üí serious (conf: 0.95)\n",
      "   'saya komplain tentang pelayanan bengkel ...' ‚Üí complaint (conf: 0.95)\n",
      "   'mau tanya harga toyota avanza berapa?...' ‚Üí normal (conf: 0.95)\n",
      "   'aplikasi error terus tidak bisa login su...' ‚Üí serious (conf: 0.95)\n",
      "   'saya kecewa dengan produk ini, minta ref...' ‚Üí complaint (conf: 0.95)\n",
      "   'bagaimana cara aktivasi fitur t-intouch?...' ‚Üí normal (conf: 0.95)\n",
      "   'mesin bunyi aneh ada masalah serius...' ‚Üí serious (conf: 0.95)\n",
      "   'info promo terbaru untuk innova zenix...' ‚Üí normal (conf: 0.95)\n",
      "\n",
      "ü§ñ CREATING ENHANCED TRAINING DATA...\n",
      "üìä Enhanced Training Data: 72 samples\n",
      "üìä Enhanced Test Data: 18 samples\n",
      "üìä Class Distribution - Train: Counter({'complaint': 24, 'serious': 24, 'normal': 24})\n",
      "üìä Class Distribution - Test: Counter({'serious': 6, 'complaint': 6, 'normal': 6})\n",
      "ü§ñ Training Enhanced ML model...\n",
      "   Training samples: 72\n",
      "   Class distribution: Counter({'complaint': 24, 'serious': 24, 'normal': 24})\n",
      "‚úÖ Model trained - Accuracy: 1.000\n",
      "üìä ENHANCED CLASSIFIER PERFORMANCE REPORT\n",
      "==================================================\n",
      "Accuracy: 1.000\n",
      "Test Samples: 18\n",
      "Class Distribution: Counter({'serious': 6, 'complaint': 6, 'normal': 6})\n",
      "\n",
      "üìà Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       1.00      1.00      1.00         6\n",
      "     serious       1.00      1.00      1.00         6\n",
      "   complaint       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "\n",
      "üéØ Confidence Analysis:\n",
      "   Average Confidence: 0.583\n",
      "   High Confidence (>0.7): 3/18\n",
      "   Low Confidence (<0.5): 6/18\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Top 15 Features per Class:\n",
      "\n",
      "NORMAL:\n",
      "   komplain: 1.154\n",
      "   untuk: 1.083\n",
      "   dengan: 0.938\n",
      "   yang: 0.785\n",
      "   kecewa: 0.750\n",
      "   pelayanan: 0.659\n",
      "   protes: 0.588\n",
      "   sangat: 0.425\n",
      "   janji: 0.423\n",
      "   produk: 0.381\n",
      "   tidak: 0.338\n",
      "   ditepati: 0.316\n",
      "   minta: 0.292\n",
      "   bengkel: 0.282\n",
      "   biaya: 0.276\n",
      "\n",
      "SERIOUS:\n",
      "   berapa: 0.852\n",
      "   cara: 0.725\n",
      "   info: 0.646\n",
      "   avanza: 0.566\n",
      "   harga: 0.519\n",
      "   innova: 0.514\n",
      "   toyota: 0.427\n",
      "   jam: 0.419\n",
      "   dealer: 0.404\n",
      "   dp: 0.366\n",
      "   berkala: 0.344\n",
      "   dan: 0.333\n",
      "   beda: 0.333\n",
      "   warna: 0.304\n",
      "   calya: 0.304\n",
      "\n",
      "COMPLAINT:\n",
      "   bisa: 0.799\n",
      "   rem: 0.661\n",
      "   mesin: 0.609\n",
      "   terus: 0.590\n",
      "   jalan: 0.467\n",
      "   di: 0.426\n",
      "   tidak: 0.402\n",
      "   menerus: 0.342\n",
      "   sama: 0.340\n",
      "   sekali: 0.340\n",
      "   tol: 0.331\n",
      "   tiba: 0.330\n",
      "   starter: 0.325\n",
      "   setiap: 0.317\n",
      "   terbakar: 0.316\n",
      "\n",
      "‚úÖ ENHANCED HYBRID CLASSIFIER READY!\n",
      "   Model Accuracy: 1.000\n",
      "   Training Samples: 72\n",
      "   Test Samples: 18\n",
      "   Rule-based Fallback: Active\n"
     ]
    }
   ],
   "source": [
    "# Hybrid ML Classifier\n",
    "class HybridClassifier:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=1000,  # REDUCE features\n",
    "            ngram_range=(1, 1),  # Start with unigrams saja\n",
    "            min_df=1,           # Less restrictive\n",
    "            max_df=0.9,\n",
    "            stop_words=None     # Jangan remove stop words, penting untuk context\n",
    "        )\n",
    "        self.classifier = LogisticRegression(\n",
    "            random_state=config.RANDOM_STATE,\n",
    "            max_iter=2000,      # More iterations\n",
    "            class_weight='balanced',\n",
    "            C=1.0              # Regularization\n",
    "        )\n",
    "        self.is_trained = False\n",
    "        \n",
    "        # Enhanced rule-based fallback\n",
    "        self.rule_keywords = {\n",
    "            'complaint': [\n",
    "                'komplain', 'kecewa', 'marah', 'protes', 'pengaduan', 'keluhan', \n",
    "                'sakit hati', 'tidak puas', 'keberatan', 'sangat kecewa', 'refund',\n",
    "                'garansi ditolak', 'pelayanan buruk', 'tidak profesional', 'minta uang kembali'\n",
    "            ],\n",
    "            'serious': [\n",
    "                'error', 'rusak', 'masalah', 'gagal', 'mogok', 'mati', 'tidak bisa', \n",
    "                'help', 'urgent', 'kendala', 'trouble', 'macet', 'hang', 'blank',\n",
    "                'not responding', 'bermasalah', 'gangguan', 'starter', 'rem blong', \n",
    "                'overheating', 'transmisi', 'kelistrikan', 'aki soak', 'check engine'\n",
    "            ],\n",
    "            'normal': [\n",
    "                'tanya', 'info', 'harga', 'berapa', 'cara', 'bagaimana', 'fungsi', \n",
    "                'promo', 'spesifikasi', 'fitur', 'mau tanya', 'boleh tanya', \n",
    "                'minta info', 'informasi', 'tanyakan', 'booking', 'test drive',\n",
    "                'alamat', 'lokasi', 'jam operasional', 'servis', 'sparepart', 'dp'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        self.high_confidence_threshold = 0.7\n",
    "        self.medium_confidence_threshold = 0.5\n",
    "        \n",
    "        print(\"‚úÖ Hybrid Classifier initialized\")\n",
    "    \n",
    "    def create_enhanced_training_data(self):\n",
    "        \"\"\"Create BETTER training data dengan lebih banyak samples dan balance\"\"\"\n",
    "        enhanced_data = {\n",
    "            'texts': [\n",
    "                \"mau tanya harga mobil avanza berapa?\",\n",
    "                \"berapa harga toyota rush terbaru?\",\n",
    "                \"info promo innova zenix terbaru\",\n",
    "                \"bagaimana cara booking test drive?\",\n",
    "                \"spesifikasi toyota fortuner lengkap\",\n",
    "                \"alamat dealer terdekat di jakarta\",\n",
    "                \"jam operasional bengkel toyota\",\n",
    "                \"berapa biaya servis berkala avanza?\",\n",
    "                \"cara aktivasi fitur t-intouch\",\n",
    "                \"fungsi safety sense pada mobil\",\n",
    "                \"minta info dp ringan kredit\",\n",
    "                \"berapa lama waktu servis berkala?\",\n",
    "                \"warna yang tersedia untuk calya\",\n",
    "                \"beda innova zenix dan innova lama\",\n",
    "                \"fasilitas di bengkel toyota\",\n",
    "                \"syarat test drive mobil baru\",\n",
    "                \"info asuransi mobil terbaik\",\n",
    "                \"cara klaim garansi mobil\",\n",
    "                \"berapa harga velg ori innova?\",\n",
    "                \"lokasi dealer 24 jam\",\n",
    "                \"info cicilan mobil tanpa dp\",\n",
    "                \"berapa konsumsi bensin avanza?\",\n",
    "                \"sparepart yang perlu diganti rutin\",\n",
    "                \"cara perawatan mobil baru\",\n",
    "                \"beda vvti dan d4d\",\n",
    "                \"berapa harga oli mesin ori?\",\n",
    "                \"jadwal service gratis pertama\",\n",
    "                \"cara connect android auto\",\n",
    "                \"info membership toyota\",\n",
    "                \"berapa harga ban mobil avanza\",\n",
    "                \n",
    "                \"mobil saya error tidak bisa starter\",\n",
    "                \"mesin bunyi aneh ada masalah serius\",\n",
    "                \"aplikasi error terus tidak bisa login\",\n",
    "                \"rem blong sangat berbahaya\",\n",
    "                \"mogok di jalan butuh bantuan cepat\",\n",
    "                \"mesin overheating terus menerus\",\n",
    "                \"transmisi bermasalah tidak bisa pindah gigi\",\n",
    "                \"kelistrikan error semua lampu mati\",\n",
    "                \"aki soak tidak bisa starter pagi ini\",\n",
    "                \"check engine menyala terus sejak kemarin\",\n",
    "                \"mobil tiba-tiba mati di tol\",\n",
    "                \"asap keluar dari kap mesin\",\n",
    "                \"rem tidak berfungsi dengan baik\",\n",
    "                \"setir berat sekali tidak bisa dibelokkan\",\n",
    "                \"oli mesin bocor parah\",\n",
    "                \"air radiator habis terus menerus\",\n",
    "                \"mobil tidak bisa distarter sama sekali\",\n",
    "                \"lampu dashboard berkedip semua\",\n",
    "                \"ban pecah di jalan tol\",\n",
    "                \"mesin bergetar sangat kencang\",\n",
    "                \"kopling slip tidak bisa jalan\",\n",
    "                \"ac tidak dingin sama sekali\",\n",
    "                \"rem bunyi keras setiap kali diinjak\",\n",
    "                \"mobil tidak bisa masuk gigi\",\n",
    "                \"asap hitam keluar dari knalpot\",\n",
    "                \"mesin sulit dinyakan di pagi hari\",\n",
    "                \"rem tangan tidak bisa dilepas\",\n",
    "                \"oli terus berkurang setiap hari\",\n",
    "                \"mobil terbakar sendiri\",\n",
    "                \"kaca spion patah karena kecelakaan\",\n",
    "                \n",
    "                \"saya komplain tentang pelayanan bengkel\",\n",
    "                \"sangat kecewa dengan produk toyota ini\",\n",
    "                \"komplain untuk garansi yang ditolak\",\n",
    "                \"pelayanan customer service sangat buruk\",\n",
    "                \"minta refund untuk produk cacat\",\n",
    "                \"protes untuk biaya servis yang mahal\",\n",
    "                \"pengaduan untuk teknisi tidak profesional\",\n",
    "                \"kecewa dengan waiting time yang lama\",\n",
    "                \"komplain sparepart palsu yang dipasang\",\n",
    "                \"protes untuk janji tidak ditepati\",\n",
    "                \"saya marah dengan kualitas servis\",\n",
    "                \"komplain mobil baru langsung rusak\",\n",
    "                \"kecewa dengan respon yang lambat\",\n",
    "                \"minta ganti rugi untuk kerusakan\",\n",
    "                \"protes harga sparepart terlalu mahal\",\n",
    "                \"komplain untuk janji service tidak tepat waktu\",\n",
    "                \"sangat tidak puas dengan pelayanan\",\n",
    "                \"komplain mobil sering masuk bengkel\",\n",
    "                \"kecewa dengan kualitas cat mobil\",\n",
    "                \"protes untuk penanganan yang lamban\",\n",
    "                \"komplain untuk informasi yang misleading\",\n",
    "                \"saya keberatan dengan biaya tambahan\",\n",
    "                \"komplain untuk attitude staff yang kasar\",\n",
    "                \"kecewa dengan fitur yang tidak berfungsi\",\n",
    "                \"protes untuk kebijakan yang tidak jelas\",\n",
    "                \"komplain untuk janji telepon tidak ditepati\",\n",
    "                \"sangat marah dengan pelayanan after sales\",\n",
    "                \"komplain untuk sparepart tidak tersedia\",\n",
    "                \"kecewa dengan waktu tunggu yang panjang\",\n",
    "                \"protes untuk solusi yang tidak memuaskan\"\n",
    "            ],\n",
    "            'labels': ['normal'] * 30 + ['serious'] * 30 + ['complaint'] * 30\n",
    "        }\n",
    "        \n",
    "        return enhanced_data\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"Train model dengan enhanced approach\"\"\"\n",
    "        try:\n",
    "            print(\"ü§ñ Training Enhanced ML model...\")\n",
    "            print(f\"   Training samples: {len(X_train)}\")\n",
    "            print(f\"   Class distribution: {Counter(y_train)}\")\n",
    "            \n",
    "            # Fit vectorizer dan transform data\n",
    "            X_vec = self.vectorizer.fit_transform(X_train)\n",
    "            \n",
    "            # Train classifier\n",
    "            self.classifier.fit(X_vec, y_train)\n",
    "            self.is_trained = True\n",
    "            \n",
    "            # Calculate training accuracy\n",
    "            train_pred = self.classifier.predict(X_vec)\n",
    "            train_accuracy = accuracy_score(y_train, train_pred)\n",
    "            \n",
    "            # Save model\n",
    "            joblib.dump(self.vectorizer, f\"{config.MODEL_SAVE_PATH}/vectorizer.pkl\")\n",
    "            joblib.dump(self.classifier, f\"{config.MODEL_SAVE_PATH}/classifier.pkl\")\n",
    "            \n",
    "            print(f\"‚úÖ Model trained - Accuracy: {train_accuracy:.3f}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Training error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"Predict dengan hybrid approach\"\"\"\n",
    "        if not text or len(text.strip()) < 3:\n",
    "            return 'normal', 0.5\n",
    "        \n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Step 1: Try ML prediction jika model sudah trained\n",
    "        ml_prediction, ml_confidence = None, 0.0\n",
    "        if self.is_trained:\n",
    "            try:\n",
    "                X_vec = self.vectorizer.transform([text])\n",
    "                ml_prediction = self.classifier.predict(X_vec)[0]\n",
    "                ml_probs = self.classifier.predict_proba(X_vec)[0]\n",
    "                ml_confidence = np.max(ml_probs)\n",
    "                \n",
    "                # High confidence ML prediction\n",
    "                if ml_confidence >= self.high_confidence_threshold:\n",
    "                    return ml_prediction, ml_confidence\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è ML prediction failed: {e}\")\n",
    "        \n",
    "        # Step 2: Rule-based prediction\n",
    "        rule_prediction = self._rule_based_predict(text_lower)\n",
    "        rule_confidence = self._calculate_rule_confidence(text_lower, rule_prediction)\n",
    "        \n",
    "        # Step 3: Hybrid decision making\n",
    "        if self.is_trained and ml_prediction:\n",
    "            if ml_confidence >= self.medium_confidence_threshold:\n",
    "                if ml_prediction == rule_prediction:\n",
    "                    hybrid_confidence = (ml_confidence + rule_confidence) / 2\n",
    "                    return ml_prediction, hybrid_confidence\n",
    "                else:\n",
    "                    # Conflict - prefer rules untuk safety\n",
    "                    return rule_prediction, rule_confidence * 0.8\n",
    "            else:\n",
    "                return rule_prediction, rule_confidence\n",
    "        else:\n",
    "            return rule_prediction, rule_confidence\n",
    "    \n",
    "    def _rule_based_predict(self, text_lower):\n",
    "        \"\"\"Rule-based classification fallback\"\"\"\n",
    "        scores = {'normal': 0, 'serious': 0, 'complaint': 0}\n",
    "        \n",
    "        for category, keywords in self.rule_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in text_lower:\n",
    "                    if category == 'complaint':\n",
    "                        scores[category] += 3\n",
    "                    elif category == 'serious':\n",
    "                        scores[category] += 2\n",
    "                    else:\n",
    "                        scores[category] += 1\n",
    "        \n",
    "        max_score = max(scores.values())\n",
    "        if max_score == 0:\n",
    "            return 'normal'\n",
    "        \n",
    "        max_categories = [cat for cat, score in scores.items() if score == max_score]\n",
    "        if len(max_categories) > 1:\n",
    "            if 'serious' in max_categories:\n",
    "                return 'serious'\n",
    "            elif 'complaint' in max_categories:\n",
    "                return 'complaint'\n",
    "            else:\n",
    "                return 'normal'\n",
    "        \n",
    "        return max_categories[0]\n",
    "    \n",
    "    def _calculate_rule_confidence(self, text_lower, predicted_category):\n",
    "        \"\"\"Calculate confidence score untuk rule-based prediction\"\"\"\n",
    "        scores = {'normal': 0, 'serious': 0, 'complaint': 0}\n",
    "        total_weight = 0\n",
    "        \n",
    "        for category, keywords in self.rule_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in text_lower:\n",
    "                    weight = 3 if category == 'complaint' else (2 if category == 'serious' else 1)\n",
    "                    scores[category] += weight\n",
    "                    total_weight += weight\n",
    "        \n",
    "        if total_weight == 0:\n",
    "            return 0.5\n",
    "        \n",
    "        max_score = max(scores.values())\n",
    "        confidence = max_score / total_weight\n",
    "        \n",
    "        sorted_scores = sorted(scores.values(), reverse=True)\n",
    "        if len(sorted_scores) > 1 and sorted_scores[0] > sorted_scores[1] * 2:\n",
    "            confidence = min(confidence * 1.2, 0.95)\n",
    "        \n",
    "        return confidence\n",
    "    \n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        \"\"\"Evaluate model performance dengan detailed report\"\"\"\n",
    "        if not self.is_trained:\n",
    "            print(\"‚ùå Model not trained\")\n",
    "            return None\n",
    "        \n",
    "        X_vec = self.vectorizer.transform(X_test)\n",
    "        y_pred = self.classifier.predict(X_vec)\n",
    "        y_pred_proba = self.classifier.predict_proba(X_vec)\n",
    "        \n",
    "        print(\"üìä ENHANCED CLASSIFIER PERFORMANCE REPORT\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.3f}\")\n",
    "        print(f\"Test Samples: {len(X_test)}\")\n",
    "        print(f\"Class Distribution: {Counter(y_test)}\")\n",
    "        \n",
    "        print(\"\\nüìà Detailed Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=['normal', 'serious', 'complaint']))\n",
    "        \n",
    "        max_confidences = np.max(y_pred_proba, axis=1)\n",
    "        print(f\"\\nüéØ Confidence Analysis:\")\n",
    "        print(f\"   Average Confidence: {np.mean(max_confidences):.3f}\")\n",
    "        print(f\"   High Confidence (>0.7): {np.sum(max_confidences > 0.7)}/{len(max_confidences)}\")\n",
    "        print(f\"   Low Confidence (<0.5): {np.sum(max_confidences < 0.5)}/{len(max_confidences)}\")\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['normal', 'serious', 'complaint'],\n",
    "                   yticklabels=['normal', 'serious', 'complaint'])\n",
    "        plt.title('Confusion Matrix - Enhanced Classifier')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Feature importance\n",
    "        self._show_feature_importance()\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def _show_feature_importance(self, top_n=15):\n",
    "        \"\"\"Show most important features untuk setiap class\"\"\"\n",
    "        if not self.is_trained:\n",
    "            return\n",
    "        \n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "        print(f\"\\nüîç Top {top_n} Features per Class:\")\n",
    "        \n",
    "        for i, class_name in enumerate(['normal', 'serious', 'complaint']):\n",
    "            coef = self.classifier.coef_[i]\n",
    "            top_indices = np.argsort(coef)[-top_n:][::-1]\n",
    "            top_features = [(feature_names[idx], coef[idx]) for idx in top_indices]\n",
    "            \n",
    "            print(f\"\\n{class_name.upper()}:\")\n",
    "            for feature, score in top_features:\n",
    "                print(f\"   {feature}: {score:.3f}\")\n",
    "\n",
    "# Initialize enhanced classifier\n",
    "classifier = HybridClassifier()\n",
    "\n",
    "# Test dengan enhanced classifier\n",
    "print(\"üß™ TESTING ENHANCED CLASSIFIER\")\n",
    "\n",
    "test_samples = [\n",
    "    \"mobil saya error tidak bisa starter, mogok di jalan\",\n",
    "    \"saya komplain tentang pelayanan bengkel yang sangat buruk\",\n",
    "    \"mau tanya harga toyota avanza berapa?\",\n",
    "    \"aplikasi error terus tidak bisa login sudah 3 hari\",\n",
    "    \"saya kecewa dengan produk ini, minta refund\",\n",
    "    \"bagaimana cara aktivasi fitur t-intouch?\",\n",
    "    \"mesin bunyi aneh ada masalah serius\",\n",
    "    \"info promo terbaru untuk innova zenix\"\n",
    "]\n",
    "\n",
    "print(\"\\nüîç Enhanced Prediction Results:\")\n",
    "for text in test_samples:\n",
    "    prediction, confidence = classifier.predict(text)\n",
    "    print(f\"   '{text[:40]}...' ‚Üí {prediction} (conf: {confidence:.2f})\")\n",
    "\n",
    "# Create ENHANCED training data\n",
    "print(\"\\nü§ñ CREATING ENHANCED TRAINING DATA...\")\n",
    "enhanced_data = classifier.create_enhanced_training_data()\n",
    "\n",
    "# Split data dengan lebih banyak samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    enhanced_data['texts'], \n",
    "    enhanced_data['labels'],\n",
    "    test_size=0.2,  # 20% test size\n",
    "    random_state=config.RANDOM_STATE,\n",
    "    stratify=enhanced_data['labels']\n",
    ")\n",
    "\n",
    "print(f\"üìä Enhanced Training Data: {len(X_train)} samples\")\n",
    "print(f\"üìä Enhanced Test Data: {len(X_test)} samples\")\n",
    "print(f\"üìä Class Distribution - Train: {Counter(y_train)}\")\n",
    "print(f\"üìä Class Distribution - Test: {Counter(y_test)}\")\n",
    "\n",
    "# Train the enhanced model\n",
    "success = classifier.train(X_train, y_train)\n",
    "\n",
    "if success:\n",
    "    # Evaluate enhanced model\n",
    "    accuracy = classifier.evaluate_model(X_test, y_test)\n",
    "    \n",
    "    print(f\"\\n‚úÖ ENHANCED HYBRID CLASSIFIER READY!\")\n",
    "    print(f\"   Model Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"   Training Samples: {len(X_train)}\")\n",
    "    print(f\"   Test Samples: {len(X_test)}\")\n",
    "    print(f\"   Rule-based Fallback: Active\")\n",
    "else:\n",
    "    print(\"‚ùå Enhanced model training failed, using rule-based only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d35453",
   "metadata": {},
   "source": [
    "Reply Analyzer & Lead Time Calculator (WITH BERT INTEGRATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5a3b546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PROPERLY FIXED Reply Analyzer & Lead Time Calculator Ready!\n",
      "============================================================\n",
      "   üîç Analyzing 27 messages for conversation start...\n",
      "   ‚úÖ Conversation start: operator greeting at position 12\n",
      "   üìù Analyzing 14 meaningful messages\n",
      "   üîÑ Sorted messages by timestamp\n",
      "   üîç Found missing answer for question 1\n",
      "   üîç Found missing answer for question 2\n",
      "   ‚úÖ Found 6 Q-A pairs (6 answered)\n",
      "   üîç Message sequence (first 5):\n",
      "      0: 2025-11-01 08:01:08.772000 | operator        | Selamat pagi Ibu Grace. Selamat datang di layanan ...\n",
      "      1: 2025-11-01 08:02:03.082000 | customer        | Saya mau tanya harga filter solar untuk vrz 2016\n",
      "      2: 2025-11-01 08:02:21.789000 | customer        | filter bahan bakar beda dgn filter oli\n",
      "      3: 2025-11-01 08:02:49.326000 | operator        | Baik, Ibu Grace.\n",
      "      4: 2025-11-01 08:02:57.943000 | customer        | Kalau filter bahan bakar tsb brp lama harus di gan...\n",
      "üß™ TESTING PROPERLY FIXED REPLY ANALYSIS:\n",
      "   Main Issue Type: normal\n",
      "   Main Question: Saya mau tanya harga filter solar untuk vrz 2016...\n",
      "üîç Analyzing replies for normal issue...\n",
      "\n",
      "üìä PROPERLY FIXED REPLY ANALYSIS RESULTS:\n",
      "   First Reply Found: False\n",
      "   Final Reply Found: True\n",
      "   Quality Rating: good\n",
      "   Quality Score: 4\n",
      "   Recommendation: Replies adequate\n",
      "\n",
      "‚è±Ô∏è LEAD TIMES:\n",
      "   final_reply_lead_time_minutes: 1.8\n",
      "   conversation_duration_minutes: 7.9\n",
      "\n",
      "üéØ THRESHOLD CHECKS:\n",
      "   normal_threshold_exceeded: ‚úÖ WITHIN LIMIT (N/Am vs N/Am)\n",
      "\n",
      "üìà PERFORMANCE ANALYSIS:\n",
      "   Performance Rating: EXCELLENT\n",
      "   Response Efficiency: EXCELLENT\n",
      "   Resolution Efficiency: UNKNOWN\n",
      "\n",
      "‚≠ê QUALITY ASSESSMENT:\n",
      "   First Reply Quality: UNKNOWN\n",
      "   Final Reply Quality: GOOD\n",
      "   Overall Quality: POOR\n",
      "\n",
      "üéØ FINAL REPLY:\n",
      "   Time: 0.89 minutes\n",
      "   Type: final_proper\n",
      "   Message: Baik, Ibu Grace. Terkait harga suku cadang, merupakan kebijakan dari masing-masing cabang bengkel re...\n"
     ]
    }
   ],
   "source": [
    "# Reply Analyzer & Lead Time Calculator dengan Enhanced Analysis\n",
    "class ReplyAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.first_reply_indicators = [\n",
    "            'cek', 'kami teruskan', 'kami diskusikan', 'kami cek dulu', \n",
    "            'tunggu sebentar', 'mohon ditunggu', 'akan kami proses',\n",
    "            'mohon maaf', 'maaf', 'sangat disayangkan', 'kami turut prihatin',\n",
    "            'bisa diinformasikan', 'bisa dibagikan', 'mohon konfirmasi',\n",
    "            'bisa dikonfirmasi', 'tolong informasikan', 'sebentar ya',\n",
    "            'pengecekan', 'verifikasi', 'proses', 'kami bantu'\n",
    "        ]\n",
    "        \n",
    "        self.final_reply_indicators = [\n",
    "            'bisa menghubungi', 'silakan menghubungi', 'disarankan untuk',\n",
    "            'berikut informasi', 'nomor telepon', 'alamat dealer', \n",
    "            'bengkel resmi', 'jawabannya adalah', 'solusinya', 'bisa dilakukan',\n",
    "            'prosedurnya', 'caranya', 'merupakan', 'adalah', 'fitur',\n",
    "            'call center', 'hotline', 'customer service', 'info lengkap',\n",
    "            'cara mengaktifkan', 'langkah-langkah', 'penjelasan tentang',\n",
    "            'harga mulai', 'biaya required', 'tarif berlaku', 'jam operasional',\n",
    "            'alamat lengkap', 'syarat dan ketentuan', 'spesifikasi', 'fungsi',\n",
    "            'harga', 'biaya', 'tarif', 'promo', 'diskon', 'cara booking'\n",
    "        ]\n",
    "        \n",
    "        self.conversation_enders = [\n",
    "            'terima kasih', 'thanks', 'makasih', 'tks', 'sampai jumpa',\n",
    "            'semoga membantu', 'apakah sudah jelas', 'apakah cukup',\n",
    "            'apakah membantu', 'selamat', 'silahkan', 'sampai bertemu',\n",
    "            'goodbye', 'bye', 'dadah', 'apakah ada hal lain'\n",
    "        ]\n",
    "        \n",
    "        self.generic_reply_patterns = [\n",
    "            'terima kasih telah menghubungi',\n",
    "            'silakan memilih dari menu',\n",
    "            'virtual assistant', \n",
    "            'akan segera menghubungi',\n",
    "            'dalam antrian',\n",
    "            'tunggu sebentar',\n",
    "            'terima kasih, saat ini anda masuk',\n",
    "            'customer service akan',\n",
    "            'menghubungi anda',\n",
    "            'apa lagi yang bisa dibantu',\n",
    "            'ada yang bisa dibantu'\n",
    "        ]\n",
    "        \n",
    "        # Time thresholds (dalam menit)\n",
    "        self.time_thresholds = {\n",
    "            'normal_final': 5,           # 5 menit untuk normal\n",
    "            'serious_first': 5,          # 5 menit first reply serious\n",
    "            'serious_final': 480,        # 8 jam final reply serious  \n",
    "            'complaint_first': 5,        # 5 menit first reply complaint\n",
    "            'complaint_final': 7200      # 5 hari final reply complaint\n",
    "        }\n",
    "    \n",
    "    def analyze_replies(self, qa_pairs, main_issue_type):\n",
    "        \"\"\"Analyze replies berdasarkan issue type dan Q-A pairs - IMPROVED\"\"\"\n",
    "        if not qa_pairs:\n",
    "            return None, None, self._create_empty_analysis(main_issue_type)\n",
    "        \n",
    "        print(f\"üîç Analyzing replies for {main_issue_type} issue...\")\n",
    "        \n",
    "        # Cari first reply (untuk serious/complaint) dan final reply yang BENERAN meaningful\n",
    "        first_reply = None\n",
    "        final_reply = None\n",
    "        \n",
    "        if main_issue_type in ['serious', 'complaint']:\n",
    "            first_reply = self._find_proper_first_reply(qa_pairs)\n",
    "        \n",
    "        final_reply = self._find_proper_final_reply(qa_pairs, main_issue_type)\n",
    "        \n",
    "        # Jika final reply tidak ditemukan, cari yang paling mendekati\n",
    "        if not final_reply:\n",
    "            final_reply = self._find_best_final_reply_candidate(qa_pairs)\n",
    "        \n",
    "        # Calculate lead times\n",
    "        lead_times = self._calculate_lead_times(qa_pairs, first_reply, final_reply, main_issue_type)\n",
    "        \n",
    "        # Validate replies\n",
    "        reply_validation = self._validate_replies(first_reply, final_reply, main_issue_type)\n",
    "        \n",
    "        # Performance analysis\n",
    "        performance_analysis = self._analyze_performance(lead_times, main_issue_type)\n",
    "        \n",
    "        analysis_result = {\n",
    "            'issue_type': main_issue_type,\n",
    "            'first_reply': first_reply,\n",
    "            'final_reply': final_reply,\n",
    "            'lead_times': lead_times,\n",
    "            'reply_validation': reply_validation,\n",
    "            'performance_analysis': performance_analysis,\n",
    "            'threshold_checks': self._check_thresholds(lead_times, main_issue_type),\n",
    "            'quality_assessment': self._assess_quality(first_reply, final_reply, main_issue_type)\n",
    "        }\n",
    "        \n",
    "        return first_reply, final_reply, analysis_result\n",
    "    \n",
    "    def _find_proper_first_reply(self, qa_pairs):\n",
    "        \"\"\"Temukan first reply yang meaningful untuk serious/complaint\"\"\"\n",
    "        for pair in qa_pairs:\n",
    "            if pair['is_answered']:\n",
    "                answer = pair['answer']\n",
    "                \n",
    "                # Skip generic replies dan conversation enders\n",
    "                if self._is_generic_reply(answer) or self._is_conversation_ender(answer):\n",
    "                    continue\n",
    "                \n",
    "                # Cek first reply indicators\n",
    "                if any(indicator in answer.lower() for indicator in self.first_reply_indicators):\n",
    "                    return self._create_reply_object(pair, 'first_proper')\n",
    "                \n",
    "                # Atau ambil jawaban pertama yang cukup panjang dan mengandung action\n",
    "                if len(answer.split()) > 6 and self._contains_action_words(answer):\n",
    "                    return self._create_reply_object(pair, 'first_action')\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _find_proper_final_reply(self, qa_pairs, issue_type):\n",
    "        \"\"\"Temukan final reply yang BENERAN menjawab masalah\"\"\"\n",
    "        meaningful_replies = []\n",
    "        \n",
    "        for pair in qa_pairs:\n",
    "            if pair['is_answered']:\n",
    "                answer = pair['answer']\n",
    "                \n",
    "                # SKIP yang jelas-jelas bukan final answer\n",
    "                if (self._is_generic_reply(answer) or \n",
    "                    self._is_conversation_ender(answer) or\n",
    "                    self._is_first_reply_type(answer)):\n",
    "                    continue\n",
    "                \n",
    "                # Score berdasarkan seberapa \"final\" reply ini\n",
    "                score = 0\n",
    "                \n",
    "                # Bonus untuk final reply indicators\n",
    "                if any(indicator in answer.lower() for indicator in self.final_reply_indicators):\n",
    "                    score += 3\n",
    "                \n",
    "                # Bonus untuk panjang content (lebih comprehensive)\n",
    "                word_count = len(answer.split())\n",
    "                if word_count > 10:\n",
    "                    score += 2\n",
    "                elif word_count > 5:\n",
    "                    score += 1\n",
    "                \n",
    "                # Bonus untuk mengandung informasi spesifik\n",
    "                if any(keyword in answer.lower() for keyword in ['nomor', 'alamat', 'harga', 'biaya', 'caranya', 'solusi']):\n",
    "                    score += 2\n",
    "                \n",
    "                # Penalty untuk yang terlalu awal di conversation\n",
    "                position_penalty = max(0, (len(qa_pairs) - pair.get('position', 0)) / len(qa_pairs) * 2)\n",
    "                score += position_penalty\n",
    "                \n",
    "                if score > 0:\n",
    "                    meaningful_replies.append({\n",
    "                        'pair': pair,\n",
    "                        'score': score,\n",
    "                        'position': pair.get('position', 0),\n",
    "                        'word_count': word_count\n",
    "                    })\n",
    "        \n",
    "        if meaningful_replies:\n",
    "            # Pilih reply dengan score tertinggi\n",
    "            best_reply = max(meaningful_replies, key=lambda x: x['score'])\n",
    "            return self._create_reply_object(best_reply['pair'], 'final_proper')\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _find_best_final_reply_candidate(self, qa_pairs):\n",
    "        \"\"\"Fallback: cari candidate terbaik untuk final reply\"\"\"\n",
    "        candidates = []\n",
    "        \n",
    "        for pair in qa_pairs:\n",
    "            if pair['is_answered']:\n",
    "                answer = pair['answer']\n",
    "                \n",
    "                # Skip yang jelas bukan final answer\n",
    "                if self._is_conversation_ender(answer) or self._is_generic_reply(answer):\n",
    "                    continue\n",
    "                \n",
    "                # Score candidate\n",
    "                score = len(answer.split())  # Basic score berdasarkan length\n",
    "                \n",
    "                if any(keyword in answer.lower() for keyword in ['bisa', 'dapat', 'silakan', 'silahkan']):\n",
    "                    score += 2\n",
    "                \n",
    "                candidates.append({\n",
    "                    'pair': pair,\n",
    "                    'score': score\n",
    "                })\n",
    "        \n",
    "        if candidates:\n",
    "            best_candidate = max(candidates, key=lambda x: x['score'])\n",
    "            return self._create_reply_object(best_candidate['pair'], 'final_fallback')\n",
    "        \n",
    "        # Last resort: ambil jawaban terakhir yang bukan ender\n",
    "        for pair in reversed(qa_pairs):\n",
    "            if pair['is_answered'] and not self._is_conversation_ender(pair['answer']):\n",
    "                return self._create_reply_object(pair, 'final_last_resort')\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _contains_action_words(self, message):\n",
    "        \"\"\"Cek apakah message mengandung action words\"\"\"\n",
    "        action_words = ['cek', 'proses', 'bantu', 'informasi', 'jelas', 'solusi', 'caranya']\n",
    "        return any(word in message.lower() for word in action_words)\n",
    "    \n",
    "    def _is_first_reply_type(self, message):\n",
    "        \"\"\"Cek apakah message lebih cocok sebagai first reply\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        first_reply_words = ['tunggu', 'sebentar', 'cek', 'proses', 'maaf']\n",
    "        return any(word in message_lower for word in first_reply_words) and len(message_lower.split()) < 10\n",
    "    \n",
    "    def _is_conversation_ender(self, message):\n",
    "        \"\"\"Cek apakah message adalah penutup conversation\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        return any(ender in message_lower for ender in self.conversation_enders)\n",
    "    \n",
    "    def _create_reply_object(self, pair, reply_type):\n",
    "        \"\"\"Create standardized reply object\"\"\"\n",
    "        return {\n",
    "            'message': pair['answer'],\n",
    "            'timestamp': pair['answer_time'],\n",
    "            'role': pair['answer_role'],\n",
    "            'reply_type': reply_type,\n",
    "            'lead_time_seconds': pair.get('lead_time_seconds'),\n",
    "            'lead_time_minutes': pair.get('lead_time_minutes'),\n",
    "            'lead_time_hhmmss': pair.get('lead_time_hhmmss'),\n",
    "            'question': pair['question'],\n",
    "            'question_time': pair['question_time'],\n",
    "            'pair_position': pair.get('position', 0)\n",
    "        }\n",
    "    \n",
    "    def _calculate_lead_times(self, qa_pairs, first_reply, final_reply, issue_type):\n",
    "        \"\"\"Hitung semua lead times yang relevan - IMPROVED\"\"\"\n",
    "        lead_times = {}\n",
    "        \n",
    "        if not qa_pairs or not qa_pairs[0]['is_answered']:\n",
    "            return lead_times\n",
    "        \n",
    "        main_question_time = qa_pairs[0]['question_time']\n",
    "        \n",
    "        # Lead time ke first reply (untuk serious/complaint)\n",
    "        if first_reply and first_reply['timestamp']:\n",
    "            lead_times['first_reply_lead_time_seconds'] = (\n",
    "                first_reply['timestamp'] - main_question_time\n",
    "            ).total_seconds()\n",
    "            lead_times['first_reply_lead_time_minutes'] = round(\n",
    "                lead_times['first_reply_lead_time_seconds'] / 60, 2\n",
    "            )\n",
    "            lead_times['first_reply_lead_time_hhmmss'] = self._seconds_to_hhmmss(\n",
    "                lead_times['first_reply_lead_time_seconds']\n",
    "            )\n",
    "        \n",
    "        # Lead time ke final reply\n",
    "        if final_reply and final_reply['timestamp']:\n",
    "            lead_times['final_reply_lead_time_seconds'] = (\n",
    "                final_reply['timestamp'] - main_question_time\n",
    "            ).total_seconds()\n",
    "            lead_times['final_reply_lead_time_minutes'] = round(\n",
    "                lead_times['final_reply_lead_time_seconds'] / 60, 2\n",
    "            )\n",
    "            lead_times['final_reply_lead_time_hhmmss'] = self._seconds_to_hhmmss(\n",
    "                lead_times['final_reply_lead_time_seconds']\n",
    "            )\n",
    "        \n",
    "        # Conversation duration (first to last message)\n",
    "        if len(qa_pairs) > 1:\n",
    "            first_time = qa_pairs[0]['question_time']\n",
    "            last_time = qa_pairs[-1]['answer_time'] if qa_pairs[-1]['is_answered'] else qa_pairs[-1]['question_time']\n",
    "            \n",
    "            lead_times['conversation_duration_seconds'] = (last_time - first_time).total_seconds()\n",
    "            lead_times['conversation_duration_minutes'] = round(\n",
    "                lead_times['conversation_duration_seconds'] / 60, 2\n",
    "            )\n",
    "        \n",
    "        return lead_times\n",
    "    \n",
    "    def _check_thresholds(self, lead_times, issue_type):\n",
    "        \"\"\"Check jika lead time melebihi threshold\"\"\"\n",
    "        checks = {}\n",
    "        \n",
    "        if issue_type == 'normal':\n",
    "            if 'final_reply_lead_time_minutes' in lead_times:\n",
    "                checks['normal_threshold_exceeded'] = (\n",
    "                    lead_times['final_reply_lead_time_minutes'] > self.time_thresholds['normal_final']\n",
    "                )\n",
    "                checks['normal_threshold_minutes'] = self.time_thresholds['normal_final']\n",
    "                checks['actual_minutes'] = lead_times['final_reply_lead_time_minutes']\n",
    "        \n",
    "        elif issue_type == 'serious':\n",
    "            if 'first_reply_lead_time_minutes' in lead_times:\n",
    "                checks['serious_first_threshold_exceeded'] = (\n",
    "                    lead_times['first_reply_lead_time_minutes'] > self.time_thresholds['serious_first']\n",
    "                )\n",
    "                checks['serious_first_threshold_minutes'] = self.time_thresholds['serious_first']\n",
    "                checks['serious_first_actual_minutes'] = lead_times['first_reply_lead_time_minutes']\n",
    "            \n",
    "            if 'final_reply_lead_time_minutes' in lead_times:\n",
    "                checks['serious_final_threshold_exceeded'] = (\n",
    "                    lead_times['final_reply_lead_time_minutes'] > self.time_thresholds['serious_final']\n",
    "                )\n",
    "                checks['serious_final_threshold_minutes'] = self.time_thresholds['serious_final']\n",
    "                checks['serious_final_actual_minutes'] = lead_times['final_reply_lead_time_minutes']\n",
    "        \n",
    "        elif issue_type == 'complaint':\n",
    "            if 'first_reply_lead_time_minutes' in lead_times:\n",
    "                checks['complaint_first_threshold_exceeded'] = (\n",
    "                    lead_times['first_reply_lead_time_minutes'] > self.time_thresholds['complaint_first']\n",
    "                )\n",
    "                checks['complaint_first_threshold_minutes'] = self.time_thresholds['complaint_first']\n",
    "                checks['complaint_first_actual_minutes'] = lead_times['first_reply_lead_time_minutes']\n",
    "            \n",
    "            if 'final_reply_lead_time_minutes' in lead_times:\n",
    "                checks['complaint_final_threshold_exceeded'] = (\n",
    "                    lead_times['final_reply_lead_time_minutes'] > self.time_thresholds['complaint_final']\n",
    "                )\n",
    "                checks['complaint_final_threshold_minutes'] = self.time_thresholds['complaint_final']\n",
    "                checks['complaint_final_actual_minutes'] = lead_times['final_reply_lead_time_minutes']\n",
    "        \n",
    "        return checks\n",
    "    \n",
    "    def _validate_replies(self, first_reply, final_reply, issue_type):\n",
    "        \"\"\"Validasi kualitas dan kelengkapan replies\"\"\"\n",
    "        validation = {\n",
    "            'first_reply_found': first_reply is not None,\n",
    "            'final_reply_found': final_reply is not None,\n",
    "            'recommendation': '',\n",
    "            'missing_elements': [],\n",
    "            'quality_score': 0,\n",
    "            'quality_rating': 'poor'\n",
    "        }\n",
    "        \n",
    "        # Check untuk serious/complaint issues\n",
    "        if issue_type in ['serious', 'complaint']:\n",
    "            if not first_reply:\n",
    "                validation['missing_elements'].append('first_reply')\n",
    "                validation['recommendation'] = 'First reply missing for serious/complaint issue'\n",
    "            elif not self._has_empathy(first_reply['message']):\n",
    "                validation['missing_elements'].append('empathy_in_first_reply')\n",
    "        \n",
    "        if not final_reply:\n",
    "            validation['missing_elements'].append('final_reply')\n",
    "            if validation['recommendation']:\n",
    "                validation['recommendation'] += ' + Final reply missing'\n",
    "            else:\n",
    "                validation['recommendation'] = 'Final reply missing'\n",
    "        elif self._is_conversation_ender(final_reply['message']):\n",
    "            validation['missing_elements'].append('meaningful_final_reply')\n",
    "            validation['recommendation'] = 'Final reply is just conversation ender, not meaningful answer'\n",
    "        \n",
    "        # Calculate quality score\n",
    "        score = 0\n",
    "        if first_reply:\n",
    "            score += 2\n",
    "            if self._has_empathy(first_reply['message']):\n",
    "                score += 1\n",
    "        if final_reply:\n",
    "            score += 2\n",
    "            if self._has_solution(final_reply['message']) and not self._is_conversation_ender(final_reply['message']):\n",
    "                score += 2\n",
    "            elif self._has_solution(final_reply['message']):\n",
    "                score += 1\n",
    "        \n",
    "        validation['quality_score'] = score\n",
    "        validation['quality_rating'] = self._get_quality_rating(score)\n",
    "        \n",
    "        if not validation['recommendation'] and score >= 4:\n",
    "            validation['recommendation'] = 'Replies adequate'\n",
    "        elif not validation['recommendation']:\n",
    "            validation['recommendation'] = 'Reply quality needs improvement'\n",
    "        \n",
    "        return validation\n",
    "    \n",
    "    def _analyze_performance(self, lead_times, issue_type):\n",
    "        \"\"\"Analisis performance berdasarkan lead times\"\"\"\n",
    "        performance = {\n",
    "            'issue_type': issue_type,\n",
    "            'performance_rating': 'unknown',\n",
    "            'response_efficiency': 'unknown',\n",
    "            'resolution_efficiency': 'unknown'\n",
    "        }\n",
    "        \n",
    "        if issue_type == 'normal' and 'final_reply_lead_time_minutes' in lead_times:\n",
    "            lt = lead_times['final_reply_lead_time_minutes']\n",
    "            if lt <= 2:\n",
    "                performance.update({'performance_rating': 'excellent', 'response_efficiency': 'excellent'})\n",
    "            elif lt <= 5:\n",
    "                performance.update({'performance_rating': 'good', 'response_efficiency': 'good'})\n",
    "            elif lt <= 10:\n",
    "                performance.update({'performance_rating': 'fair', 'response_efficiency': 'fair'})\n",
    "            else:\n",
    "                performance.update({'performance_rating': 'poor', 'response_efficiency': 'poor'})\n",
    "        \n",
    "        elif issue_type in ['serious', 'complaint']:\n",
    "            # Evaluate first response\n",
    "            if 'first_reply_lead_time_minutes' in lead_times:\n",
    "                lt_first = lead_times['first_reply_lead_time_minutes']\n",
    "                if lt_first <= 2:\n",
    "                    performance['response_efficiency'] = 'excellent'\n",
    "                elif lt_first <= 5:\n",
    "                    performance['response_efficiency'] = 'good'\n",
    "                elif lt_first <= 10:\n",
    "                    performance['response_efficiency'] = 'fair'\n",
    "                else:\n",
    "                    performance['response_efficiency'] = 'poor'\n",
    "            \n",
    "            # Evaluate final resolution\n",
    "            if 'final_reply_lead_time_minutes' in lead_times:\n",
    "                lt_final = lead_times['final_reply_lead_time_minutes']\n",
    "                max_threshold = self.time_thresholds['serious_final'] if issue_type == 'serious' else self.time_thresholds['complaint_final']\n",
    "                \n",
    "                if lt_final <= max_threshold * 0.3:  # Within 30% of threshold\n",
    "                    performance['resolution_efficiency'] = 'excellent'\n",
    "                elif lt_final <= max_threshold * 0.6:  # Within 60% of threshold\n",
    "                    performance['resolution_efficiency'] = 'good'\n",
    "                elif lt_final <= max_threshold:  # Within threshold\n",
    "                    performance['resolution_efficiency'] = 'fair'\n",
    "                else:\n",
    "                    performance['resolution_efficiency'] = 'poor'\n",
    "            \n",
    "            # Overall rating\n",
    "            if performance['response_efficiency'] in ['excellent', 'good'] and performance['resolution_efficiency'] in ['excellent', 'good']:\n",
    "                performance['performance_rating'] = 'excellent'\n",
    "            elif performance['response_efficiency'] in ['excellent', 'good', 'fair'] and performance['resolution_efficiency'] in ['excellent', 'good', 'fair']:\n",
    "                performance['performance_rating'] = 'good'\n",
    "            else:\n",
    "                performance['performance_rating'] = 'poor'\n",
    "        \n",
    "        return performance\n",
    "    \n",
    "    def _assess_quality(self, first_reply, final_reply, issue_type):\n",
    "        \"\"\"Assess kualitas replies\"\"\"\n",
    "        quality = {\n",
    "            'first_reply_quality': 'unknown',\n",
    "            'final_reply_quality': 'unknown',\n",
    "            'overall_quality': 'unknown'\n",
    "        }\n",
    "        \n",
    "        if first_reply:\n",
    "            quality['first_reply_quality'] = self._assess_reply_quality(first_reply['message'], 'first', issue_type)\n",
    "        \n",
    "        if final_reply:\n",
    "            quality['final_reply_quality'] = self._assess_reply_quality(final_reply['message'], 'final', issue_type)\n",
    "        \n",
    "        # Overall quality\n",
    "        if (quality['first_reply_quality'] in ['excellent', 'good'] and \n",
    "            quality['final_reply_quality'] in ['excellent', 'good'] and\n",
    "            final_reply and not self._is_conversation_ender(final_reply['message'])):\n",
    "            quality['overall_quality'] = 'excellent'\n",
    "        elif (quality['first_reply_quality'] in ['excellent', 'good', 'fair'] and \n",
    "              quality['final_reply_quality'] in ['excellent', 'good', 'fair']):\n",
    "            quality['overall_quality'] = 'good'\n",
    "        else:\n",
    "            quality['overall_quality'] = 'poor'\n",
    "        \n",
    "        return quality\n",
    "    \n",
    "    def _assess_reply_quality(self, message, reply_type, issue_type):\n",
    "        \"\"\"Assess kualitas individual reply\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        \n",
    "        if reply_type == 'first':\n",
    "            # First reply assessment\n",
    "            empathy_indicators = ['mohon maaf', 'maaf', 'turut prihatin', 'sangat disayangkan', 'kami turut merasakan']\n",
    "            action_indicators = ['kami cek', 'kami proses', 'akan kami', 'pengecekan', 'verifikasi', 'kami bantu']\n",
    "            \n",
    "            empathy_score = sum(1 for indicator in empathy_indicators if indicator in message_lower)\n",
    "            action_score = sum(1 for indicator in action_indicators if indicator in message_lower)\n",
    "            \n",
    "            if empathy_score >= 1 and action_score >= 1:\n",
    "                return 'excellent'\n",
    "            elif empathy_score >= 1 or action_score >= 1:\n",
    "                return 'good'\n",
    "            else:\n",
    "                return 'fair'\n",
    "        \n",
    "        else:  # final reply\n",
    "            # Skip jika cuma conversation ender\n",
    "            if self._is_conversation_ender(message):\n",
    "                return 'poor'\n",
    "                \n",
    "            # Final reply assessment\n",
    "            solution_indicators = ['solusi', 'jawaban', 'caranya', 'prosedur', 'bisa menghubungi', 'silakan menghubungi', 'disarankan']\n",
    "            information_indicators = ['berikut', 'informasi', 'nomor', 'alamat', 'jam', 'kontak', 'harga', 'biaya', 'caranya']\n",
    "            \n",
    "            solution_score = sum(1 for indicator in solution_indicators if indicator in message_lower)\n",
    "            information_score = sum(1 for indicator in information_indicators if indicator in message_lower)\n",
    "            \n",
    "            if solution_score >= 1 and information_score >= 2:\n",
    "                return 'excellent'\n",
    "            elif solution_score >= 1 or information_score >= 1:\n",
    "                return 'good'\n",
    "            else:\n",
    "                return 'fair'\n",
    "    \n",
    "    def _has_empathy(self, message):\n",
    "        \"\"\"Cek apakah reply mengandung empathy\"\"\"\n",
    "        empathy_indicators = ['mohon maaf', 'maaf', 'turut prihatin', 'sangat disayangkan', 'kami turut merasakan']\n",
    "        return any(indicator in message.lower() for indicator in empathy_indicators)\n",
    "    \n",
    "    def _has_solution(self, message):\n",
    "        \"\"\"Cek apakah reply mengandung solusi\"\"\"\n",
    "        solution_indicators = ['solusi', 'jawaban', 'caranya', 'prosedur', 'bisa menghubungi', 'silakan menghubungi', 'bisa', 'dapat']\n",
    "        return any(indicator in message.lower() for indicator in solution_indicators)\n",
    "    \n",
    "    def _is_generic_reply(self, message):\n",
    "        \"\"\"Cek apakah reply generic/template\"\"\"\n",
    "        message_lower = message.lower()\n",
    "        return any(pattern in message_lower for pattern in self.generic_reply_patterns)\n",
    "    \n",
    "    def _get_quality_rating(self, score):\n",
    "        \"\"\"Convert quality score ke rating\"\"\"\n",
    "        if score >= 5:\n",
    "            return 'excellent'\n",
    "        elif score >= 3:\n",
    "            return 'good'\n",
    "        elif score >= 1:\n",
    "            return 'fair'\n",
    "        else:\n",
    "            return 'poor'\n",
    "    \n",
    "    def _create_empty_analysis(self, issue_type):\n",
    "        \"\"\"Create empty analysis result\"\"\"\n",
    "        return {\n",
    "            'issue_type': issue_type,\n",
    "            'lead_times': {},\n",
    "            'reply_validation': {\n",
    "                'first_reply_found': False,\n",
    "                'final_reply_found': False,\n",
    "                'recommendation': 'No replies analyzed',\n",
    "                'missing_elements': ['first_reply', 'final_reply'],\n",
    "                'quality_score': 0,\n",
    "                'quality_rating': 'poor'\n",
    "            },\n",
    "            'performance_analysis': {\n",
    "                'issue_type': issue_type,\n",
    "                'performance_rating': 'unknown',\n",
    "                'response_efficiency': 'unknown',\n",
    "                'resolution_efficiency': 'unknown'\n",
    "            },\n",
    "            'threshold_checks': {},\n",
    "            'quality_assessment': {\n",
    "                'first_reply_quality': 'unknown',\n",
    "                'final_reply_quality': 'unknown',\n",
    "                'overall_quality': 'poor'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _seconds_to_hhmmss(self, seconds):\n",
    "        \"\"\"Convert seconds to HH:MM:SS format\"\"\"\n",
    "        try:\n",
    "            hours = int(seconds // 3600)\n",
    "            minutes = int((seconds % 3600) // 60)\n",
    "            seconds = int(seconds % 60)\n",
    "            return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "        except:\n",
    "            return \"00:00:00\"\n",
    "\n",
    "# InitializeReply Analyzer\n",
    "reply_analyzer = ReplyAnalyzer()\n",
    "\n",
    "print(\"‚úÖ PROPERLY FIXED Reply Analyzer & Lead Time Calculator Ready!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test dengan sample data\n",
    "if 'parser' in locals() and 'detector' in locals() and raw_df is not None:\n",
    "    sample_ticket_id = 'ead8d44e4914399b76af974a5169856e'\n",
    "    ticket_df = raw_df[raw_df['Ticket Number'] == sample_ticket_id]\n",
    "    qa_pairs = parser.parse_conversation(ticket_df)\n",
    "    \n",
    "    if qa_pairs:\n",
    "        print(\"üß™ TESTING PROPERLY FIXED REPLY ANALYSIS:\")\n",
    "        \n",
    "        # Detect main issue\n",
    "        main_issue = detector.detect_main_issue(qa_pairs)\n",
    "        issue_type = main_issue['issue_type']\n",
    "        \n",
    "        print(f\"   Main Issue Type: {issue_type}\")\n",
    "        print(f\"   Main Question: {main_issue['question'][:80]}...\")\n",
    "        \n",
    "        # Analyze replies dengan fixed version\n",
    "        first_reply, final_reply, analysis = reply_analyzer.analyze_replies(qa_pairs, issue_type)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nüìä PROPERLY FIXED REPLY ANALYSIS RESULTS:\")\n",
    "        print(f\"   First Reply Found: {analysis['reply_validation']['first_reply_found']}\")\n",
    "        print(f\"   Final Reply Found: {analysis['reply_validation']['final_reply_found']}\")\n",
    "        print(f\"   Quality Rating: {analysis['reply_validation']['quality_rating']}\")\n",
    "        print(f\"   Quality Score: {analysis['reply_validation']['quality_score']}\")\n",
    "        print(f\"   Recommendation: {analysis['reply_validation']['recommendation']}\")\n",
    "        \n",
    "        # Lead Times\n",
    "        if analysis['lead_times']:\n",
    "            print(f\"\\n‚è±Ô∏è LEAD TIMES:\")\n",
    "            for key, value in analysis['lead_times'].items():\n",
    "                if 'minutes' in key and value is not None:\n",
    "                    print(f\"   {key}: {value}\")\n",
    "        \n",
    "        # Threshold Checks\n",
    "        if analysis['threshold_checks']:\n",
    "            print(f\"\\nüéØ THRESHOLD CHECKS:\")\n",
    "            for key, value in analysis['threshold_checks'].items():\n",
    "                if 'exceeded' in key:\n",
    "                    status = \"‚ùå EXCEEDED\" if value else \"‚úÖ WITHIN LIMIT\"\n",
    "                    actual = analysis['threshold_checks'].get(f\"{key.replace('_exceeded', '_actual_minutes')}\", 'N/A')\n",
    "                    threshold = analysis['threshold_checks'].get(f\"{key.replace('_exceeded', '_threshold_minutes')}\", 'N/A')\n",
    "                    print(f\"   {key}: {status} ({actual}m vs {threshold}m)\")\n",
    "        \n",
    "        # Performance Analysis\n",
    "        perf = analysis['performance_analysis']\n",
    "        print(f\"\\nüìà PERFORMANCE ANALYSIS:\")\n",
    "        print(f\"   Performance Rating: {perf['performance_rating'].upper()}\")\n",
    "        if 'response_efficiency' in perf:\n",
    "            print(f\"   Response Efficiency: {perf['response_efficiency'].upper()}\")\n",
    "        if 'resolution_efficiency' in perf:\n",
    "            print(f\"   Resolution Efficiency: {perf['resolution_efficiency'].upper()}\")\n",
    "        \n",
    "        # Quality Assessment\n",
    "        quality = analysis['quality_assessment']\n",
    "        print(f\"\\n‚≠ê QUALITY ASSESSMENT:\")\n",
    "        print(f\"   First Reply Quality: {quality['first_reply_quality'].upper()}\")\n",
    "        print(f\"   Final Reply Quality: {quality['final_reply_quality'].upper()}\")\n",
    "        print(f\"   Overall Quality: {quality['overall_quality'].upper()}\")\n",
    "        \n",
    "        # Show actual replies jika ada\n",
    "        if first_reply:\n",
    "            print(f\"\\nüîç FIRST REPLY:\")\n",
    "            print(f\"   Time: {first_reply.get('lead_time_minutes', 'N/A')} minutes\")\n",
    "            print(f\"   Type: {first_reply.get('reply_type', 'N/A')}\")\n",
    "            print(f\"   Message: {first_reply['message'][:100]}...\")\n",
    "        \n",
    "        if final_reply:\n",
    "            print(f\"\\nüéØ FINAL REPLY:\")\n",
    "            print(f\"   Time: {final_reply.get('lead_time_minutes', 'N/A')} minutes\") \n",
    "            print(f\"   Type: {final_reply.get('reply_type', 'N/A')}\")\n",
    "            print(f\"   Message: {final_reply['message'][:100]}...\")\n",
    "            if reply_analyzer._is_conversation_ender(final_reply['message']):\n",
    "                print(f\"   ‚ö†Ô∏è  WARNING: This appears to be a conversation ender, not a meaningful final answer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b92e50",
   "metadata": {},
   "source": [
    "Complete Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f576be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Hybrid Classifier initialized\n",
      "üöÄ Complete Analysis Pipeline Initialized\n",
      "   ‚úì Data Preprocessor\n",
      "   ‚úì Conversation Parser\n",
      "   ‚úì Main Issue Detector\n",
      "   ‚úì Hybrid Classifier\n",
      "   ‚úì Reply Analyzer\n",
      "‚úÖ FULLY FIXED Complete Analysis Pipeline Ready!\n",
      "   ‚úì All raw data preserved for export\n",
      "   ‚úì Enhanced statistics tracking\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL 8 - CompleteAnalysisPipeline (FULL FIX)\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "class CompleteAnalysisPipeline:\n",
    "    def __init__(self):\n",
    "        self.preprocessor = DataPreprocessor()\n",
    "        self.parser = ConversationParser()\n",
    "        self.issue_detector = MainIssueDetector()\n",
    "        self.classifier = HybridClassifier()\n",
    "        self.reply_analyzer = ReplyAnalyzer()\n",
    "        self.results = []\n",
    "        self.analysis_stats = {}\n",
    "        \n",
    "        print(\"üöÄ Complete Analysis Pipeline Initialized\")\n",
    "        print(\"   ‚úì Data Preprocessor\")\n",
    "        print(\"   ‚úì Conversation Parser\") \n",
    "        print(\"   ‚úì Main Issue Detector\")\n",
    "        print(\"   ‚úì Hybrid Classifier\")\n",
    "        print(\"   ‚úì Reply Analyzer\")\n",
    "    \n",
    "    def analyze_single_ticket(self, ticket_df, ticket_id):\n",
    "        \"\"\"Analisis lengkap untuk single ticket - SIMPAN SEMUA DATA\"\"\"\n",
    "        print(f\"üéØ Analyzing Ticket: {ticket_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Parse Q-A pairs\n",
    "            qa_pairs = self.parser.parse_conversation(ticket_df)\n",
    "            \n",
    "            if not qa_pairs:\n",
    "                return self._create_ticket_result(ticket_id, \"failed\", \"No Q-A pairs detected\", {})\n",
    "            \n",
    "            answered_count = sum(1 for pair in qa_pairs if pair['is_answered'])\n",
    "            print(f\"   ‚úì Found {len(qa_pairs)} Q-A pairs ({answered_count} answered)\")\n",
    "            \n",
    "            # Step 2: Detect main issue\n",
    "            main_issue = self.issue_detector.detect_main_issue(qa_pairs)\n",
    "            \n",
    "            if not main_issue:\n",
    "                return self._create_ticket_result(ticket_id, \"failed\", \"No main issue detected\", {})\n",
    "            \n",
    "            print(f\"   ‚úì Main issue: {main_issue['issue_type']} (conf: {main_issue['confidence_score']:.2f})\")\n",
    "            \n",
    "            # Step 3: Classify issue type (double-check dengan ML)\n",
    "            ml_prediction, ml_confidence = self.classifier.predict(main_issue['question'])\n",
    "            final_issue_type = self._resolve_issue_type(main_issue['issue_type'], ml_prediction, ml_confidence)\n",
    "            \n",
    "            print(f\"   ‚úì Final classification: {final_issue_type} (ML conf: {ml_confidence:.2f})\")\n",
    "            \n",
    "            # Step 4: Analyze replies and lead times\n",
    "            first_reply, final_reply, reply_analysis = self.reply_analyzer.analyze_replies(\n",
    "                qa_pairs, final_issue_type\n",
    "            )\n",
    "            \n",
    "            # Step 5: Compile COMPREHENSIVE results dengan SEMUA DATA\n",
    "            result = {\n",
    "                'ticket_id': ticket_id,\n",
    "                'status': 'success',\n",
    "                'analysis_timestamp': datetime.now(),\n",
    "                \n",
    "                # Conversation info\n",
    "                'total_messages': len(ticket_df),\n",
    "                'total_qa_pairs': len(qa_pairs),\n",
    "                'answered_pairs': answered_count,\n",
    "                'conversation_duration_minutes': reply_analysis.get('lead_times', {}).get('conversation_duration_minutes', 0),\n",
    "                \n",
    "                # Main issue analysis - LENGKAP\n",
    "                'main_question': main_issue['question'],\n",
    "                'main_question_time': main_issue['question_time'],\n",
    "                'detected_issue_type': main_issue['issue_type'],\n",
    "                'detection_confidence': main_issue['confidence_score'],\n",
    "                'final_issue_type': final_issue_type,\n",
    "                'ml_prediction': ml_prediction,\n",
    "                'ml_confidence': ml_confidence,\n",
    "                'main_issue_reason': main_issue['selected_reason'],\n",
    "                \n",
    "                # Reply analysis - LENGKAP\n",
    "                'first_reply_found': reply_analysis['reply_validation']['first_reply_found'],\n",
    "                'final_reply_found': reply_analysis['reply_validation']['final_reply_found'],\n",
    "                'first_reply_message': first_reply['message'] if first_reply else None,\n",
    "                'first_reply_time': first_reply['timestamp'] if first_reply else None,\n",
    "                'final_reply_message': final_reply['message'] if final_reply else None,\n",
    "                'final_reply_time': final_reply['timestamp'] if final_reply else None,\n",
    "                \n",
    "                # Lead times - LENGKAP\n",
    "                'first_reply_lead_time_minutes': reply_analysis['lead_times'].get('first_reply_lead_time_minutes'),\n",
    "                'final_reply_lead_time_minutes': reply_analysis['lead_times'].get('final_reply_lead_time_minutes'),\n",
    "                'first_reply_lead_time_hhmmss': reply_analysis['lead_times'].get('first_reply_lead_time_hhmmss'),\n",
    "                'final_reply_lead_time_hhmmss': reply_analysis['lead_times'].get('final_reply_lead_time_hhmmss'),\n",
    "                \n",
    "                # Performance metrics\n",
    "                'performance_rating': reply_analysis['performance_analysis']['performance_rating'],\n",
    "                'response_efficiency': reply_analysis['performance_analysis'].get('response_efficiency', 'unknown'),\n",
    "                'resolution_efficiency': reply_analysis['performance_analysis'].get('resolution_efficiency', 'unknown'),\n",
    "                'quality_rating': reply_analysis['reply_validation']['quality_rating'],\n",
    "                'quality_score': reply_analysis['reply_validation']['quality_score'],\n",
    "                \n",
    "                # Threshold checks\n",
    "                'threshold_violations': self._extract_threshold_violations(reply_analysis['threshold_checks']),\n",
    "                \n",
    "                # Recommendations\n",
    "                'recommendation': reply_analysis['reply_validation']['recommendation'],\n",
    "                'missing_elements': reply_analysis['reply_validation']['missing_elements'],\n",
    "                \n",
    "                # ‚úÖ‚úÖ‚úÖ RAW DATA LENGKAP UNTUK EXPORT ‚úÖ‚úÖ‚úÖ\n",
    "                '_raw_qa_pairs': qa_pairs,                    # SEMUA Q-A PAIRS\n",
    "                '_raw_main_issue': main_issue,                # DETAIL MAIN ISSUE\n",
    "                '_raw_reply_analysis': reply_analysis         # DETAIL REPLY ANALYSIS\n",
    "            }\n",
    "            \n",
    "            print(f\"   ‚úÖ Analysis completed - Performance: {result['performance_rating'].upper()}\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error: {str(e)}\"\n",
    "            print(f\"   ‚ùå Analysis failed: {error_msg}\")\n",
    "            return self._create_ticket_result(ticket_id, \"failed\", error_msg, {})\n",
    "    \n",
    "    def _resolve_issue_type(self, detected_type, ml_prediction, ml_confidence):\n",
    "        \"\"\"Resolve final issue type antara rule-based dan ML\"\"\"\n",
    "        if ml_confidence > 0.7:  # High confidence ML\n",
    "            return ml_prediction\n",
    "        elif ml_confidence > 0.5 and ml_prediction == detected_type:  # Consistent\n",
    "            return ml_prediction\n",
    "        else:  # Trust rule-based detection\n",
    "            return detected_type\n",
    "    \n",
    "    def _extract_threshold_violations(self, threshold_checks):\n",
    "        \"\"\"Extract threshold violations dari analysis\"\"\"\n",
    "        violations = []\n",
    "        for key, value in threshold_checks.items():\n",
    "            if 'exceeded' in key and value:\n",
    "                violations.append(key)\n",
    "        return violations\n",
    "    \n",
    "    def _create_ticket_result(self, ticket_id, status, reason, extra_data):\n",
    "        \"\"\"Create standardized result object\"\"\"\n",
    "        result = {\n",
    "            'ticket_id': ticket_id,\n",
    "            'status': status,\n",
    "            'failure_reason': reason if status == 'failed' else None,\n",
    "            'analysis_timestamp': datetime.now()\n",
    "        }\n",
    "        result.update(extra_data)\n",
    "        return result\n",
    "    \n",
    "    def analyze_all_tickets(self, df, sample_size=None, max_tickets=None):\n",
    "        \"\"\"Analisis semua tickets dengan comprehensive reporting\"\"\"\n",
    "        print(\"üöÄ STARTING COMPLETE ANALYSIS PIPELINE\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        ticket_ids = df['Ticket Number'].unique()\n",
    "        \n",
    "        if sample_size:\n",
    "            ticket_ids = ticket_ids[:sample_size]\n",
    "            print(f\"üîç Analyzing {sample_size} sample tickets...\")\n",
    "        elif max_tickets:\n",
    "            ticket_ids = ticket_ids[:max_tickets]\n",
    "            print(f\"üîç Analyzing {max_tickets} tickets (max limit)...\")\n",
    "        else:\n",
    "            print(f\"üîç Analyzing {len(ticket_ids)} tickets...\")\n",
    "        \n",
    "        self.results = []\n",
    "        successful_analyses = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, ticket_id in enumerate(ticket_ids):\n",
    "            ticket_df = df[df['Ticket Number'] == ticket_id]\n",
    "            \n",
    "            result = self.analyze_single_ticket(ticket_df, ticket_id)\n",
    "            self.results.append(result)\n",
    "            \n",
    "            if result['status'] == 'success':\n",
    "                successful_analyses += 1\n",
    "            \n",
    "            # Progress reporting\n",
    "            if (i + 1) % 10 == 0 or (i + 1) == len(ticket_ids):\n",
    "                progress = (i + 1) / len(ticket_ids) * 100\n",
    "                print(f\"   üìä Progress: {i + 1}/{len(ticket_ids)} ({progress:.1f}%) - {successful_analyses} successful\")\n",
    "        \n",
    "        # Calculate comprehensive statistics\n",
    "        analysis_time = time.time() - start_time\n",
    "        self.analysis_stats = self._calculate_comprehensive_stats(analysis_time)\n",
    "        \n",
    "        print(f\"\\nüéâ ANALYSIS PIPELINE COMPLETED!\")\n",
    "        print(\"=\" * 60)\n",
    "        self._print_summary_report()\n",
    "        \n",
    "        return self.results, self.analysis_stats\n",
    "    \n",
    "    def _calculate_comprehensive_stats(self, analysis_time):\n",
    "        \"\"\"Hitung comprehensive statistics dari results\"\"\"\n",
    "        successful = [r for r in self.results if r['status'] == 'success']\n",
    "        failed = [r for r in self.results if r['status'] == 'failed']\n",
    "        \n",
    "        if not successful:\n",
    "            return {\n",
    "                'total_tickets': len(self.results),\n",
    "                'successful_analysis': 0,\n",
    "                'failed_analysis': len(failed),\n",
    "                'success_rate': 0,\n",
    "                'analysis_duration_seconds': analysis_time\n",
    "            }\n",
    "        \n",
    "        # Basic stats\n",
    "        stats = {\n",
    "            'total_tickets': len(self.results),\n",
    "            'successful_analysis': len(successful),\n",
    "            'failed_analysis': len(failed),\n",
    "            'success_rate': len(successful) / len(self.results),\n",
    "            'analysis_duration_seconds': analysis_time,\n",
    "            'avg_analysis_time_per_ticket': analysis_time / len(self.results)\n",
    "        }\n",
    "        \n",
    "        # Issue type distribution\n",
    "        issue_types = [r['final_issue_type'] for r in successful]\n",
    "        stats['issue_type_distribution'] = dict(Counter(issue_types))\n",
    "        \n",
    "        # Performance metrics\n",
    "        performance_ratings = [r['performance_rating'] for r in successful]\n",
    "        stats['performance_distribution'] = dict(Counter(performance_ratings))\n",
    "        \n",
    "        # Lead time statistics\n",
    "        lead_times = [r['final_reply_lead_time_minutes'] for r in successful if r['final_reply_lead_time_minutes'] is not None]\n",
    "        if lead_times:\n",
    "            stats['lead_time_stats'] = {\n",
    "                'avg_lead_time_minutes': np.mean(lead_times),\n",
    "                'median_lead_time_minutes': np.median(lead_times),\n",
    "                'min_lead_time_minutes': np.min(lead_times),\n",
    "                'max_lead_time_minutes': np.max(lead_times),\n",
    "                'std_lead_time_minutes': np.std(lead_times)\n",
    "            }\n",
    "        \n",
    "        # Quality metrics\n",
    "        quality_scores = [r['quality_score'] for r in successful]\n",
    "        stats['quality_stats'] = {\n",
    "            'avg_quality_score': np.mean(quality_scores),\n",
    "            'avg_quality_rating': Counter([r['quality_rating'] for r in successful]).most_common(1)[0][0]\n",
    "        }\n",
    "        \n",
    "        # Threshold violations\n",
    "        all_violations = []\n",
    "        for r in successful:\n",
    "            all_violations.extend(r.get('threshold_violations', []))\n",
    "        stats['threshold_violations'] = dict(Counter(all_violations))\n",
    "        \n",
    "        # Reply effectiveness\n",
    "        stats['reply_effectiveness'] = {\n",
    "            'first_reply_found_rate': sum(1 for r in successful if r['first_reply_found']) / len(successful),\n",
    "            'final_reply_found_rate': sum(1 for r in successful if r['final_reply_found']) / len(successful),\n",
    "            'both_replies_found_rate': sum(1 for r in successful if r['first_reply_found'] and r['final_reply_found']) / len(successful)\n",
    "        }\n",
    "\n",
    "        # Q-A Pairs Statistics\n",
    "        total_qa_pairs = sum(r['total_qa_pairs'] for r in successful)\n",
    "        total_answered_pairs = sum(r['answered_pairs'] for r in successful)\n",
    "        stats['qa_pairs_stats'] = {\n",
    "            'total_qa_pairs': total_qa_pairs,\n",
    "            'total_answered_pairs': total_answered_pairs,\n",
    "            'answer_rate': total_answered_pairs / total_qa_pairs if total_qa_pairs > 0 else 0,\n",
    "            'avg_qa_pairs_per_ticket': total_qa_pairs / len(successful) if successful else 0\n",
    "        }\n",
    "\n",
    "        # Raw Data Availability\n",
    "        raw_data_available = {\n",
    "            'qa_pairs_available': sum(1 for r in successful if '_raw_qa_pairs' in r),\n",
    "            'main_issue_available': sum(1 for r in successful if '_raw_main_issue' in r),\n",
    "            'reply_analysis_available': sum(1 for r in successful if '_raw_reply_analysis' in r)\n",
    "        }\n",
    "        stats['raw_data_availability'] = raw_data_available\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def _print_summary_report(self):\n",
    "        \"\"\"Print comprehensive summary report\"\"\"\n",
    "        stats = self.analysis_stats\n",
    "        \n",
    "        print(f\"üìä COMPREHENSIVE ANALYSIS REPORT\")\n",
    "        print(f\"   ‚Ä¢ Total Tickets: {stats['total_tickets']}\")\n",
    "        print(f\"   ‚Ä¢ Successful Analysis: {stats['successful_analysis']} ({stats['success_rate']*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Analysis Duration: {stats['analysis_duration_seconds']:.1f}s\")\n",
    "        print(f\"   ‚Ä¢ Avg Time per Ticket: {stats['avg_analysis_time_per_ticket']:.2f}s\")\n",
    "        \n",
    "        if 'issue_type_distribution' in stats:\n",
    "            print(f\"\\nüéØ ISSUE TYPE DISTRIBUTION:\")\n",
    "            for issue_type, count in stats['issue_type_distribution'].items():\n",
    "                percentage = (count / stats['successful_analysis']) * 100\n",
    "                print(f\"   ‚Ä¢ {issue_type.title()}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        if 'lead_time_stats' in stats:\n",
    "            lt_stats = stats['lead_time_stats']\n",
    "            print(f\"\\n‚è±Ô∏è LEAD TIME STATISTICS:\")\n",
    "            print(f\"   ‚Ä¢ Average: {lt_stats['avg_lead_time_minutes']:.2f} min\")\n",
    "            print(f\"   ‚Ä¢ Median: {lt_stats['median_lead_time_minutes']:.2f} min\") \n",
    "            print(f\"   ‚Ä¢ Range: {lt_stats['min_lead_time_minutes']:.2f} - {lt_stats['max_lead_time_minutes']:.2f} min\")\n",
    "        \n",
    "        if 'performance_distribution' in stats:\n",
    "            print(f\"\\nüìà PERFORMANCE DISTRIBUTION:\")\n",
    "            for rating, count in stats['performance_distribution'].items():\n",
    "                percentage = (count / stats['successful_analysis']) * 100\n",
    "                print(f\"   ‚Ä¢ {rating.upper()}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        if 'threshold_violations' in stats:\n",
    "            print(f\"\\nüö® THRESHOLD VIOLATIONS:\")\n",
    "            for violation, count in stats['threshold_violations'].items():\n",
    "                print(f\"   ‚Ä¢ {violation}: {count}\")\n",
    "        \n",
    "        if 'reply_effectiveness' in stats:\n",
    "            eff = stats['reply_effectiveness']\n",
    "            print(f\"\\nüí¨ REPLY EFFECTIVENESS:\")\n",
    "            print(f\"   ‚Ä¢ First Reply Found: {eff['first_reply_found_rate']*100:.1f}%\")\n",
    "            print(f\"   ‚Ä¢ Final Reply Found: {eff['final_reply_found_rate']*100:.1f}%\")\n",
    "            print(f\"   ‚Ä¢ Both Replies Found: {eff['both_replies_found_rate']*100:.1f}%\")\n",
    "\n",
    "        if 'qa_pairs_stats' in stats:\n",
    "            qa_stats = stats['qa_pairs_stats']\n",
    "            print(f\"\\nüîó Q-A PAIRS STATISTICS:\")\n",
    "            print(f\"   ‚Ä¢ Total Q-A Pairs: {qa_stats['total_qa_pairs']}\")\n",
    "            print(f\"   ‚Ä¢ Answered Pairs: {qa_stats['total_answered_pairs']} ({qa_stats['answer_rate']*100:.1f}%)\")\n",
    "            print(f\"   ‚Ä¢ Avg Pairs per Ticket: {qa_stats['avg_qa_pairs_per_ticket']:.1f}\")\n",
    "\n",
    "        if 'raw_data_availability' in stats:\n",
    "            raw_stats = stats['raw_data_availability']\n",
    "            print(f\"\\nüìÅ RAW DATA AVAILABILITY:\")\n",
    "            print(f\"   ‚Ä¢ Q-A Pairs Data: {raw_stats['qa_pairs_available']}/{stats['successful_analysis']} tickets\")\n",
    "            print(f\"   ‚Ä¢ Main Issue Data: {raw_stats['main_issue_available']}/{stats['successful_analysis']} tickets\")\n",
    "            print(f\"   ‚Ä¢ Reply Analysis Data: {raw_stats['reply_analysis_available']}/{stats['successful_analysis']} tickets\")\n",
    "\n",
    "    def export_results(self, output_file=\"output/pipeline_results.xlsx\"):\n",
    "        \"\"\"Export results ke Excel file\"\"\"\n",
    "        try:\n",
    "            # Prepare data untuk export\n",
    "            export_data = []\n",
    "            \n",
    "            for result in self.results:\n",
    "                if result['status'] == 'success':\n",
    "                    row = {\n",
    "                        'ticket_id': result['ticket_id'],\n",
    "                        'issue_type': result['final_issue_type'],\n",
    "                        'main_question': result['main_question'],\n",
    "                        'performance_rating': result['performance_rating'],\n",
    "                        'quality_rating': result['quality_rating'],\n",
    "                        'quality_score': result['quality_score'],\n",
    "                        'final_reply_lead_time_minutes': result.get('final_reply_lead_time_minutes'),\n",
    "                        'first_reply_found': result['first_reply_found'],\n",
    "                        'final_reply_found': result['final_reply_found'],\n",
    "                        'threshold_violations': ', '.join(result['threshold_violations']) if result['threshold_violations'] else 'None',\n",
    "                        'recommendation': result['recommendation'],\n",
    "                        'detection_confidence': result['detection_confidence'],\n",
    "                        'ml_confidence': result['ml_confidence'],\n",
    "                        'total_messages': result['total_messages'],\n",
    "                        'total_qa_pairs': result['total_qa_pairs'],\n",
    "                        'answered_pairs': result['answered_pairs'],\n",
    "                        'first_reply_message': result.get('first_reply_message', '')[:100] + '...' if result.get('first_reply_message') else '',\n",
    "                        'final_reply_message': result.get('final_reply_message', '')[:100] + '...' if result.get('final_reply_message') else ''\n",
    "                    }\n",
    "                    export_data.append(row)\n",
    "                else:\n",
    "                    row = {\n",
    "                        'ticket_id': result['ticket_id'],\n",
    "                        'issue_type': 'FAILED',\n",
    "                        'main_question': result.get('failure_reason', 'Analysis failed'),\n",
    "                        'performance_rating': 'N/A',\n",
    "                        'quality_rating': 'N/A',\n",
    "                        'quality_score': 0,\n",
    "                        'final_reply_lead_time_minutes': None,\n",
    "                        'first_reply_found': False,\n",
    "                        'final_reply_found': False,\n",
    "                        'threshold_violations': 'N/A',\n",
    "                        'recommendation': 'Analysis failed',\n",
    "                        'detection_confidence': 0,\n",
    "                        'ml_confidence': 0,\n",
    "                        'total_messages': 0,\n",
    "                        'total_qa_pairs': 0,\n",
    "                        'answered_pairs': 0,\n",
    "                        'first_reply_message': '',\n",
    "                        'final_reply_message': ''\n",
    "                    }\n",
    "                    export_data.append(row)\n",
    "            \n",
    "            # Create DataFrame dan save\n",
    "            df_export = pd.DataFrame(export_data)\n",
    "            \n",
    "            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "                # Detailed results\n",
    "                df_export.to_excel(writer, sheet_name='Detailed_Results', index=False)\n",
    "                \n",
    "                # Summary statistics\n",
    "                summary_data = self._create_summary_sheet()\n",
    "                summary_df = pd.DataFrame(summary_data)\n",
    "                summary_df.to_excel(writer, sheet_name='Summary_Statistics', index=False)\n",
    "                \n",
    "                # Performance metrics\n",
    "                perf_data = self._create_performance_sheet()\n",
    "                perf_df = pd.DataFrame(perf_data)\n",
    "                perf_df.to_excel(writer, sheet_name='Performance_Metrics', index=False)\n",
    "            \n",
    "            print(f\"üíæ Results exported to: {output_file}\")\n",
    "            return output_file\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error exporting results: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _create_summary_sheet(self):\n",
    "        \"\"\"Create summary sheet data\"\"\"\n",
    "        stats = self.analysis_stats\n",
    "        \n",
    "        summary_data = [\n",
    "            ['COMPLETE ANALYSIS PIPELINE - SUMMARY REPORT', '', ''],\n",
    "            ['Generated', datetime.now().strftime('%Y-%m-%d %H:%M:%S'), ''],\n",
    "            ['', '', ''],\n",
    "            ['OVERALL STATISTICS', '', ''],\n",
    "            ['Total Tickets Processed', stats['total_tickets'], ''],\n",
    "            ['Successful Analysis', stats['successful_analysis'], ''],\n",
    "            ['Failed Analysis', stats['failed_analysis'], ''],\n",
    "            ['Success Rate', f\"{stats['success_rate']*100:.1f}%\", ''],\n",
    "            ['Total Analysis Time', f\"{stats['analysis_duration_seconds']:.1f} seconds\", ''],\n",
    "            ['Average Time per Ticket', f\"{stats['avg_analysis_time_per_ticket']:.2f} seconds\", ''],\n",
    "            ['', '', ''],\n",
    "            ['ISSUE TYPE DISTRIBUTION', 'Count', 'Percentage']\n",
    "        ]\n",
    "        \n",
    "        if 'issue_type_distribution' in stats:\n",
    "            for issue_type, count in stats['issue_type_distribution'].items():\n",
    "                percentage = (count / stats['successful_analysis']) * 100\n",
    "                summary_data.append([issue_type.title(), count, f\"{percentage:.1f}%\"])\n",
    "        \n",
    "        summary_data.extend([\n",
    "            ['', '', ''],\n",
    "            ['PERFORMANCE DISTRIBUTION', 'Count', 'Percentage']\n",
    "        ])\n",
    "        \n",
    "        if 'performance_distribution' in stats:\n",
    "            for rating, count in stats['performance_distribution'].items():\n",
    "                percentage = (count / stats['successful_analysis']) * 100\n",
    "                summary_data.append([rating.upper(), count, f\"{percentage:.1f}%\"])\n",
    "        \n",
    "        return summary_data\n",
    "    \n",
    "    def _create_performance_sheet(self):\n",
    "        \"\"\"Create performance metrics sheet\"\"\"\n",
    "        stats = self.analysis_stats\n",
    "        \n",
    "        perf_data = [\n",
    "            ['PERFORMANCE METRICS', 'Value', ''],\n",
    "            ['Reply Effectiveness', '', ''],\n",
    "            ['First Reply Found Rate', f\"{stats.get('reply_effectiveness', {}).get('first_reply_found_rate', 0)*100:.1f}%\", ''],\n",
    "            ['Final Reply Found Rate', f\"{stats.get('reply_effectiveness', {}).get('final_reply_found_rate', 0)*100:.1f}%\", ''],\n",
    "            ['Both Replies Found Rate', f\"{stats.get('reply_effectiveness', {}).get('both_replies_found_rate', 0)*100:.1f}%\", ''],\n",
    "            ['', '', ''],\n",
    "            ['Lead Time Statistics', '', '']\n",
    "        ]\n",
    "        \n",
    "        if 'lead_time_stats' in stats:\n",
    "            lt = stats['lead_time_stats']\n",
    "            perf_data.extend([\n",
    "                ['Average Lead Time', f\"{lt['avg_lead_time_minutes']:.2f} minutes\", ''],\n",
    "                ['Median Lead Time', f\"{lt['median_lead_time_minutes']:.2f} minutes\", ''],\n",
    "                ['Minimum Lead Time', f\"{lt['min_lead_time_minutes']:.2f} minutes\", ''],\n",
    "                ['Maximum Lead Time', f\"{lt['max_lead_time_minutes']:.2f} minutes\", ''],\n",
    "                ['Standard Deviation', f\"{lt['std_lead_time_minutes']:.2f} minutes\", '']\n",
    "            ])\n",
    "        \n",
    "        perf_data.extend([\n",
    "            ['', '', ''],\n",
    "            ['Quality Metrics', '', ''],\n",
    "            ['Average Quality Score', f\"{stats.get('quality_stats', {}).get('avg_quality_score', 0):.2f}/6\", ''],\n",
    "            ['Most Common Quality Rating', stats.get('quality_stats', {}).get('avg_quality_rating', 'N/A').upper(), '']\n",
    "        ])\n",
    "        \n",
    "        return perf_data\n",
    "\n",
    "# Initialize Fixed Pipeline\n",
    "pipeline = CompleteAnalysisPipeline()\n",
    "\n",
    "print(\"‚úÖ FULLY FIXED Complete Analysis Pipeline Ready!\")\n",
    "print(\"   ‚úì All raw data preserved for export\")\n",
    "print(\"   ‚úì Enhanced statistics tracking\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd97a2f",
   "metadata": {},
   "source": [
    "Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae5d8926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model Trainer Ready!\n",
      "============================================================\n",
      "üß™ TESTING MODEL TRAINING WITH SAMPLE DATA...\n",
      "üéØ Analyzing Ticket: 18ea89910d0d8eac44aecca81d779e3a\n",
      "   üîç Analyzing 28 messages for conversation start...\n",
      "   ‚úÖ Conversation start: operator greeting at position 23\n",
      "   üìù Analyzing 1 meaningful messages\n",
      "   üîÑ Sorted messages by timestamp\n",
      "   ‚úÖ Found 0 Q-A pairs (0 answered)\n",
      "   üîç Message sequence (first 5):\n",
      "      0: 2025-11-01 03:03:38.126000 | operator        | Selamat malam, Bapak Rajiv. Selamat datang di laya...\n",
      "üéØ Analyzing Ticket: 9842cd7eee5451283f8430fb83469940\n",
      "   üîç Analyzing 13 messages for conversation start...\n",
      "   ‚úÖ Conversation start: operator greeting at position 8\n",
      "   üìù Analyzing 1 meaningful messages\n",
      "   üîÑ Sorted messages by timestamp\n",
      "   ‚úÖ Found 0 Q-A pairs (0 answered)\n",
      "   üîç Message sequence (first 5):\n",
      "      0: 2025-11-01 05:27:53.335000 | operator        | Selamat pagi, Bapak Irwan. Selamat datang di layan...\n",
      "üéØ Analyzing Ticket: ead8d44e4914399b76af974a5169856e\n",
      "   üîç Analyzing 27 messages for conversation start...\n",
      "   ‚úÖ Conversation start: operator greeting at position 12\n",
      "   üìù Analyzing 14 meaningful messages\n",
      "   üîÑ Sorted messages by timestamp\n",
      "   üîç Found missing answer for question 1\n",
      "   üîç Found missing answer for question 2\n",
      "   ‚úÖ Found 6 Q-A pairs (6 answered)\n",
      "   üîç Message sequence (first 5):\n",
      "      0: 2025-11-01 08:01:08.772000 | operator        | Selamat pagi Ibu Grace. Selamat datang di layanan ...\n",
      "      1: 2025-11-01 08:02:03.082000 | customer        | Saya mau tanya harga filter solar untuk vrz 2016\n",
      "      2: 2025-11-01 08:02:21.789000 | customer        | filter bahan bakar beda dgn filter oli\n",
      "      3: 2025-11-01 08:02:49.326000 | operator        | Baik, Ibu Grace.\n",
      "      4: 2025-11-01 08:02:57.943000 | customer        | Kalau filter bahan bakar tsb brp lama harus di gan...\n",
      "   ‚úì Found 6 Q-A pairs (6 answered)\n",
      "   ‚úì Main issue: normal (conf: 0.90)\n",
      "   ‚úì Final classification: normal (ML conf: 0.95)\n",
      "üîç Analyzing replies for normal issue...\n",
      "   ‚úÖ Analysis completed - Performance: EXCELLENT\n",
      "üéØ Analyzing Ticket: d3c13cabf2875bcde12dfeec3c4b247c\n",
      "   üîç Analyzing 56 messages for conversation start...\n",
      "   ‚úÖ Conversation start: operator greeting at position 26\n",
      "   üìù Analyzing 24 meaningful messages\n",
      "   üîÑ Sorted messages by timestamp\n",
      "   üîç Found missing answer for question 1\n",
      "   üîç Found missing answer for question 2\n",
      "   ‚úÖ Found 9 Q-A pairs (9 answered)\n",
      "   üîç Message sequence (first 5):\n",
      "      0: 2025-11-01 08:01:50.703000 | operator        | Selamat pagi Bapak/Ibu. Selamat datang di layanan ...\n",
      "      1: 2025-11-01 08:02:09.505000 | customer        | Pagi saya degan Andi\n",
      "      2: 2025-11-01 08:02:13.864000 | customer        | Innova zenix saya mogok, tidak bisa d start, kondi...\n",
      "      3: 2025-11-01 08:02:28.266000 | customer        | Untuk lokasi di Beji, Depok\n",
      "      4: 2025-11-01 08:02:33.603000 | operator        | Baik, Bapak Andi.\n",
      "   ‚úì Found 9 Q-A pairs (9 answered)\n",
      "   ‚úì Main issue: serious (conf: 0.80)\n",
      "   ‚úì Final classification: serious (ML conf: 0.95)\n",
      "üîç Analyzing replies for serious issue...\n",
      "   ‚úÖ Analysis completed - Performance: POOR\n",
      "üéØ Analyzing Ticket: 26c136be7ac38a949f5ce346eea80838\n",
      "   üîç Analyzing 21 messages for conversation start...\n",
      "   ‚úÖ Conversation start: operator greeting at position 13\n",
      "   üìù Analyzing 4 meaningful messages\n",
      "   üîÑ Sorted messages by timestamp\n",
      "   ‚úÖ Found 1 Q-A pairs (1 answered)\n",
      "   üîç Message sequence (first 5):\n",
      "      0: 2025-11-01 09:01:03.540000 | operator        | Selamat pagi. Bapak Anto. Selamat datang di layana...\n",
      "      1: 2025-11-01 09:01:25.144000 | customer        | Pagi\n",
      "      2: 2025-11-01 09:01:39.076000 | customer        | Mau tanya promo spektakuler\n",
      "      3: 2025-11-01 09:03:13.401000 | operator        | Baik, Silakan Bapak Anto. Ada yang bisa dibantu?\n",
      "   ‚úì Found 1 Q-A pairs (1 answered)\n",
      "   ‚úì Main issue: normal (conf: 0.80)\n",
      "   ‚úì Final classification: normal (ML conf: 0.95)\n",
      "üîç Analyzing replies for normal issue...\n",
      "   ‚úÖ Analysis completed - Performance: EXCELLENT\n",
      "üéØ Analyzing Ticket: 436eb3b35fd79b32ec52fe80f10cc430\n",
      "   üîç Analyzing 52 messages for conversation start...\n",
      "   ‚úÖ Conversation start: operator greeting at position 20\n",
      "   üìù Analyzing 27 meaningful messages\n",
      "   üîÑ Sorted messages by timestamp\n",
      "   üîç Found missing answer for question 1\n",
      "   üîç Found missing answer for question 2\n",
      "   üîç Found missing answer for question 3\n",
      "   üîç Found missing answer for question 4\n",
      "   üîç Found missing answer for question 5\n",
      "   ‚úÖ Found 11 Q-A pairs (11 answered)\n",
      "   üîç Message sequence (first 5):\n",
      "      0: 2025-11-01 09:15:31.827000 | operator        | Selamat pagi. Ibu Astrid. Selamat datang di layana...\n",
      "      1: 2025-11-01 09:16:56.305000 | customer        | iya, maaf ini mau aktivasi t intouch di m toyota, ...\n",
      "      2: 2025-11-01 09:17:00.629000 | customer        | apakah bisa dibantu?\n",
      "      3: 2025-11-01 09:17:03.674000 | customer        | terima kasih\n",
      "      4: 2025-11-01 09:17:21.439000 | operator        | Mohon dilampirkan tangkapan layarnya.\n",
      "   ‚úì Found 11 Q-A pairs (11 answered)\n",
      "   ‚úì Main issue: serious (conf: 0.30)\n",
      "   ‚úì Final classification: serious (ML conf: 0.50)\n",
      "üîç Analyzing replies for serious issue...\n",
      "   ‚úÖ Analysis completed - Performance: POOR\n",
      "üéØ Analyzing Ticket: e894d4c923651de517346b463bbb1411\n",
      "   üîç Analyzing 34 messages for conversation start...\n",
      "   ‚úÖ Conversation start: operator greeting at position 16\n",
      "   üìù Analyzing 14 meaningful messages\n",
      "   üîÑ Sorted messages by timestamp\n",
      "   ‚úÖ Found 5 Q-A pairs (5 answered)\n",
      "   üîç Message sequence (first 5):\n",
      "      0: 2025-11-01 09:19:16.244000 | operator        | Selamat pagi Bapak Nadhif Alifiansyah. Selamat dat...\n",
      "      1: 2025-11-01 09:19:53.710000 | customer        | Pagi kak\n",
      "      2: 2025-11-01 09:20:05.591000 | customer        | Mau tanya tentang asuransi mobil saya\n",
      "      3: 2025-11-01 09:21:13.366000 | operator        | Asuransi apa Bapak Nadhif?\n",
      "      4: 2025-11-01 09:22:05.944000 | customer        | Kalau mau claim asuransi gimana caranya?\n",
      "   ‚úì Found 5 Q-A pairs (5 answered)\n",
      "   ‚úì Main issue: normal (conf: 0.70)\n",
      "   ‚úì Final classification: normal (ML conf: 0.95)\n",
      "üîç Analyzing replies for normal issue...\n",
      "   ‚úÖ Analysis completed - Performance: GOOD\n",
      "üéØ Analyzing Ticket: ca29261e102b8eacd757c79472f8c813\n",
      "   üîç Analyzing 55 messages for conversation start...\n",
      "   ‚úÖ Conversation start: operator greeting at position 12\n",
      "   üìù Analyzing 37 meaningful messages\n",
      "   üîÑ Sorted messages by timestamp\n",
      "   üîç Found missing answer for question 1\n",
      "   üîç Found missing answer for question 2\n",
      "   üîç Found missing answer for question 3\n",
      "   üîç Found missing answer for question 4\n",
      "   üîç Found missing answer for question 5\n",
      "   üîç Found missing answer for question 6\n",
      "   üîç Found missing answer for question 7\n",
      "   ‚úÖ Found 14 Q-A pairs (14 answered)\n",
      "   üîç Message sequence (first 5):\n",
      "      0: 2025-11-01 10:06:04.188000 | operator        | Selamat siang. Bapak Tio. Selamat datang di layana...\n",
      "      1: 2025-11-01 10:06:17.926000 | customer        | Tolong bantu\n",
      "      2: 2025-11-01 10:06:18.516000 | customer        | Ini mobil saya ga bs di starter\n",
      "      3: 2025-11-01 10:06:23.563000 | customer        | Ini kenapa ya?\n",
      "      4: 2025-11-01 10:07:03.095000 | operator        | bisa diinformasikan tipe kendaraan dan tahunnya?\n",
      "   ‚úì Found 14 Q-A pairs (14 answered)\n",
      "   ‚úì Main issue: serious (conf: 0.90)\n",
      "   ‚úì Final classification: serious (ML conf: 0.60)\n",
      "üîç Analyzing replies for serious issue...\n",
      "   ‚úÖ Analysis completed - Performance: EXCELLENT\n",
      "üéØ Analyzing Ticket: d8def5fa29f007b79cbcefb3da0fe2ef\n",
      "   üîç Analyzing 50 messages for conversation start...\n",
      "   ‚úÖ Conversation start: operator greeting at position 6\n",
      "   üìù Analyzing 34 meaningful messages\n",
      "   üîÑ Sorted messages by timestamp\n",
      "   üîç Found missing answer for question 1\n",
      "   üîç Found missing answer for question 2\n",
      "   üîç Found missing answer for question 3\n",
      "   üîç Found missing answer for question 4\n",
      "   üîç Found missing answer for question 5\n",
      "   üîç Found missing answer for question 6\n",
      "   ‚úÖ Found 14 Q-A pairs (14 answered)\n",
      "   üîç Message sequence (first 5):\n",
      "      0: 2025-11-01 10:50:05.220000 | operator        | Selamat siang Bapak Gandi. Selamat datang di layan...\n",
      "      1: 2025-11-01 10:50:19.414000 | customer        | Selamat siang\n",
      "      2: 2025-11-01 10:50:27.198000 | customer        | Mbak saya sdh donlod m toyota\n",
      "      3: 2025-11-01 10:50:31.568000 | customer        | Sdh register mbl\n",
      "      4: 2025-11-01 10:50:48.916000 | customer        | Knapa di fitur in touch tdk ada tombol connect ya\n",
      "   ‚úì Found 14 Q-A pairs (14 answered)\n",
      "   ‚úì Main issue: normal (conf: 0.50)\n",
      "   ‚úì Final classification: normal (ML conf: 0.95)\n",
      "üîç Analyzing replies for normal issue...\n",
      "   ‚úÖ Analysis completed - Performance: EXCELLENT\n",
      "üéØ Analyzing Ticket: dda916f027531a87dd754bd416859568\n",
      "   üîç Analyzing 26 messages for conversation start...\n",
      "   ‚úÖ Conversation start: operator greeting at position 13\n",
      "   üìù Analyzing 12 meaningful messages\n",
      "   üîÑ Sorted messages by timestamp\n",
      "   ‚úÖ Found 3 Q-A pairs (3 answered)\n",
      "   üîç Message sequence (first 5):\n",
      "      0: 2025-11-01 11:01:41.229000 | operator        | Selamat siang Bapak Dedy. Selamat datang di layana...\n",
      "      1: 2025-11-01 11:02:07.557000 | customer        | mau service berkala\n",
      "      2: 2025-11-01 11:02:36.429000 | operator        | Baik, Bapak Dedy. Menggunakan jenis kendaraan Toyo...\n",
      "      3: 2025-11-01 11:03:03.741000 | customer        | veloz 1,5 q\n",
      "      4: 2025-11-01 11:03:20.332000 | operator        | Rencana Booking Service untuk jadwal kapan, Bapak ...\n",
      "   ‚úì Found 3 Q-A pairs (3 answered)\n",
      "   ‚úì Main issue: normal (conf: 0.10)\n",
      "   ‚úì Final classification: normal (ML conf: 0.50)\n",
      "üîç Analyzing replies for normal issue...\n",
      "   ‚úÖ Analysis completed - Performance: GOOD\n",
      "üìö Collecting training data from analysis results...\n",
      "‚úÖ Collected 8 training samples\n",
      "üîÑ Enhancing training data...\n",
      "‚úÖ Enhanced training data: 32 total samples\n",
      "üìä Training data distribution: {'normal': 13, 'serious': 11, 'complaint': 8}\n",
      "ü§ñ Training model with enhanced real data...\n",
      "üìä Dataset: 32 samples\n",
      "üìä Training: 22 samples\n",
      "üìä Testing: 10 samples\n",
      "üìä Class distribution: Counter({'normal': 13, 'serious': 11, 'complaint': 8})\n",
      "ü§ñ Training Enhanced ML model...\n",
      "   Training samples: 22\n",
      "   Class distribution: Counter({'normal': 9, 'serious': 8, 'complaint': 5})\n",
      "‚úÖ Model trained - Accuracy: 1.000\n",
      "üìä ENHANCED CLASSIFIER PERFORMANCE REPORT\n",
      "==================================================\n",
      "Accuracy: 0.900\n",
      "Test Samples: 10\n",
      "Class Distribution: Counter({'normal': 4, 'serious': 3, 'complaint': 3})\n",
      "\n",
      "üìà Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.75      1.00      0.86         3\n",
      "     serious       1.00      0.75      0.86         4\n",
      "   complaint       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.92      0.92      0.90        10\n",
      "weighted avg       0.93      0.90      0.90        10\n",
      "\n",
      "\n",
      "üéØ Confidence Analysis:\n",
      "   Average Confidence: 0.442\n",
      "   High Confidence (>0.7): 0/10\n",
      "   Low Confidence (<0.5): 8/10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Top 15 Features per Class:\n",
      "\n",
      "NORMAL:\n",
      "   yang: 0.655\n",
      "   untuk: 0.579\n",
      "   komplain: 0.536\n",
      "   protes: 0.471\n",
      "   sangat: 0.327\n",
      "   kecewa: 0.327\n",
      "   pelayanan: 0.327\n",
      "   bengkel: 0.327\n",
      "   janji: 0.322\n",
      "   ditepati: 0.322\n",
      "   palsu: 0.286\n",
      "   sparepart: 0.286\n",
      "   dipasang: 0.286\n",
      "   lamban: 0.280\n",
      "   penanganan: 0.280\n",
      "\n",
      "SERIOUS:\n",
      "   mau: 0.438\n",
      "   tanya: 0.285\n",
      "   harga: 0.281\n",
      "   lengkap: 0.228\n",
      "   rush: 0.228\n",
      "   spesifikasi: 0.228\n",
      "   service: 0.225\n",
      "   berkala: 0.225\n",
      "   baru: 0.213\n",
      "   kredit: 0.213\n",
      "   syarat: 0.213\n",
      "   dealer: 0.198\n",
      "   toyota: 0.198\n",
      "   terdekat: 0.198\n",
      "   alamat: 0.198\n",
      "\n",
      "COMPLAINT:\n",
      "   jalan: 0.307\n",
      "   semua: 0.307\n",
      "   tiba: 0.296\n",
      "   di: 0.291\n",
      "   sendiri: 0.284\n",
      "   terbakar: 0.284\n",
      "   oli: 0.221\n",
      "   parah: 0.221\n",
      "   mesin: 0.221\n",
      "   bocor: 0.221\n",
      "   dashboard: 0.221\n",
      "   lampu: 0.221\n",
      "   berkedip: 0.221\n",
      "   rem: 0.216\n",
      "   berfungsi: 0.216\n",
      "üîç Performing cross-validation...\n",
      "\n",
      "============================================================\n",
      "üìä COMPREHENSIVE MODEL EVALUATION REPORT\n",
      "============================================================\n",
      "üéØ ACCURACY METRICS:\n",
      "   ‚Ä¢ Test Accuracy: 0.900\n",
      "   ‚Ä¢ Cross-Val Accuracy: 0.838 (¬±0.106)\n",
      "\n",
      "üìä DATASET INFO:\n",
      "   ‚Ä¢ Total Samples: 32\n",
      "   ‚Ä¢ Training Samples: 22\n",
      "   ‚Ä¢ Test Samples: 10\n",
      "   ‚Ä¢ Class Distribution: {'normal': 13, 'serious': 11, 'complaint': 8}\n",
      "\n",
      "üîç CROSS-VALIDATION DETAILS:\n",
      "   ‚Ä¢ Fold 1: 1.000\n",
      "   ‚Ä¢ Fold 2: 0.857\n",
      "   ‚Ä¢ Fold 3: 0.833\n",
      "   ‚Ä¢ Fold 4: 0.833\n",
      "   ‚Ä¢ Fold 5: 0.667\n",
      "\n",
      "üìà PERFORMANCE ASSESSMENT: EXCELLENT üéØ\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚Ä¢ Model ready for production use\n",
      "   ‚Ä¢ Continue monitoring performance\n",
      "\n",
      "üîç Analyzing model confidence on real data...\n",
      "   ‚Ä¢ Total Predictions: 8\n",
      "   ‚Ä¢ High Confidence Predictions: 5 (62.5%)\n",
      "   ‚Ä¢ Average Confidence: 0.794\n",
      "   ‚Ä¢ Confidence Range: 0.500 - 0.950\n",
      "üíæ Model evaluation report saved: output/model_evaluation_report.txt\n",
      "\n",
      "üéØ MODEL TRAINING COMPLETED!\n",
      "   Final Accuracy: 0.900\n",
      "\n",
      "üí° Untuk full-scale training, run: full_scale_training()\n",
      "üí° Model sudah siap untuk digunakan dalam production!\n"
     ]
    }
   ],
   "source": [
    "# Model Training & Evaluation dengan Real Data (FIXED)\n",
    "class ModelTrainer:\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.training_data = []\n",
    "        self.evaluation_results = {}\n",
    "        \n",
    "    def collect_training_data_from_analysis(self, results):\n",
    "        \"\"\"Collect training data dari analysis results\"\"\"\n",
    "        print(\"üìö Collecting training data from analysis results...\")\n",
    "        \n",
    "        training_samples = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success':\n",
    "                # Use the final classification sebagai ground truth\n",
    "                training_samples.append({\n",
    "                    'text': result['main_question'],\n",
    "                    'label': result['final_issue_type'],\n",
    "                    'ticket_id': result['ticket_id'],\n",
    "                    'confidence': result['detection_confidence'],\n",
    "                    'ml_confidence': result['ml_confidence']\n",
    "                })\n",
    "        \n",
    "        self.training_data = training_samples\n",
    "        print(f\"‚úÖ Collected {len(training_samples)} training samples\")\n",
    "        return training_samples\n",
    "    \n",
    "    def enhance_training_data(self):\n",
    "        \"\"\"Enhance training data dengan manual corrections dan additional samples\"\"\"\n",
    "        print(\"üîÑ Enhancing training data...\")\n",
    "        \n",
    "        # Additional curated samples berdasarkan domain knowledge\n",
    "        enhanced_samples = [\n",
    "            # Additional NORMAL samples\n",
    "            {\"text\": \"berapa harga mobil avanza terbaru\", \"label\": \"normal\"},\n",
    "            {\"text\": \"info promo cashback toyota\", \"label\": \"normal\"},\n",
    "            {\"text\": \"cara booking test drive fortuner\", \"label\": \"normal\"},\n",
    "            {\"text\": \"alamat dealer toyota terdekat\", \"label\": \"normal\"},\n",
    "            {\"text\": \"jam operasional bengkel\", \"label\": \"normal\"},\n",
    "            {\"text\": \"spesifikasi lengkap rush\", \"label\": \"normal\"},\n",
    "            {\"text\": \"syarat kredit mobil baru\", \"label\": \"normal\"},\n",
    "            {\"text\": \"beda innova zenix dan innova lama\", \"label\": \"normal\"},\n",
    "            \n",
    "            # Additional SERIOUS samples  \n",
    "            {\"text\": \"mobil tiba-tiba mati di jalan tol\", \"label\": \"serious\"},\n",
    "            {\"text\": \"mesin overheating terus menerus\", \"label\": \"serious\"},\n",
    "            {\"text\": \"rem tidak berfungsi dengan baik\", \"label\": \"serious\"},\n",
    "            {\"text\": \"aki soak tidak bisa starter\", \"label\": \"serious\"},\n",
    "            {\"text\": \"lampu dashboard berkedip semua\", \"label\": \"serious\"},\n",
    "            {\"text\": \"oli mesin bocor parah\", \"label\": \"serious\"},\n",
    "            {\"text\": \"ban pecah di jalan cepat\", \"label\": \"serious\"},\n",
    "            {\"text\": \"mobil terbakar sendiri\", \"label\": \"serious\"},\n",
    "            \n",
    "            # Additional COMPLAINT samples\n",
    "            {\"text\": \"sangat kecewa dengan pelayanan bengkel\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"komplain sparepart palsu yang dipasang\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"protes untuk biaya servis yang mahal\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"minta refund untuk produk cacat\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"kecewa dengan waiting time yang lama\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"komplain untuk janji tidak ditepati\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"pelayanan customer service sangat buruk\", \"label\": \"complaint\"},\n",
    "            {\"text\": \"protes untuk penanganan yang lamban\", \"label\": \"complaint\"}\n",
    "        ]\n",
    "        \n",
    "        # Combine dengan collected data\n",
    "        if self.training_data:\n",
    "            current_texts = [sample['text'] for sample in self.training_data]\n",
    "            for sample in enhanced_samples:\n",
    "                if sample['text'] not in current_texts:\n",
    "                    self.training_data.append(sample)\n",
    "        else:\n",
    "            self.training_data = enhanced_samples\n",
    "        \n",
    "        print(f\"‚úÖ Enhanced training data: {len(self.training_data)} total samples\")\n",
    "        \n",
    "        # Show distribution\n",
    "        labels = [sample['label'] for sample in self.training_data]\n",
    "        distribution = Counter(labels)\n",
    "        print(f\"üìä Training data distribution: {dict(distribution)}\")\n",
    "    \n",
    "    def train_and_evaluate_model(self, test_size=0.2):\n",
    "        \"\"\"Train dan evaluate model dengan real data\"\"\"\n",
    "        if not self.training_data:\n",
    "            print(\"‚ùå No training data available\")\n",
    "            return None\n",
    "        \n",
    "        print(\"ü§ñ Training model with enhanced real data...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        texts = [sample['text'] for sample in self.training_data]\n",
    "        labels = [sample['label'] for sample in self.training_data]\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            texts, labels, \n",
    "            test_size=test_size, \n",
    "            random_state=config.RANDOM_STATE,\n",
    "            stratify=labels\n",
    "        )\n",
    "        \n",
    "        print(f\"üìä Dataset: {len(texts)} samples\")\n",
    "        print(f\"üìä Training: {len(X_train)} samples\")\n",
    "        print(f\"üìä Testing: {len(X_test)} samples\")\n",
    "        print(f\"üìä Class distribution: {Counter(labels)}\")\n",
    "        \n",
    "        # Train model\n",
    "        success = self.pipeline.classifier.train(X_train, y_train)\n",
    "        \n",
    "        if success:\n",
    "            # Evaluate model\n",
    "            accuracy = self.pipeline.classifier.evaluate_model(X_test, y_test)\n",
    "            \n",
    "            # Store evaluation results\n",
    "            self.evaluation_results = {\n",
    "                'accuracy': accuracy,\n",
    "                'training_samples': len(X_train),\n",
    "                'test_samples': len(X_test),\n",
    "                'class_distribution': dict(Counter(labels)),\n",
    "                'test_distribution': dict(Counter(y_test))\n",
    "            }\n",
    "            \n",
    "            # Cross-validation untuk lebih robust evaluation\n",
    "            cv_results = self._cross_validate(texts, labels)\n",
    "            self.evaluation_results.update(cv_results)\n",
    "            \n",
    "            self._print_evaluation_report()\n",
    "            \n",
    "            return accuracy\n",
    "        else:\n",
    "            print(\"‚ùå Model training failed\")\n",
    "            return None\n",
    "    \n",
    "    def _cross_validate(self, texts, labels, cv_folds=5):\n",
    "        \"\"\"Perform cross-validation untuk robust evaluation\"\"\"\n",
    "        print(\"üîç Performing cross-validation...\")\n",
    "        \n",
    "        try:\n",
    "            from sklearn.model_selection import cross_val_score\n",
    "            \n",
    "            # Create pipeline untuk cross-validation\n",
    "            from sklearn.pipeline import Pipeline\n",
    "            cv_pipeline = Pipeline([\n",
    "                ('tfidf', self.pipeline.classifier.vectorizer),\n",
    "                ('clf', self.pipeline.classifier.classifier)\n",
    "            ])\n",
    "            \n",
    "            # Perform cross-validation\n",
    "            cv_scores = cross_val_score(\n",
    "                cv_pipeline, texts, labels, \n",
    "                cv=cv_folds, scoring='accuracy'\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'cross_val_accuracy_mean': np.mean(cv_scores),\n",
    "                'cross_val_accuracy_std': np.std(cv_scores),\n",
    "                'cross_val_scores': cv_scores.tolist()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Cross-validation failed: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def _print_evaluation_report(self):\n",
    "        \"\"\"Print comprehensive evaluation report\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä COMPREHENSIVE MODEL EVALUATION REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        eval_results = self.evaluation_results\n",
    "        \n",
    "        print(f\"üéØ ACCURACY METRICS:\")\n",
    "        print(f\"   ‚Ä¢ Test Accuracy: {eval_results.get('accuracy', 0):.3f}\")\n",
    "        if 'cross_val_accuracy_mean' in eval_results:\n",
    "            print(f\"   ‚Ä¢ Cross-Val Accuracy: {eval_results['cross_val_accuracy_mean']:.3f} (¬±{eval_results['cross_val_accuracy_std']:.3f})\")\n",
    "        \n",
    "        print(f\"\\nüìä DATASET INFO:\")\n",
    "        print(f\"   ‚Ä¢ Total Samples: {eval_results.get('training_samples', 0) + eval_results.get('test_samples', 0)}\")\n",
    "        print(f\"   ‚Ä¢ Training Samples: {eval_results.get('training_samples', 0)}\")\n",
    "        print(f\"   ‚Ä¢ Test Samples: {eval_results.get('test_samples', 0)}\")\n",
    "        \n",
    "        if 'class_distribution' in eval_results:\n",
    "            print(f\"   ‚Ä¢ Class Distribution: {eval_results['class_distribution']}\")\n",
    "        \n",
    "        if 'cross_val_scores' in eval_results:\n",
    "            print(f\"\\nüîç CROSS-VALIDATION DETAILS:\")\n",
    "            for i, score in enumerate(eval_results['cross_val_scores']):\n",
    "                print(f\"   ‚Ä¢ Fold {i+1}: {score:.3f}\")\n",
    "        \n",
    "        # Model performance assessment\n",
    "        accuracy = eval_results.get('accuracy', 0)\n",
    "        if accuracy >= 0.9:\n",
    "            assessment = \"EXCELLENT üéØ\"\n",
    "        elif accuracy >= 0.8:\n",
    "            assessment = \"VERY GOOD ‚úÖ\"  \n",
    "        elif accuracy >= 0.7:\n",
    "            assessment = \"GOOD üëç\"\n",
    "        elif accuracy >= 0.6:\n",
    "            assessment = \"FAIR ‚ö†Ô∏è\"\n",
    "        else:\n",
    "            assessment = \"POOR ‚ùå\"\n",
    "        \n",
    "        print(f\"\\nüìà PERFORMANCE ASSESSMENT: {assessment}\")\n",
    "        \n",
    "        # Recommendations\n",
    "        print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "        if accuracy >= 0.85:\n",
    "            print(f\"   ‚Ä¢ Model ready for production use\")\n",
    "            print(f\"   ‚Ä¢ Continue monitoring performance\")\n",
    "        elif accuracy >= 0.7:\n",
    "            print(f\"   ‚Ä¢ Model acceptable for use\")\n",
    "            print(f\"   ‚Ä¢ Consider adding more training data\")\n",
    "        else:\n",
    "            print(f\"   ‚Ä¢ Model needs improvement\")\n",
    "            print(f\"   ‚Ä¢ Collect more labeled data\")\n",
    "            print(f\"   ‚Ä¢ Review feature engineering\")\n",
    "    \n",
    "    def analyze_model_confidence(self, results):\n",
    "        \"\"\"Analyze model confidence pada real predictions\"\"\"\n",
    "        print(\"\\nüîç Analyzing model confidence on real data...\")\n",
    "        \n",
    "        confident_predictions = 0\n",
    "        total_predictions = 0\n",
    "        confidence_scores = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success':\n",
    "                total_predictions += 1\n",
    "                ml_confidence = result.get('ml_confidence', 0)\n",
    "                confidence_scores.append(ml_confidence)\n",
    "                \n",
    "                if ml_confidence > 0.7:  # High confidence threshold\n",
    "                    confident_predictions += 1\n",
    "        \n",
    "        if total_predictions > 0:\n",
    "            avg_confidence = np.mean(confidence_scores)\n",
    "            high_confidence_rate = confident_predictions / total_predictions\n",
    "            \n",
    "            print(f\"   ‚Ä¢ Total Predictions: {total_predictions}\")\n",
    "            print(f\"   ‚Ä¢ High Confidence Predictions: {confident_predictions} ({high_confidence_rate*100:.1f}%)\")\n",
    "            print(f\"   ‚Ä¢ Average Confidence: {avg_confidence:.3f}\")\n",
    "            print(f\"   ‚Ä¢ Confidence Range: {np.min(confidence_scores):.3f} - {np.max(confidence_scores):.3f}\")\n",
    "            \n",
    "            return {\n",
    "                'total_predictions': total_predictions,\n",
    "                'high_confidence_predictions': confident_predictions,\n",
    "                'high_confidence_rate': high_confidence_rate,\n",
    "                'avg_confidence': avg_confidence,\n",
    "                'confidence_scores': confidence_scores\n",
    "            }\n",
    "        \n",
    "        return {}\n",
    "\n",
    "    def save_model_report(self):\n",
    "        \"\"\"Save model evaluation report ke file\"\"\"\n",
    "        try:\n",
    "            report_path = \"output/model_evaluation_report.txt\"\n",
    "            \n",
    "            with open(report_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"ü§ñ CHAT ANALYSIS MODEL EVALUATION REPORT\\n\")\n",
    "                f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "                \n",
    "                f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "                \n",
    "                # Accuracy metrics\n",
    "                f.write(\"ACCURACY METRICS:\\n\")\n",
    "                f.write(f\"- Test Accuracy: {self.evaluation_results.get('accuracy', 0):.3f}\\n\")\n",
    "                if 'cross_val_accuracy_mean' in self.evaluation_results:\n",
    "                    f.write(f\"- Cross-Val Accuracy: {self.evaluation_results['cross_val_accuracy_mean']:.3f} (¬±{self.evaluation_results['cross_val_accuracy_std']:.3f})\\n\")\n",
    "                \n",
    "                # Dataset info\n",
    "                f.write(f\"\\nDATASET INFO:\\n\")\n",
    "                f.write(f\"- Total Samples: {len(self.training_data)}\\n\")\n",
    "                f.write(f\"- Training Samples: {self.evaluation_results.get('training_samples', 0)}\\n\")\n",
    "                f.write(f\"- Test Samples: {self.evaluation_results.get('test_samples', 0)}\\n\")\n",
    "                f.write(f\"- Class Distribution: {self.evaluation_results.get('class_distribution', {})}\\n\")\n",
    "                \n",
    "                # Model info\n",
    "                f.write(f\"\\nMODEL INFO:\\n\")\n",
    "                f.write(f\"- Classifier: Logistic Regression\\n\")\n",
    "                f.write(f\"- Vectorizer: TF-IDF\\n\")\n",
    "                f.write(f\"- Features: {self.pipeline.classifier.vectorizer.max_features}\\n\")\n",
    "                \n",
    "                # Recommendations\n",
    "                accuracy = self.evaluation_results.get('accuracy', 0)\n",
    "                f.write(f\"\\nRECOMMENDATIONS:\\n\")\n",
    "                if accuracy >= 0.85:\n",
    "                    f.write(\"- ‚úÖ Model ready for production use\\n\")\n",
    "                elif accuracy >= 0.7:\n",
    "                    f.write(\"- ‚ö†Ô∏è Model acceptable, consider more training data\\n\")\n",
    "                else:\n",
    "                    f.write(\"- ‚ùå Model needs improvement\\n\")\n",
    "            \n",
    "            print(f\"üíæ Model evaluation report saved: {report_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving model report: {e}\")\n",
    "\n",
    "# Initialize Model Trainer\n",
    "model_trainer = ModelTrainer(pipeline)\n",
    "\n",
    "print(\"‚úÖ Model Trainer Ready!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test dengan sample data terlebih dahulu\n",
    "if raw_df is not None:\n",
    "    print(\"üß™ TESTING MODEL TRAINING WITH SAMPLE DATA...\")\n",
    "    \n",
    "    # Analyze sample tickets untuk collect training data\n",
    "    sample_tickets = raw_df['Ticket Number'].unique()[:10]  # 10 tickets sample\n",
    "    sample_results = []\n",
    "    \n",
    "    for ticket_id in sample_tickets:\n",
    "        ticket_df = raw_df[raw_df['Ticket Number'] == ticket_id]\n",
    "        result = pipeline.analyze_single_ticket(ticket_df, ticket_id)\n",
    "        sample_results.append(result)\n",
    "    \n",
    "    # Collect training data dari results\n",
    "    training_data = model_trainer.collect_training_data_from_analysis(sample_results)\n",
    "    \n",
    "    if training_data:\n",
    "        # Enhance training data\n",
    "        model_trainer.enhance_training_data()\n",
    "        \n",
    "        # Train and evaluate model\n",
    "        accuracy = model_trainer.train_and_evaluate_model(test_size=0.3)\n",
    "        \n",
    "        if accuracy:\n",
    "            # Analyze confidence on real predictions\n",
    "            confidence_analysis = model_trainer.analyze_model_confidence(sample_results)\n",
    "            \n",
    "            # Save model report\n",
    "            model_trainer.save_model_report()\n",
    "            \n",
    "            print(f\"\\nüéØ MODEL TRAINING COMPLETED!\")\n",
    "            print(f\"   Final Accuracy: {accuracy:.3f}\")\n",
    "        else:\n",
    "            print(\"‚ùå Model training failed\")\n",
    "    else:\n",
    "        print(\"‚ùå No training data collected\")\n",
    "\n",
    "def full_scale_training():\n",
    "    \"\"\"Full scale training dengan seluruh dataset\"\"\"\n",
    "    print(\"\\nüöÄ STARTING FULL-SCALE MODEL TRAINING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if raw_df is None:\n",
    "        print(\"‚ùå No data available for training\")\n",
    "        return\n",
    "    \n",
    "    # Analyze semua tickets untuk collect comprehensive training data\n",
    "    print(\"üìä Analyzing all tickets for training data collection...\")\n",
    "    all_results, stats = pipeline.analyze_all_tickets(raw_df, max_tickets=50)  # Limit untuk testing\n",
    "    \n",
    "    if all_results:\n",
    "        # Train model dengan comprehensive data\n",
    "        training_data = model_trainer.collect_training_data_from_analysis(all_results)\n",
    "        model_trainer.enhance_training_data()\n",
    "        accuracy = model_trainer.train_and_evaluate_model(test_size=0.2)\n",
    "        \n",
    "        if accuracy:\n",
    "            # Save comprehensive report\n",
    "            model_trainer.save_model_report()\n",
    "            \n",
    "            print(f\"\\nüéâ FULL-SCALE TRAINING COMPLETED!\")\n",
    "            print(f\"   Model Accuracy: {accuracy:.3f}\")\n",
    "            print(f\"   Training Samples: {len(model_trainer.training_data)}\")\n",
    "            print(f\"   Model ready for production use! üöÄ\")\n",
    "        else:\n",
    "            print(\"‚ùå Full-scale training failed\")\n",
    "    else:\n",
    "        print(\"‚ùå No results for training\")\n",
    "\n",
    "# Option untuk run full-scale training\n",
    "print(f\"\\nüí° Untuk full-scale training, run: full_scale_training()\")\n",
    "print(f\"üí° Model sudah siap untuk digunakan dalam production!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996e818",
   "metadata": {},
   "source": [
    "Results Export & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe944166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced Results Exporter Initialized\n",
      "‚úÖ ENHANCED Results Exporter & Visualizer Ready!\n",
      "   ‚úì 8 Sheets Excel Export\n",
      "   ‚úì Complete Q-A Pairs Data\n",
      "   ‚úì Main Issue Scoring Details\n",
      "   ‚úì Reply Analysis Details\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Results Export & Visualization\n",
    "class ResultsExporter:\n",
    "    def __init__(self):\n",
    "        self.output_dir = \"output/\"\n",
    "        self.reports_dir = f\"{self.output_dir}reports/\"\n",
    "        self.visualizations_dir = f\"{self.output_dir}visualizations/\"\n",
    "        \n",
    "        Path(self.output_dir).mkdir(exist_ok=True)\n",
    "        Path(self.reports_dir).mkdir(exist_ok=True)\n",
    "        Path(self.visualizations_dir).mkdir(exist_ok=True)\n",
    "        \n",
    "        print(\"‚úÖ Enhanced Results Exporter Initialized\")\n",
    "    \n",
    "    def export_comprehensive_results(self, results, stats, filename=\"comprehensive_analysis_results.xlsx\"):\n",
    "        \"\"\"Export COMPLETE results dengan semua data parse\"\"\"\n",
    "        output_path = f\"{self.output_dir}{filename}\"\n",
    "        \n",
    "        print(f\"üíæ Exporting COMPREHENSIVE results to {output_path}...\")\n",
    "        \n",
    "        try:\n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "                # Sheet 1: Detailed Analysis Results (LENGKAP)\n",
    "                self._create_comprehensive_detailed_sheet(writer, results)\n",
    "                \n",
    "                # Sheet 2: Q-A Pairs Raw Data (HASIL PARSE LENGKAP) - FIXED SORTING\n",
    "                self._create_qa_pairs_sheet(writer, results)\n",
    "                \n",
    "                # Sheet 3: Main Issue Analysis Details\n",
    "                self._create_main_issue_sheet(writer, results)\n",
    "                \n",
    "                # Sheet 4: Reply Analysis Details\n",
    "                self._create_reply_analysis_sheet(writer, results)\n",
    "                \n",
    "                # Sheet 5: Summary Statistics\n",
    "                self._create_summary_sheet(writer, stats)\n",
    "                \n",
    "                # Sheet 6: Performance Metrics\n",
    "                self._create_performance_sheet(writer, results)\n",
    "                \n",
    "                # Sheet 7: Lead Time Analysis\n",
    "                self._create_lead_time_sheet(writer, results)\n",
    "                \n",
    "                # Sheet 8: Quality Assessment\n",
    "                self._create_quality_sheet(writer, results)\n",
    "            \n",
    "            print(f\"‚úÖ COMPREHENSIVE results exported: {output_path}\")\n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error exporting comprehensive results: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _create_qa_pairs_sheet(self, writer, results):\n",
    "        \"\"\"Create sheet dengan RAW Q-A PAIRS data - FIXED SORTING VERSION\"\"\"\n",
    "        qa_pairs_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success' and '_raw_qa_pairs' in result:\n",
    "                # üî• FIX: URUTKAN Q-A PAIRS BERDASARKAN POSITION/WAKTU\n",
    "                sorted_qa_pairs = sorted(\n",
    "                    result['_raw_qa_pairs'], \n",
    "                    key=lambda x: x.get('position', 0)\n",
    "                )\n",
    "                \n",
    "                for i, qa_pair in enumerate(sorted_qa_pairs):\n",
    "                    qa_pairs_data.append({\n",
    "                        'Ticket_ID': result['ticket_id'],\n",
    "                        'QA_Pair_Index': i + 1,\n",
    "                        'Question': qa_pair.get('question', ''),\n",
    "                        'Question_Time': qa_pair.get('question_time'),\n",
    "                        'Bubble_Count': qa_pair.get('bubble_count', 1),\n",
    "                        'Is_Answered': qa_pair.get('is_answered', False),\n",
    "                        'Answer': qa_pair.get('answer', ''),\n",
    "                        'Answer_Time': qa_pair.get('answer_time'),\n",
    "                        'Answer_Role': qa_pair.get('answer_role', ''),\n",
    "                        'Lead_Time_Seconds': qa_pair.get('lead_time_seconds'),\n",
    "                        'Lead_Time_Minutes': qa_pair.get('lead_time_minutes'),\n",
    "                        'Lead_Time_HHMMSS': qa_pair.get('lead_time_hhmmss'),\n",
    "                        'Position_Index': qa_pair.get('position', i)  # Untuk debugging\n",
    "                    })\n",
    "        \n",
    "        if qa_pairs_data:\n",
    "            # üî• FIX: URUTKAN DATA UNTUK EXCEL BERDASARKAN TICKET DAN WAKTU\n",
    "            df_qa = pd.DataFrame(qa_pairs_data)\n",
    "            \n",
    "            # Urutkan berdasarkan Ticket_ID dan Question_Time\n",
    "            df_qa = df_qa.sort_values(['Ticket_ID', 'Question_Time']).reset_index(drop=True)\n",
    "            \n",
    "            # Update QA_Pair_Index yang benar setelah sorting\n",
    "            df_qa['QA_Pair_Index'] = df_qa.groupby('Ticket_ID').cumcount() + 1\n",
    "            \n",
    "            df_qa.to_excel(writer, sheet_name='Raw_QA_Pairs', index=False)\n",
    "            \n",
    "            print(f\"   ‚úÖ Exported {len(df_qa)} Q-A pairs (sorted by time)\")\n",
    "        else:\n",
    "            # Create empty sheet jika tidak ada data\n",
    "            empty_df = pd.DataFrame(['No Q-A pairs data available'])\n",
    "            empty_df.to_excel(writer, sheet_name='Raw_QA_Pairs', index=False, header=False)\n",
    "\n",
    "    def _create_comprehensive_detailed_sheet(self, writer, results):\n",
    "        \"\"\"Create DETAILED sheet dengan SEMUA data\"\"\"\n",
    "        detailed_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success':\n",
    "                row = {\n",
    "                    # BASIC INFO\n",
    "                    'Ticket_ID': result['ticket_id'],\n",
    "                    'Status': 'SUCCESS',\n",
    "                    'Analysis_Timestamp': result['analysis_timestamp'],\n",
    "                    \n",
    "                    # CONVERSATION INFO\n",
    "                    'Total_Messages': result['total_messages'],\n",
    "                    'Total_QA_Pairs': result['total_qa_pairs'],\n",
    "                    'Answered_Pairs': result['answered_pairs'],\n",
    "                    'Conversation_Duration_Min': result.get('conversation_duration_minutes', 'N/A'),\n",
    "                    \n",
    "                    # MAIN ISSUE - LENGKAP\n",
    "                    'Main_Question': result['main_question'],\n",
    "                    'Main_Question_Time': result.get('main_question_time'),\n",
    "                    'Detected_Issue_Type': result.get('detected_issue_type', 'N/A'),\n",
    "                    'Final_Issue_Type': result['final_issue_type'],\n",
    "                    'Detection_Confidence': result['detection_confidence'],\n",
    "                    'ML_Prediction': result.get('ml_prediction', 'N/A'),\n",
    "                    'ML_Confidence': result.get('ml_confidence', 'N/A'),\n",
    "                    'Main_Issue_Reason': result.get('main_issue_reason', 'N/A'),\n",
    "                    \n",
    "                    # FIRST REPLY - LENGKAP\n",
    "                    'First_Reply_Found': result['first_reply_found'],\n",
    "                    'First_Reply_Message': result.get('first_reply_message', ''),\n",
    "                    'First_Reply_Time': result.get('first_reply_time'),\n",
    "                    'First_Reply_Lead_Time_Min': result.get('first_reply_lead_time_minutes'),\n",
    "                    'First_Reply_Lead_Time_HHMMSS': result.get('first_reply_lead_time_hhmmss'),\n",
    "                    \n",
    "                    # FINAL REPLY - LENGKAP\n",
    "                    'Final_Reply_Found': result['final_reply_found'],\n",
    "                    'Final_Reply_Message': result.get('final_reply_message', ''),\n",
    "                    'Final_Reply_Time': result.get('final_reply_time'),\n",
    "                    'Final_Reply_Lead_Time_Min': result.get('final_reply_lead_time_minutes'),\n",
    "                    'Final_Reply_Lead_Time_HHMMSS': result.get('final_reply_lead_time_hhmmss'),\n",
    "                    \n",
    "                    # PERFORMANCE METRICS\n",
    "                    'Performance_Rating': result['performance_rating'],\n",
    "                    'Response_Efficiency': result.get('response_efficiency', 'N/A'),\n",
    "                    'Resolution_Efficiency': result.get('resolution_efficiency', 'N/A'),\n",
    "                    'Quality_Rating': result['quality_rating'],\n",
    "                    'Quality_Score': result['quality_score'],\n",
    "                    \n",
    "                    # THRESHOLD & RECOMMENDATIONS\n",
    "                    'Threshold_Violations': ', '.join(result['threshold_violations']) if result['threshold_violations'] else 'None',\n",
    "                    'Recommendation': result['recommendation'],\n",
    "                    'Missing_Elements': ', '.join(result['missing_elements']) if result['missing_elements'] else 'None'\n",
    "                }\n",
    "            else:\n",
    "                row = {\n",
    "                    'Ticket_ID': result['ticket_id'],\n",
    "                    'Status': 'FAILED',\n",
    "                    'Failure_Reason': result['failure_reason'],\n",
    "                    'Analysis_Timestamp': result['analysis_timestamp']\n",
    "                }\n",
    "            \n",
    "            detailed_data.append(row)\n",
    "        \n",
    "        df_detailed = pd.DataFrame(detailed_data)\n",
    "        df_detailed.to_excel(writer, sheet_name='Detailed_Analysis', index=False)\n",
    "        \n",
    "        # Auto-adjust column widths\n",
    "        worksheet = writer.sheets['Detailed_Analysis']\n",
    "        for column in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 2, 50)\n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "    def _create_qa_pairs_sheet(self, writer, results):\n",
    "        \"\"\"Create sheet dengan RAW Q-A PAIRS data (HASIL PARSE LENGKAP)\"\"\"\n",
    "        qa_pairs_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success' and '_raw_qa_pairs' in result:\n",
    "                for i, qa_pair in enumerate(result['_raw_qa_pairs']):\n",
    "                    qa_pairs_data.append({\n",
    "                        'Ticket_ID': result['ticket_id'],\n",
    "                        'QA_Pair_Index': i + 1,\n",
    "                        'Question': qa_pair.get('question', ''),\n",
    "                        'Question_Time': qa_pair.get('question_time'),\n",
    "                        'Bubble_Count': qa_pair.get('bubble_count', 1),\n",
    "                        'Is_Answered': qa_pair.get('is_answered', False),\n",
    "                        'Answer': qa_pair.get('answer', ''),\n",
    "                        'Answer_Time': qa_pair.get('answer_time'),\n",
    "                        'Answer_Role': qa_pair.get('answer_role', ''),\n",
    "                        'Lead_Time_Seconds': qa_pair.get('lead_time_seconds'),\n",
    "                        'Lead_Time_Minutes': qa_pair.get('lead_time_minutes'),\n",
    "                        'Lead_Time_HHMMSS': qa_pair.get('lead_time_hhmmss')\n",
    "                    })\n",
    "        \n",
    "        if qa_pairs_data:\n",
    "            df_qa = pd.DataFrame(qa_pairs_data)\n",
    "            df_qa.to_excel(writer, sheet_name='Raw_QA_Pairs', index=False)\n",
    "        else:\n",
    "            # Create empty sheet jika tidak ada data\n",
    "            empty_df = pd.DataFrame(['No Q-A pairs data available'])\n",
    "            empty_df.to_excel(writer, sheet_name='Raw_QA_Pairs', index=False, header=False)\n",
    "\n",
    "    def _create_main_issue_sheet(self, writer, results):\n",
    "        \"\"\"Create sheet dengan MAIN ISSUE analysis details\"\"\"\n",
    "        main_issue_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success' and '_raw_main_issue' in result:\n",
    "                main_issue = result['_raw_main_issue']\n",
    "                scoring_details = main_issue.get('scoring_details', {})\n",
    "                \n",
    "                main_issue_data.append({\n",
    "                    'Ticket_ID': result['ticket_id'],\n",
    "                    'Selected_Question': main_issue.get('question', ''),\n",
    "                    'Question_Time': main_issue.get('question_time'),\n",
    "                    'Issue_Type': main_issue.get('issue_type', ''),\n",
    "                    'Confidence_Score': main_issue.get('confidence_score', 0),\n",
    "                    'Selection_Reason': main_issue.get('selected_reason', ''),\n",
    "                    \n",
    "                    # SCORING DETAILS\n",
    "                    'Complaint_Keyword_Matches': scoring_details.get('complaint_matches', 0),\n",
    "                    'Serious_Keyword_Matches': scoring_details.get('serious_matches', 0),\n",
    "                    'Normal_Keyword_Matches': scoring_details.get('normal_matches', 0),\n",
    "                    'Is_Initial_Question': scoring_details.get('is_initial_question', False),\n",
    "                    'Is_Follow_Up': scoring_details.get('is_follow_up', False),\n",
    "                    \n",
    "                    # CANDIDATE COUNT\n",
    "                    'Total_Candidates': len(main_issue.get('all_candidates', [])),\n",
    "                    'Winning_Score': max([c.get('score', 0) for c in main_issue.get('all_candidates', [])]) if main_issue.get('all_candidates') else 0\n",
    "                })\n",
    "        \n",
    "        if main_issue_data:\n",
    "            df_main_issue = pd.DataFrame(main_issue_data)\n",
    "            df_main_issue.to_excel(writer, sheet_name='Main_Issue_Details', index=False)\n",
    "        else:\n",
    "            empty_df = pd.DataFrame(['No main issue details available'])\n",
    "            empty_df.to_excel(writer, sheet_name='Main_Issue_Details', index=False, header=False)\n",
    "\n",
    "    def _create_reply_analysis_sheet(self, writer, results):\n",
    "        \"\"\"Create sheet dengan REPLY ANALYSIS details\"\"\"\n",
    "        reply_analysis_data = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['status'] == 'success' and '_raw_reply_analysis' in result:\n",
    "                reply_analysis = result['_raw_reply_analysis']\n",
    "                lead_times = reply_analysis.get('lead_times', {})\n",
    "                threshold_checks = reply_analysis.get('threshold_checks', {})\n",
    "                quality_assessment = reply_analysis.get('quality_assessment', {})\n",
    "                reply_validation = reply_analysis.get('reply_validation', {})\n",
    "                performance_analysis = reply_analysis.get('performance_analysis', {})\n",
    "                \n",
    "                reply_analysis_data.append({\n",
    "                    'Ticket_ID': result['ticket_id'],\n",
    "                    'Issue_Type': reply_analysis.get('issue_type', ''),\n",
    "                    \n",
    "                    # LEAD TIMES DETAILS\n",
    "                    'First_Reply_Lead_Time_Seconds': lead_times.get('first_reply_lead_time_seconds'),\n",
    "                    'Final_Reply_Lead_Time_Seconds': lead_times.get('final_reply_lead_time_seconds'),\n",
    "                    'Conversation_Duration_Seconds': lead_times.get('conversation_duration_seconds'),\n",
    "                    \n",
    "                    # THRESHOLD CHECKS\n",
    "                    'Threshold_Violations_Count': len([v for v in threshold_checks.values() if v is True]),\n",
    "                    'Specific_Threshold_Violations': ', '.join([k for k, v in threshold_checks.items() if v is True]),\n",
    "                    \n",
    "                    # QUALITY ASSESSMENT\n",
    "                    'First_Reply_Quality': quality_assessment.get('first_reply_quality', 'unknown'),\n",
    "                    'Final_Reply_Quality': quality_assessment.get('final_reply_quality', 'unknown'),\n",
    "                    'Overall_Quality': quality_assessment.get('overall_quality', 'unknown'),\n",
    "                    \n",
    "                    # REPLY VALIDATION\n",
    "                    'First_Reply_Found': reply_validation.get('first_reply_found', False),\n",
    "                    'Final_Reply_Found': reply_validation.get('final_reply_found', False),\n",
    "                    'Validation_Quality_Score': reply_validation.get('quality_score', 0),\n",
    "                    'Validation_Quality_Rating': reply_validation.get('quality_rating', 'poor'),\n",
    "                    'Missing_Elements': ', '.join(reply_validation.get('missing_elements', [])),\n",
    "                    'Validation_Recommendation': reply_validation.get('recommendation', ''),\n",
    "                    \n",
    "                    # PERFORMANCE ANALYSIS\n",
    "                    'Performance_Rating': performance_analysis.get('performance_rating', 'unknown'),\n",
    "                    'Response_Efficiency': performance_analysis.get('response_efficiency', 'unknown'),\n",
    "                    'Resolution_Efficiency': performance_analysis.get('resolution_efficiency', 'unknown')\n",
    "                })\n",
    "        \n",
    "        if reply_analysis_data:\n",
    "            df_reply = pd.DataFrame(reply_analysis_data)\n",
    "            df_reply.to_excel(writer, sheet_name='Reply_Analysis_Details', index=False)\n",
    "        else:\n",
    "            empty_df = pd.DataFrame(['No reply analysis details available'])\n",
    "            empty_df.to_excel(writer, sheet_name='Reply_Analysis_Details', index=False, header=False)\n",
    "\n",
    "    def _create_summary_sheet(self, writer, stats):\n",
    "        \"\"\"Create summary statistics sheet\"\"\"\n",
    "        summary_data = [\n",
    "            ['COMPREHENSIVE ANALYSIS SUMMARY - ALL DATA EXPORTED', ''],\n",
    "            ['Generated', datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "            ['Total Sheets in this File', '8 Sheets: Detailed, QA-Pairs, Main-Issue, Reply-Analysis, Summary, Performance, Lead-Time, Quality'],\n",
    "            ['', ''],\n",
    "            ['OVERALL STATISTICS', ''],\n",
    "            ['Total Tickets Processed', stats['total_tickets']],\n",
    "            ['Successful Analysis', stats['successful_analysis']],\n",
    "            ['Failed Analysis', stats['failed_analysis']],\n",
    "            ['Success Rate', f\"{stats['success_rate']*100:.1f}%\"],\n",
    "            ['Analysis Duration', f\"{stats['analysis_duration_seconds']:.1f} seconds\"],\n",
    "            ['Average Time per Ticket', f\"{stats['avg_analysis_time_per_ticket']:.2f} seconds\"],\n",
    "            ['', ''],\n",
    "            ['DATA COMPLETENESS', ''],\n",
    "            ['Total Q-A Pairs Extracted', 'See Raw_QA_Pairs sheet'],\n",
    "            ['Total Main Issues Identified', 'See Main_Issue_Details sheet'], \n",
    "            ['Total Reply Analyses', 'See Reply_Analysis_Details sheet'],\n",
    "            ['', ''],\n",
    "            ['EXPORT NOTES', ''],\n",
    "            ['Sheet 1 - Detailed_Analysis', 'Main results dengan semua field'],\n",
    "            ['Sheet 2 - Raw_QA_Pairs', 'SEMUA Q-A pairs yang berhasil di-parse'],\n",
    "            ['Sheet 3 - Main_Issue_Details', 'Detail scoring dan selection main issue'],\n",
    "            ['Sheet 4 - Reply_Analysis_Details', 'Detail analisis reply dan lead times'],\n",
    "            ['Sheet 5 - Summary_Statistics', 'Statistik aggregate'],\n",
    "            ['Sheet 6 - Performance_Metrics', 'Performance metrics per ticket'],\n",
    "            ['Sheet 7 - Lead_Time_Analysis', 'Analisis lead time detail'],\n",
    "            ['Sheet 8 - Quality_Assessment', 'Assesment kualitas conversation']\n",
    "        ]\n",
    "        \n",
    "        # Tambahkan statistik biasa\n",
    "        if 'issue_type_distribution' in stats:\n",
    "            summary_data.extend([['', ''], ['ISSUE TYPE DISTRIBUTION', '']])\n",
    "            for issue_type, count in stats['issue_type_distribution'].items():\n",
    "                percentage = (count / stats['successful_analysis']) * 100\n",
    "                summary_data.append([f'{issue_type.title()} Issues', f'{count} ({percentage:.1f}%)'])\n",
    "        \n",
    "        if 'performance_distribution' in stats:\n",
    "            summary_data.extend([['', ''], ['PERFORMANCE DISTRIBUTION', '']])\n",
    "            for rating, count in stats['performance_distribution'].items():\n",
    "                percentage = (count / stats['successful_analysis']) * 100\n",
    "                summary_data.append([f'{rating.upper()} Performance', f'{count} ({percentage:.1f}%)'])\n",
    "        \n",
    "        if 'lead_time_stats' in stats:\n",
    "            lt_stats = stats['lead_time_stats']\n",
    "            summary_data.extend([['', ''], ['LEAD TIME STATISTICS', '']])\n",
    "            summary_data.extend([\n",
    "                ['Average Lead Time', f\"{lt_stats['avg_lead_time_minutes']:.2f} minutes\"],\n",
    "                ['Median Lead Time', f\"{lt_stats['median_lead_time_minutes']:.2f} minutes\"],\n",
    "                ['Minimum Lead Time', f\"{lt_stats['min_lead_time_minutes']:.2f} minutes\"],\n",
    "                ['Maximum Lead Time', f\"{lt_stats['max_lead_time_minutes']:.2f} minutes\"],\n",
    "                ['Standard Deviation', f\"{lt_stats['std_lead_time_minutes']:.2f} minutes\"]\n",
    "            ])\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data, columns=['Metric', 'Value'])\n",
    "        summary_df.to_excel(writer, sheet_name='Summary_Statistics', index=False)\n",
    "\n",
    "    def _create_performance_sheet(self, writer, results):\n",
    "        \"\"\"Create performance metrics sheet\"\"\"\n",
    "        successful = [r for r in results if r['status'] == 'success']\n",
    "        \n",
    "        perf_data = []\n",
    "        for result in successful:\n",
    "            perf_data.append({\n",
    "                'Ticket_ID': result['ticket_id'],\n",
    "                'Issue_Type': result['final_issue_type'],\n",
    "                'Performance_Rating': result['performance_rating'],\n",
    "                'Response_Efficiency': result.get('response_efficiency', 'N/A'),\n",
    "                'Resolution_Efficiency': result.get('resolution_efficiency', 'N/A'),\n",
    "                'First_Reply_Lead_Time_Min': result.get('first_reply_lead_time_minutes'),\n",
    "                'Final_Reply_Lead_Time_Min': result.get('final_reply_lead_time_minutes'),\n",
    "                'Threshold_Violations_Count': len(result['threshold_violations']),\n",
    "                'Specific_Violations': ', '.join(result['threshold_violations']) if result['threshold_violations'] else 'None'\n",
    "            })\n",
    "        \n",
    "        df_perf = pd.DataFrame(perf_data)\n",
    "        df_perf.to_excel(writer, sheet_name='Performance_Metrics', index=False)\n",
    "\n",
    "    def _create_lead_time_sheet(self, writer, results):\n",
    "        \"\"\"Create lead time analysis sheet\"\"\"\n",
    "        successful = [r for r in results if r['status'] == 'success' and r.get('final_reply_lead_time_minutes')]\n",
    "        \n",
    "        lead_time_data = []\n",
    "        for result in successful:\n",
    "            lead_time_data.append({\n",
    "                'Ticket_ID': result['ticket_id'],\n",
    "                'Issue_Type': result['final_issue_type'],\n",
    "                'Final_Reply_Lead_Time_Min': result['final_reply_lead_time_minutes'],\n",
    "                'First_Reply_Lead_Time_Min': result.get('first_reply_lead_time_minutes', 'N/A'),\n",
    "                'Conversation_Duration_Min': result.get('conversation_duration_minutes', 'N/A'),\n",
    "                'Performance_Rating': result['performance_rating'],\n",
    "                'Within_Threshold': 'Yes' if not result['threshold_violations'] else 'No'\n",
    "            })\n",
    "        \n",
    "        df_lead = pd.DataFrame(lead_time_data)\n",
    "        df_lead.to_excel(writer, sheet_name='Lead_Time_Analysis', index=False)\n",
    "\n",
    "    def _create_quality_sheet(self, writer, results):\n",
    "        \"\"\"Create quality assessment sheet\"\"\"\n",
    "        successful = [r for r in results if r['status'] == 'success']\n",
    "        \n",
    "        quality_data = []\n",
    "        for result in successful:\n",
    "            quality_data.append({\n",
    "                'Ticket_ID': result['ticket_id'],\n",
    "                'Issue_Type': result['final_issue_type'],\n",
    "                'Quality_Rating': result['quality_rating'],\n",
    "                'Quality_Score': result['quality_score'],\n",
    "                'First_Reply_Found': 'Yes' if result['first_reply_found'] else 'No',\n",
    "                'Final_Reply_Found': 'Yes' if result['final_reply_found'] else 'No',\n",
    "                'Missing_Elements': ', '.join(result['missing_elements']) if result['missing_elements'] else 'None',\n",
    "                'Recommendation': result['recommendation']\n",
    "            })\n",
    "        \n",
    "        df_quality = pd.DataFrame(quality_data)\n",
    "        df_quality.to_excel(writer, sheet_name='Quality_Assessment', index=False)\n",
    "\n",
    "    def create_comprehensive_visualizations(self, results, stats):\n",
    "        \"\"\"Create comprehensive visualizations dashboard\"\"\"\n",
    "        print(\"üìä Creating comprehensive visualizations...\")\n",
    "        \n",
    "        # Import gridspec here to fix the NameError\n",
    "        import matplotlib.gridspec as gridspec\n",
    "        \n",
    "        successful = [r for r in results if r['status'] == 'success']\n",
    "        \n",
    "        if not successful:\n",
    "            print(\"‚ùå No successful analyses to visualize\")\n",
    "            return\n",
    "        \n",
    "        # Create figure dengan multiple subplots\n",
    "        fig = plt.figure(figsize=(20, 15))\n",
    "        fig.suptitle('Chat Analysis Dashboard - Comprehensive Overview', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Define grid layout\n",
    "        gs = gridspec.GridSpec(3, 3, figure=fig)\n",
    "        \n",
    "        # Plot 1: Issue Type Distribution\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        self._plot_issue_type_distribution(ax1, stats)\n",
    "        \n",
    "        # Plot 2: Performance Rating Distribution\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        self._plot_performance_distribution(ax2, stats)\n",
    "        \n",
    "        # Plot 3: Lead Time Distribution\n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "        self._plot_lead_time_distribution(ax3, successful)\n",
    "        \n",
    "        # Plot 4: Quality Score Distribution\n",
    "        ax4 = fig.add_subplot(gs[1, 0])\n",
    "        self._plot_quality_distribution(ax4, successful)\n",
    "        \n",
    "        # Plot 5: Reply Effectiveness\n",
    "        ax5 = fig.add_subplot(gs[1, 1])\n",
    "        self._plot_reply_effectiveness(ax5, stats)\n",
    "        \n",
    "        # Plot 6: Threshold Violations\n",
    "        ax6 = fig.add_subplot(gs[1, 2])\n",
    "        self._plot_threshold_violations(ax6, stats)\n",
    "        \n",
    "        # Plot 7: Lead Time by Issue Type\n",
    "        ax7 = fig.add_subplot(gs[2, :])\n",
    "        self._plot_lead_time_by_issue_type(ax7, successful)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.93)\n",
    "        \n",
    "        # Save dashboard\n",
    "        dashboard_path = f\"{self.visualizations_dir}analysis_dashboard.png\"\n",
    "        plt.savefig(dashboard_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"‚úÖ Visualizations saved: {dashboard_path}\")\n",
    "        \n",
    "        # Create additional individual charts\n",
    "        self._create_individual_charts(successful, stats)\n",
    "    \n",
    "    def _plot_issue_type_distribution(self, ax, stats):\n",
    "        \"\"\"Plot issue type distribution\"\"\"\n",
    "        if 'issue_type_distribution' not in stats:\n",
    "            ax.text(0.5, 0.5, 'No data', ha='center', va='center')\n",
    "            return\n",
    "        \n",
    "        types = list(stats['issue_type_distribution'].keys())\n",
    "        counts = list(stats['issue_type_distribution'].values())\n",
    "        colors = [self.colors.get(t, '#999999') for t in types]\n",
    "        \n",
    "        ax.pie(counts, labels=types, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "        ax.set_title('Issue Type Distribution', fontweight='bold')\n",
    "    \n",
    "    def _plot_performance_distribution(self, ax, stats):\n",
    "        \"\"\"Plot performance rating distribution\"\"\"\n",
    "        if 'performance_distribution' not in stats:\n",
    "            ax.text(0.5, 0.5, 'No data', ha='center', va='center')\n",
    "            return\n",
    "        \n",
    "        ratings = list(stats['performance_distribution'].keys())\n",
    "        counts = list(stats['performance_distribution'].values())\n",
    "        colors = [self.performance_colors.get(r, '#999999') for r in ratings]\n",
    "        \n",
    "        bars = ax.bar(ratings, counts, color=colors)\n",
    "        ax.set_title('Performance Rating Distribution', fontweight='bold')\n",
    "        ax.set_ylabel('Number of Tickets')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    def _plot_lead_time_distribution(self, ax, successful):\n",
    "        \"\"\"Plot lead time distribution\"\"\"\n",
    "        lead_times = [r.get('final_reply_lead_time_minutes', 0) for r in successful \n",
    "                     if r.get('final_reply_lead_time_minutes') is not None]\n",
    "        \n",
    "        if not lead_times:\n",
    "            ax.text(0.5, 0.5, 'No lead time data', ha='center', va='center')\n",
    "            return\n",
    "        \n",
    "        ax.hist(lead_times, bins=15, alpha=0.7, color='#2E86AB', edgecolor='black')\n",
    "        ax.set_title('Final Reply Lead Time Distribution', fontweight='bold')\n",
    "        ax.set_xlabel('Lead Time (minutes)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        \n",
    "        # Add statistics\n",
    "        avg_lt = np.mean(lead_times)\n",
    "        ax.axvline(avg_lt, color='red', linestyle='--', label=f'Average: {avg_lt:.1f} min')\n",
    "        ax.legend()\n",
    "    \n",
    "    def _plot_quality_distribution(self, ax, successful):\n",
    "        \"\"\"Plot quality score distribution\"\"\"\n",
    "        quality_scores = [r.get('quality_score', 0) for r in successful]\n",
    "        \n",
    "        ax.hist(quality_scores, bins=range(0, 8), alpha=0.7, color='#F18F01', edgecolor='black')\n",
    "        ax.set_title('Quality Score Distribution', fontweight='bold')\n",
    "        ax.set_xlabel('Quality Score (0-6)')\n",
    "        ax.set_ylabel('Number of Tickets')\n",
    "        ax.set_xticks(range(0, 7))\n",
    "    \n",
    "    def _plot_reply_effectiveness(self, ax, stats):\n",
    "        \"\"\"Plot reply effectiveness metrics\"\"\"\n",
    "        if 'reply_effectiveness' not in stats:\n",
    "            ax.text(0.5, 0.5, 'No data', ha='center', va='center')\n",
    "            return\n",
    "        \n",
    "        eff = stats['reply_effectiveness']\n",
    "        metrics = ['First Reply\\nFound', 'Final Reply\\nFound', 'Both Replies\\nFound']\n",
    "        rates = [eff['first_reply_found_rate'] * 100, \n",
    "                eff['final_reply_found_rate'] * 100,\n",
    "                eff['both_replies_found_rate'] * 100]\n",
    "        \n",
    "        bars = ax.bar(metrics, rates, color=['#2E86AB', '#A23B72', '#F18F01'])\n",
    "        ax.set_title('Reply Effectiveness Rates', fontweight='bold')\n",
    "        ax.set_ylabel('Rate (%)')\n",
    "        ax.set_ylim(0, 100)\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for bar, rate in zip(bars, rates):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                   f'{rate:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    def _plot_threshold_violations(self, ax, stats):\n",
    "        \"\"\"Plot threshold violations\"\"\"\n",
    "        if 'threshold_violations' not in stats or not stats['threshold_violations']:\n",
    "            ax.text(0.5, 0.5, 'No threshold violations', ha='center', va='center', fontweight='bold')\n",
    "            return\n",
    "        \n",
    "        violations = list(stats['threshold_violations'].keys())\n",
    "        counts = list(stats['threshold_violations'].values())\n",
    "        \n",
    "        bars = ax.bar(violations, counts, color='#C73E1D')\n",
    "        ax.set_title('Threshold Violations', fontweight='bold')\n",
    "        ax.set_ylabel('Number of Occurrences')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    def _plot_lead_time_by_issue_type(self, ax, successful):\n",
    "        \"\"\"Plot lead time by issue type\"\"\"\n",
    "        issue_data = {}\n",
    "        for result in successful:\n",
    "            issue_type = result['final_issue_type']\n",
    "            lead_time = result.get('final_reply_lead_time_minutes')\n",
    "            if lead_time is not None:\n",
    "                if issue_type not in issue_data:\n",
    "                    issue_data[issue_type] = []\n",
    "                issue_data[issue_type].append(lead_time)\n",
    "        \n",
    "        if not issue_data:\n",
    "            ax.text(0.5, 0.5, 'No lead time data by issue type', ha='center', va='center')\n",
    "            return\n",
    "        \n",
    "        # Prepare data for box plot\n",
    "        labels = list(issue_data.keys())\n",
    "        data = [issue_data[label] for label in labels]\n",
    "        colors = [self.colors.get(label, '#999999') for label in labels]\n",
    "        \n",
    "        box_plot = ax.boxplot(data, labels=labels, patch_artist=True)\n",
    "        \n",
    "        # Color the boxes\n",
    "        for patch, color in zip(box_plot['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "        ax.set_title('Lead Time Distribution by Issue Type', fontweight='bold')\n",
    "        ax.set_ylabel('Lead Time (minutes)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def _create_individual_charts(self, successful, stats):\n",
    "        \"\"\"Create additional individual charts\"\"\"\n",
    "        # 1. Performance by Issue Type\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        performance_by_type = {}\n",
    "        for result in successful:\n",
    "            issue_type = result['final_issue_type']\n",
    "            performance = result['performance_rating']\n",
    "            if issue_type not in performance_by_type:\n",
    "                performance_by_type[issue_type] = []\n",
    "            performance_by_type[issue_type].append(performance)\n",
    "        \n",
    "        # Convert to counts\n",
    "        plot_data = {}\n",
    "        for issue_type, performances in performance_by_type.items():\n",
    "            plot_data[issue_type] = Counter(performances)\n",
    "        \n",
    "        # Create stacked bar chart\n",
    "        ratings = ['excellent', 'good', 'fair', 'poor']\n",
    "        bottom = np.zeros(len(plot_data))\n",
    "        \n",
    "        for i, rating in enumerate(ratings):\n",
    "            counts = [plot_data[issue_type].get(rating, 0) for issue_type in plot_data.keys()]\n",
    "            ax.bar(plot_data.keys(), counts, bottom=bottom, label=rating.capitalize(), \n",
    "                  color=self.performance_colors.get(rating, '#999999'))\n",
    "            bottom += counts\n",
    "        \n",
    "        ax.set_title('Performance Rating by Issue Type', fontweight='bold')\n",
    "        ax.set_ylabel('Number of Tickets')\n",
    "        ax.legend()\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.visualizations_dir}performance_by_issue_type.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"‚úÖ Individual charts created in {self.visualizations_dir}\")\n",
    "\n",
    "# Initialize Enhanced Results Exporter\n",
    "exporter = ResultsExporter()\n",
    "\n",
    "print(\"‚úÖ ENHANCED Results Exporter & Visualizer Ready!\")\n",
    "print(\"   ‚úì 8 Sheets Excel Export\")\n",
    "print(\"   ‚úì Complete Q-A Pairs Data\") \n",
    "print(\"   ‚úì Main Issue Scoring Details\")\n",
    "print(\"   ‚úì Reply Analysis Details\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
